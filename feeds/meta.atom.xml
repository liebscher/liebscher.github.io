<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Alex Liebscher - meta</title><link href="/" rel="alternate"></link><link href="/feeds/meta.atom.xml" rel="self"></link><id>/</id><updated>2022-05-16T00:00:00-07:00</updated><entry><title>Highlights from PyCon 2022</title><link href="/posts/2022/May/pycon-2022-highlights/" rel="alternate"></link><published>2022-05-16T00:00:00-07:00</published><updated>2022-05-16T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2022-05-16:/posts/2022/May/pycon-2022-highlights/</id><summary type="html">&lt;p&gt;Lessons from 18 talks at this year&amp;#8217;s three days of&amp;nbsp;Pycon&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was fortunate enough to attend PyCon 2022 this year in Salt Lake City (thanks BetterUp!). This is the annual Python conference, put on by the Python Software Foundation. It was my first time going and I had few expectations going into it. I really enjoyed my time, and learned a number of new things and ways of thinking. Here are some highlights and learnings from a subset of the talks I&amp;nbsp;attended.&lt;/p&gt;
&lt;h2&gt;Day&amp;nbsp;1&lt;/h2&gt;
&lt;table class="uk-table"&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th class="uk-width-1-6"&gt;Speaker&lt;/th&gt;
            &lt;th class="uk-width-1-5"&gt;Topic&lt;/th&gt;
            &lt;th&gt;Notes&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;Łukasz Langa&lt;/td&gt;
            &lt;td&gt;Type Annotations&lt;/td&gt;
            &lt;td&gt;This was a pretty technical deep-dive into Python&amp;#8217;s typing system. It was a good reminder to me that this is a (useful) feature in Python that is here to stay. Check out &lt;a href="http://mypy-lang.org/" target="_new"&gt;mypy&lt;/a&gt; for implementation details. This was my first time hearing of Łukasz, who is a core developer of Python and known by many.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href="https://treyhunner.com/" target="_new"&gt;Trey Hunner&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Python Oddities Explained&lt;/td&gt;
            &lt;td&gt;A good reminder that Python is quirky, and to always be on the lookout for things that didn&amp;#8217;t match your expectations. See also &lt;a href="https://github.com/pablogsal/python-horror-show" target="_new"&gt;Python&amp;#8217;s Horror Show&lt;/a&gt; from Pablo S (talk below)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href="https://github.com/brandtbucher/" target="_new"&gt;Brandt Bucher&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Structural Pattern Matching&lt;/td&gt;
            &lt;td&gt;&lt;a href="https://peps.python.org/pep-0636/" target="_new"&gt;Pattern matching&lt;/a&gt; (new &lt;code&gt;match&lt;/code&gt; keyword) seems like a neat new feature in Python 3.11. Not sure yet how I&amp;#8217;d leverage it but I&amp;#8217;m happy to know it will exist. It may look like a switch statement, but it&amp;#8217;s not! It&amp;#8217;s for flow control and unpacking variables. It&amp;#8217;s more powerful and flexible than a switch statement, but also serves a slightly different purpose.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Reuven Lerner&lt;/td&gt;
            &lt;td&gt;Understanding Python attributes&lt;/td&gt;
            &lt;td&gt;
                &lt;p&gt;Ask yourself, how does a class object, an instance, an instance variable, an attribute, and a descriptor all relate? This is surprisingly complex question, in my opinion. It&amp;#8217;s one of those oddly confusing computer science-y things (similar to the reasons why I didn&amp;#8217;t want to study &lt;span class="caps"&gt;CS&lt;/span&gt;). Class objects support two kinds of operations: attribute references and instantiation. With the former, you can access class attributes and variables. With the latter, once we have an instance object, we can only perform attribute reference. There are two instance attribute types: data attributes (sometimes called instance variables or class members) and methods. Instance variables are data unique for an instance, and class variables are data shared by all instances of the class. But what about a&amp;nbsp;descriptor?&lt;/p&gt;
                &lt;blockquote&gt;A descriptor is what we call any object that defines `__get__()`, `__set__()`, or `__delete__()` &amp;#8230; The main motivation for descriptors is to provide a hook allowing objects stored in class variables to control what happens during attribute lookup.&lt;/blockquote&gt;
                &lt;p&gt;If you&amp;#8217;re thoroughly confused, I understand. I recommend the Python docs &lt;a href="https://docs.python.org/3/tutorial/classes.html" target="_new"&gt;tutorial on classes&lt;/a&gt; as a starting point for&amp;nbsp;clarification.&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Paul Ganssle&lt;/td&gt;
            &lt;td&gt;&lt;a href="https://ganssle.io/talks/" target="_new"&gt;What to Do When the Bug Is in Someone Else&amp;#8217;s Code&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Somewhat relevant to something I&amp;#8217;ve been doing, a good new way to look at &lt;span class="caps"&gt;OSS&lt;/span&gt; and how to work with it. The speaker discussed five ways that you can overcome bugs in code that you don&amp;#8217;t maintain. In order of best to worst: patching upstream (fix the bug, then make a &lt;span class="caps"&gt;PR&lt;/span&gt; on the project), wrapper functions (encapsulate buggy code in updated code), monkey patching (assign the global variable a fixed version), vendoring (clone a copy, then patch it locally), and maintaining a fork (fork and patch a copy of the project). I&amp;#8217;m guilty of some of the worse behaviors, but now I&amp;#8217;ve got some perspective on why they&amp;#8217;re &amp;#8220;bad&amp;#8221; that I didn&amp;#8217;t have before.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Nir Barazida&lt;/td&gt;
            &lt;td&gt;Dock your Jupyter Notebook&lt;/td&gt;
            &lt;td&gt;This talk proposed hosting your Jupyter-based data science and research projects in Docker images. I&amp;#8217;d thought of running scripts in containers, but this was specifically about running notebooks. The speaker introduced &lt;a href="https://github.com/jupyter/docker-stacks" target="_new"&gt;docker-stacks&lt;/a&gt;. I thought this was all very fascinating for creating reproducible research. However, I tried to quickly implement this with my own work and it wasn&amp;#8217;t so easy. I still find Docker tricky as soon as you want to do even the slightest customizations to the image and runtime. Also, Conda overcomes many barriers to reproducibility and Docker seems to only contribute marginally.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Maria Jose Molina Contreras&lt;/td&gt;
            &lt;td&gt;Creating an indoor air quality monitoring and predictive system&lt;/td&gt;
            &lt;td&gt;This was an exposition of a data science project. The speaker basically linked up some &lt;span class="caps"&gt;CO2&lt;/span&gt; and climate sensors to a microcontroller and slapped a prediction algorithm on top. A couple learnings. First, open the windows, get some air inside your room/office! Second, machine learning projects don&amp;#8217;t have to be crazy complex. You can get detailed, but it&amp;#8217;s not necessary to make a point. The most interesting projects are the ones with real world consequences, not just the titanic dataset or housing prices. Third, so much effort goes into everything that sets up any prediction model. Always remember that.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1&gt;Day&amp;nbsp;2&lt;/h1&gt;
&lt;table class="uk-table"&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th class="uk-width-1-6"&gt;Speaker&lt;/th&gt;
            &lt;th class="uk-width-1-5"&gt;Title&lt;/th&gt;
            &lt;th&gt;Notes&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href="https://sissaoun.github.io/" target="_new"&gt;Sara Issaoun&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;Hands down one of the best talks of the weekend. Dr. Issaoun&amp;#8217;s talk was an inspiration, and for an extremely complex subject (astrophysics, astronomy, blackholes, etc.) she made the audience (or at least me) feel like both experts and curious children. If I had to pick one talk to re-attend, this would be the one. It was the only one where I went up to talk to talk to the speaker at the end.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Peter Wang&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;Peter gave an introduction to and live-demo of &lt;a href="https://pyscript.net/" target="_new"&gt;PyScript&lt;/a&gt;, &amp;#8220;a framework that allows users to create rich Python applications in the browser using &lt;span class="caps"&gt;HTML&lt;/span&gt;’s interface.&amp;#8221; This was another extremely inspiring talk. I don&amp;#8217;t know exactly how I would use Python-in-the-browser but I can imagine it will open a world of possibilities, similar to Node. I&amp;#8217;m very eager to see where this project goes, and perhaps sometime soon I&amp;#8217;ll give it a try and write up my experience.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Fred Phillips&lt;/td&gt;
            &lt;td&gt;Hooking into Imports&lt;/td&gt;
            &lt;td&gt;This speaker introduced the idea of &amp;#8220;hooking&amp;#8221; into the Python import process. For example, it might be necessary to create a blocklist of packages that can&amp;#8217;t be imported; or load package code from a remote database. In both cases, it can be helpful to modify and overload the default package search and execution process. I currently have no use case for it, but it was good to learn about what&amp;#8217;s happening under the hood. I had never considered the process with which Python resolves and loads the modules we import.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Antoine Toubhans&lt;/td&gt;
            &lt;td&gt;Flexible &lt;span class="caps"&gt;ML&lt;/span&gt; Experiment Tracking&lt;/td&gt;
            &lt;td&gt;Data Version Control (&lt;span class="caps"&gt;DVC&lt;/span&gt;) is something I&amp;#8217;ve been thinking about for years, and just haven&amp;#8217;t tried it out yet. It seems like it could help solve a number of common data science and machine learning problems. I just need to learn it. I&amp;#8217;ve decided to try it out in a current project I&amp;#8217;m working on. There is a learning curve, but not near as confusing as something like Docker; more comparable to git. So far I&amp;#8217;m finding some value in the experiment tracking functionality. I don&amp;#8217;t really want to implement my own visualizations to &lt;a href="https://dvc.org/doc/use-cases/experiment-tracking" traget="_new"&gt;track experiments&lt;/a&gt;, as was proposed in this talk (with streamlit), and I&amp;#8217;m hoping the maintainers of the &lt;span class="caps"&gt;DVC&lt;/span&gt; library add in more viz tools.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Ryan Kuhl&lt;/td&gt;
            &lt;td&gt;GraphQL&lt;/td&gt;
            &lt;td&gt;I had heard of GraphQL before but haven&amp;#8217;t spent anytime learning about it. Therefore I thought this would be a good crash-course on the tool, but it wasn&amp;#8217;t. GraphQL is a way to query any database (although it works well for graph DBs especially). My takeaways could be summed up as, this is a fascinating technology with a clear implementational benefit over other querying languages, but it seems highly engineered, clunky, and probably only worth it if you&amp;#8217;re dealing with a lot of data in a production environment.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href="https://github.com/pablogsal" target="_new"&gt;Pablo Galindo Salgado&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Making Python better w/ Errors&lt;/td&gt;
            &lt;td&gt;Python 3.11 and 3.12 will contain some big makeovers in the traceback and error diagnostic capabilities in Python. I&amp;#8217;m looking forward to having clearer and more specific errors and exceptions.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Kelly Schuster, Sean Paredes&lt;/td&gt;
            &lt;td&gt;Python like a 12-year-old&lt;/td&gt;
            &lt;td&gt;The speakers were two Python educators, who have experience teaching Python to middle schoolers. Their top learnings from working with these kids: Be curious! Take risks! Kids think broadly, unlike us adults. Engage all senses, not just what you can see (e.g. build something with your hands). Always be on the lookout for unexpected behavior. When solving a problem, think: what&amp;#8217;s the worst way to do this? (to force yourself to think in others&amp;#8217; shoes.)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Jeremiah Paige&lt;/td&gt;
            &lt;td&gt;Intro to Introspection&lt;/td&gt;
            &lt;td&gt;Python has many tools available for debugging, and although Python can be frustrating with its lack of verbosity sometimes, we must remember what we have at our disposal to dissect issues. For example, Python has the &lt;code&gt;&lt;a href="https://docs.python.org/3/library/inspect.html" target="_new"&gt;inspect&lt;/a&gt;&lt;/code&gt; built-in module to help diagnose runtime issues.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2&gt;Day&amp;nbsp;3&lt;/h2&gt;
&lt;table class="uk-table"&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th class="uk-width-1-6"&gt;Speaker&lt;/th&gt;
            &lt;th class="uk-width-1-5"&gt;Title&lt;/th&gt;
            &lt;th&gt;Notes&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;Joseph Lucas&lt;/td&gt;
            &lt;td&gt;Serialization&lt;/td&gt;
            &lt;td&gt;This talk introduced serialization and ways to do this in Python. Serialization refers to breaking down data and objects (in Python, or elsewhere) and storing it with the intent to deserialize it later for use. The speaker first talked about the built-in &lt;a href="https://docs.python.org/3/library/pickle.html" target="_new"&gt;pickle&lt;/a&gt; module. This is a Python-specific module for serializing objects and data structures in a compressed byte-stream. Unlike &lt;span class="caps"&gt;JSON&lt;/span&gt; (another serialization format), pickles are binary, not unicode; pickles are not human readable; pickles can represent a wide number of Python objects; and deserializing pickles can pose an execution safety risk, unlike &lt;span class="caps"&gt;JSON&lt;/span&gt;. If we&amp;#8217;re trying to serialize an object that pickle cannot handle, there is the &lt;a href="https://pypi.org/project/dill/" target="_new"&gt;dill&lt;/a&gt; module.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Tetsuya &amp;#8220;Jesse&amp;#8221; Hirata&lt;/td&gt;
            &lt;td&gt;Productionize Research-Oriented Code&lt;/td&gt;
            &lt;td&gt;I went into this thinking it would cover how to write research code for your production engineers. Instead, it was how to read research code from your researchers as an engineer. This was a pleasant surprise, and was almost sort of a lesson in empathy. This reinforced my belief that my code and work is most valuable when it can be (quickly and easily) taken to a place of impact. Some reminders for myself: write clean code, and document it; modularize when possible; separate loading, cleaning, processing, and modeling; if you have time, look for ways to refactor.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Cillian Kieran&lt;/td&gt;
            &lt;td&gt;Open-Source Tools For Data Privacy&lt;/td&gt;
            &lt;td&gt;The &lt;a href="https://ethyca.com/fides/" target="_new"&gt;Ethyca fida&lt;/a&gt; folks have laid out a really appealing taxonomy of data privacy in the way of privacy-as-code. I love data privacy, and I lvoe categorizing things, especially data, so this is like candy to me. I don&amp;#8217;t know if I would try this out in reality, as it seems like a pretty heavy lift, but maybe one day.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;</content><category term="meta"></category><category term="Python"></category></entry><entry><title>Oddities and Surprises: Unusual Behaviors in R and Python</title><link href="/posts/2022/May/oddities-and-surprises/" rel="alternate"></link><published>2022-05-13T00:00:00-07:00</published><updated>2022-05-13T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2022-05-13:/posts/2022/May/oddities-and-surprises/</id><summary type="html">&lt;p&gt;Questioning the developers of our favorite&amp;nbsp;languages&lt;/p&gt;</summary><content type="html">&lt;p&gt;This document is a collection of unexpected behaviors in R and Python. It&amp;#8217;s inspired by &lt;a href="https://treyhunner.com/python-oddities/resources.html"&gt;Python Oddities&lt;/a&gt; and &lt;a href="https://github.com/pablogsal/python-horror-show"&gt;Python&amp;#8217;s horror show&lt;/a&gt;. I will add to it over&amp;nbsp;time.&lt;/p&gt;
&lt;h1&gt;Python&lt;/h1&gt;
&lt;h2&gt;String&amp;nbsp;Strip&lt;/h2&gt;
&lt;h3&gt;Behavior&lt;/h3&gt;
&lt;p&gt;Let&amp;#8217;s say we have a&amp;nbsp;string:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;I love when monkeys write&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When we run &lt;code&gt;sentence.rstrip('new york times')&lt;/code&gt;, as if we wanted to remove any case of &amp;#8220;new york times&amp;#8221; from the string, we would expect the string to go unchanged. After all, &amp;#8220;new york times&amp;#8221; is not mentioned anywhere in &lt;code&gt;sentence&lt;/code&gt;. Instead though, we get&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rstrip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;new york times&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;'I love wh'&lt;/pre&gt;

&lt;h3&gt;Explanation&lt;/h3&gt;
&lt;p&gt;Unlike how one might guess based on their names, Python&amp;#8217;s &lt;code&gt;rstrip&lt;/code&gt; and similar string methods don&amp;#8217;t remove &lt;em&gt;suffixes&lt;/em&gt;. Instead, they remove trailing characters in the list provided. And as it turns out, &amp;#8220;New York Times&amp;#8221; is &lt;a href="https://en.wikipedia.org/wiki/Anagram"&gt;an anagram&lt;/a&gt; of &amp;#8220;monkeys write&amp;#8221; (plus the &amp;#8220;en&amp;#8221; in &amp;#8220;when&amp;#8221;). Therefore all of the characters in the former get found in the&amp;nbsp;latter.&lt;/p&gt;
&lt;p&gt;From the&amp;nbsp;documentation,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The chars argument is not a suffix; rather, all combinations of its values are&amp;nbsp;stripped&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What&amp;#8217;s the &amp;#8220;right&amp;#8221; way to remove a suffix? The docs recommend &lt;a href="https://docs.python.org/3/library/stdtypes.html#str.removesuffix"&gt;str.removesuffix()&lt;/a&gt;. This is only implemented in Python 3.9 and&amp;nbsp;above.&lt;/p&gt;</content><category term="meta"></category><category term="Python"></category><category term="Rlang"></category></entry><entry><title>Solving the Grecian Computer</title><link href="/posts/2022/Mar/solving-grecian-computer/" rel="alternate"></link><published>2022-03-18T00:00:00-07:00</published><updated>2022-03-18T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2022-03-18:/posts/2022/Mar/solving-grecian-computer/</id><summary type="html">&lt;p&gt;Solving Grandma&amp;#8217;s puzzle with a little algorithmic&amp;nbsp;help&lt;/p&gt;</summary><content type="html">&lt;p&gt;My family celebrated my grandma&amp;#8217;s 88th birthday a couple weekends ago. She, however, was prepared to give out gifts to everyone else. Knowing what my family enjoys doing, she mail ordered (from a catalogue, yes) a puzzle for us all to solve. It&amp;#8217;s called the Grecian Computer puzzle. Unfortunately, I can&amp;#8217;t find any reliable background on it. Barnes and Noble &lt;a href="https://www.barnesandnoble.com/w/true-genius-greek-computer-2-wooden-brainteaser-puzzle-project-genius/1137585230"&gt;claims&lt;/a&gt; it was inspired by an astronomical tool found in an old Grecian shipwreck. I think it&amp;#8217;s just a puzzle someone came up with. However skeptical I am of its origins, the puzzle is hard, very hard. My sister, dad, and I took turns trying to solve it and none of us made any progress. Not that we&amp;#8217;re numerical geniuses, but collectively we were&amp;nbsp;stumped.&lt;/p&gt;
&lt;p&gt;To help you picture what we were up against, here is what the puzzle looks&amp;nbsp;like:&lt;/p&gt;
&lt;p&gt;&lt;img data-src="/images/grecian-computer-start.jpg" class="uk-align-center" width="90%" height="" alt="Starting position of the Grecian Computer puzzle" uk-img&gt;&lt;/p&gt;
&lt;p&gt;Each of the concentric circles rotates, and the goal is to turn these dials until each of the 12 columns add up to&amp;nbsp;42.&lt;/p&gt;
&lt;p&gt;The dials aren&amp;#8217;t purely concentric &amp;#8212; some of the spaces are &amp;#8220;blank&amp;#8221;, revealing the number on the dial&amp;nbsp;below.&lt;/p&gt;
&lt;p&gt;After turning the dials for a while without success, I took out a piece of paper and started writing out numbers. It took me a moment before realizing how to write them out: each dial being a &amp;#8220;layer&amp;#8221; and represented as a matrix. I could leave a cell empty to represent a hole in a dial. Here&amp;#8217;s one of my&amp;nbsp;notes:&lt;/p&gt;
&lt;p&gt;&lt;img data-src="/images/grecian-computer-notes.jpg" class="uk-align-center" width="60%" height="" alt="A piece of scratch paper with a collection of numbers written out to describe my thoughts while trying to represent the puzzle numerically" uk-img&gt;&lt;/p&gt;
&lt;p&gt;This started to make sense in my head and I noticed a couple patterns, but nothing meaningful enough to help solve the puzzle. I thought, Well since these are really just matrices, could we write an algorithm to solve&amp;nbsp;this?&lt;/p&gt;
&lt;p&gt;Let me first get it out of the way that yes, I solved the puzzle. Yes, I did it using a computer. No, I have no idea how to solve the puzzle without the computer&amp;#8217;s brute force. Puzzles are for meant to be fun, and reveling in Algorithm Land is my version of&amp;nbsp;fun.&lt;/p&gt;
&lt;p&gt;That made clear, I&amp;#8217;m sure the reader is most interested in the computational solution. Without further delay, I first will describe the solution, then my progress and&amp;nbsp;learnings.&lt;/p&gt;
&lt;h2&gt;Solution&lt;/h2&gt;
&lt;p&gt;I represented our puzzle as a 3-dimensional tensor. A tensor is a generalization of a scalar, a vector, or a matrix. A scalar is a 0-dimensional tensor, a vector 1-dimensional, and a matrix 2-dimensional. The puzzle has 5 dials, with 4 rows of numbers, and 12 columns. Naturally then, this is a tensor with shape&amp;nbsp;5x4x12.&lt;/p&gt;
&lt;p&gt;The solution is given to us: all columns must sum to 42. Mathematically, we can represent this solution as a vector of length 12, each value equal to&amp;nbsp;42.&lt;/p&gt;
&lt;p&gt;We have two unanswered questions. First, how do we represent those &amp;#8220;blank&amp;#8221; or &amp;#8220;empty&amp;#8221; cells? Second, how do we &amp;#8220;rotate&amp;#8221; the&amp;nbsp;dials?&lt;/p&gt;
&lt;p&gt;My answer to the first is that the &amp;#8220;empty&amp;#8221; cells in the tensor are set to 0. A zero signals, through masking and multiplication, that the value beneath is&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;My answer to the second is to &amp;#8220;rotate&amp;#8221; or &amp;#8220;roll&amp;#8221; a specific axis of the tensor. The matrix gets pushed to the right and the column that falls off gets placed on the&amp;nbsp;left.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m intentionally grounding this explanation in metaphors of the physical world. Without the metaphors, we would quickly become lost in&amp;nbsp;terminology.&lt;/p&gt;
&lt;p&gt;Another hidden difficulty in this is summing the columns. What&amp;#8217;s trivial for the human eye to pick up as a &amp;#8220;column&amp;#8221; is less so in this computational framework. I thought of this as working down, or outward. First, we consider the innermost or top dial. Suppose on a dial, &lt;span class="math"&gt;\(A\)&lt;/span&gt;, with two numbers (but four spaces) there&amp;nbsp;are&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[0, 5, 0, 1]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then if we sum over each column we get the result: &lt;code&gt;[0, 5, 0, 1]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Suppose there&amp;#8217;s a dial underneath, call this &lt;span class="math"&gt;\(B\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[
  [1,1,1,1],
  [2,2,2,2]
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;How would we add this with the innermost dial? Overlay the first dial onto the second. The first column would be 1 + 2 = 3. Second, 1 + 5 = 6. Third, 1 + 2 = 3. Fourth, 1 + 1 = 2. Resulting in &lt;code&gt;[3, 6, 3, 2]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I represented the innermost dial &lt;span class="math"&gt;\(A\)&lt;/span&gt; then&amp;nbsp;as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[
  [0, 0, 0, 0],
  [0, 5, 0, 1]
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To quickly compute the result of &lt;span class="math"&gt;\(A\)&lt;/span&gt; overlaid on &lt;span class="math"&gt;\(B\)&lt;/span&gt;,&amp;nbsp;solve:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;A + (A == 0)*B
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code&gt;(A == 0)&lt;/code&gt; becomes a masking matrix of 1s (&lt;code&gt;True&lt;/code&gt;) and 0s (&lt;code&gt;False&lt;/code&gt;). Thus this only uses values of &lt;span class="math"&gt;\(B\)&lt;/span&gt; where &lt;span class="math"&gt;\(A\)&lt;/span&gt; is empty. Bringing it all together, this sums the values of &lt;span class="math"&gt;\(B\)&lt;/span&gt; where &lt;span class="math"&gt;\(A\)&lt;/span&gt; is empty, with all values of &lt;span class="math"&gt;\(A\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We extend this for all five puzzle dials until we have something that looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here &lt;code&gt;game&lt;/code&gt; is just a copy of the game board after rotating it. Consider &lt;code&gt;game[4]&lt;/code&gt; as &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;code&gt;game[3]&lt;/code&gt; as &lt;span class="math"&gt;\(B\)&lt;/span&gt;. Now extend the logic to the next dial, say &lt;span class="math"&gt;\(C\)&lt;/span&gt;, where the values of &lt;span class="math"&gt;\(C\)&lt;/span&gt; are only relevant where we can see them (i.e. where the values of both &lt;span class="math"&gt;\(A\)&lt;/span&gt; and &lt;span class="math"&gt;\(B\)&lt;/span&gt; are&amp;nbsp;0).&lt;/p&gt;
&lt;p&gt;Now what about rotating the dials? Numpy has an &lt;code&gt;np.roll&lt;/code&gt; method that performs exactly what we need: rolling an axis of a tensor so that the &amp;#8220;columns&amp;#8221; are shifted, with the final column being carried over to the&amp;nbsp;front.&lt;/p&gt;
&lt;p&gt;Lastly, we must represent the state of the dial somehow. I did this with a vector of length 5, with each element representing the rotation (up to 12) of one of the five dials. The starting point of the game is arbitrary, and doesn&amp;#8217;t matter since we can brute force all combinations&amp;nbsp;anyways.&lt;/p&gt;
&lt;p&gt;We have a function for summing the puzzle and checking the&amp;nbsp;score:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;equals&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# first roll the board so the dials are at the right positions&lt;/span&gt;
    &lt;span class="n"&gt;sub_copy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roll_board&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# now sum all the columns, for each dial taking into account how it&amp;#39;s masked&lt;/span&gt;
    &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# do all our columsn equal our solution?&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;solution&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We also have a function for rotating the board, according to a given&amp;nbsp;state:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;roll_board&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# first, create a copy of the game (so we don&amp;#39;t modify the original)&lt;/span&gt;
    &lt;span class="n"&gt;sub_copy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# for each of the 5 dials&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;selected&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;game&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
        &lt;span class="c1"&gt;# roll the dial (on axis 2) and keep the new position in the copy&lt;/span&gt;
        &lt;span class="n"&gt;selected&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;roll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;selected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;sub_copy&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;selected&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sub_copy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I saw this as a recursive problem, instead of writing out many loops. This recursive function looks like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nd"&gt;@tail_recursive&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recursive&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tally&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="c1"&gt;# exit condition&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;equals&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tally&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# create a copy of the puzzle state that may be masked&lt;/span&gt;
    &lt;span class="n"&gt;masked&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# we want to know if any of the dials have been exhausted&lt;/span&gt;
    &lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argwhere&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;masked&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# if none have, turn the outermost dial one place&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;masked&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="c1"&gt;# recurse with one change in the state&lt;/span&gt;
        &lt;span class="n"&gt;recurse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;masked&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tally&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# if one of dials has been exhausted, we increment the dial&lt;/span&gt;
    &lt;span class="c1"&gt;# just greater than it, and wipe clean the dials less than it&lt;/span&gt;
    &lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;masked&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;masked&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="n"&gt;recurse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;masked&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tally&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can initiate the algorithm and&amp;nbsp;solve:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;recursive&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
(array([0, 5, 9, 2, 7]), 10871)
&lt;/pre&gt;

&lt;p&gt;It took 10,871 dial turns to reach the solution: [0, 5, 9, 2,&amp;nbsp;7].&lt;/p&gt;
&lt;p&gt;Here is what the puzzle looks like at this state, with all columns adding to&amp;nbsp;42:&lt;/p&gt;
&lt;p&gt;&lt;img data-src="/images/grecian-computer-end.jpg" class="uk-align-center" width="90%" height="" alt="Completed position of the Grecian Computer puzzle, with all five columns adding to 42" uk-img&gt;&lt;/p&gt;
&lt;h2&gt;Progress and&amp;nbsp;Learnings&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m glad to be able to share this solution, and I did my best to explain it simply. There was a handful of attempts to get here though, and it wasn&amp;#8217;t a straight&amp;nbsp;shot.&lt;/p&gt;
&lt;p&gt;First, I didn&amp;#8217;t immediately realize that I&amp;#8217;d need to mask numbers. I was confused why the columns weren&amp;#8217;t adding up digitally like they were on the puzzle. Eventually I understood that numbers on outer dials were being &amp;#8220;hidden&amp;#8221; by inner dials. I found that I could mask the outer dials by converting the inner dial to &amp;#8220;mask&amp;#8221; or &amp;#8220;no&amp;nbsp;mask&amp;#8221;.&lt;/p&gt;
&lt;p&gt;I also wasn&amp;#8217;t aware of the &lt;code&gt;np.roll&lt;/code&gt; method going into this. I thought I was going to have to&amp;#8230; roll my own. Luckily, it took me one or two Google searches to find the pre-built roll method. It did however take me some time to understand how best to use it in this case. Through trial-and-error, I rolled different tensors and tried matching the output with what I&amp;nbsp;expected.&lt;/p&gt;
&lt;p&gt;It was about this point that a &lt;a href="https://en.wikipedia.org/wiki/Recursion"&gt;recursive strategy&lt;/a&gt; came to mind. I prototyped a looping method, but it seemed too &amp;#8220;hardcoded&amp;#8221;, messy, and &amp;#8220;stateful.&amp;#8221; I have not taken any algorithms courses though. My understanding of algorithms, and recursion, is very&amp;nbsp;limited.&lt;/p&gt;
&lt;p&gt;I also realized around this time that I wouldn&amp;#8217;t be able to continue on without using simplified toy data. The real data was too complex, and if I wanted to prototype with only one or two layers I wouldn&amp;#8217;t have a known solution. So, I created a toy dataset of size 3x3x3 (3 dials, with 3 rows, and 3&amp;nbsp;columns).&lt;/p&gt;
&lt;p&gt;I came up with a first recursive attempt, but, surprisingly, it wasn&amp;#8217;t recursive enough. I was really only iterating down a single dimension, not all dimensions. So, many of the possible combinations weren&amp;#8217;t getting tried out. I paused and thought about what I needed in a recursive function. I tried&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;There were a couple updates to adapt my previous recursive function to the real data. The toy data was necessary for getting the mechanics down, but I needed to see how things would flow in reality. This included putting quite a few print statements in the recursive&amp;nbsp;function.&lt;/p&gt;
&lt;p&gt;As I was testing, I hit a &lt;a href="https://stackoverflow.com/questions/2401447/python-recursive-function-error-maximum-recursion-depth-exceeded"&gt;RecursionError&lt;/a&gt; saying I reached the maximum recursion depth. I had to Google what this meant. I went back to the drawing board to start fresh with some of the implementations I saw&amp;nbsp;online.&lt;/p&gt;
&lt;p&gt;I created a new function and again hit a recursion error. This forced me to go learn about &lt;a href="https://stackoverflow.com/questions/33923/what-is-tail-recursion"&gt;(non-)tail recursion&lt;/a&gt; and how Python handles this type of computation. I discovered that Guido in fact &lt;a href="https://neopythonic.blogspot.com/2009/04/tail-recursion-elimination.html"&gt;does not believe&lt;/a&gt; that Python should be designed with recursion in&amp;nbsp;mind:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Third, I don&amp;#8217;t believe in recursion as the basis of all programming. This is a fundamental belief of certain computer scientists, especially those who love Scheme and like to teach programming by starting with a &amp;#8220;cons&amp;#8221; cell and recursion. But to me, seeing recursion as the basis of everything else is just a nice theoretical approach to fundamental mathematics (&lt;a href="http://en.wikipedia.org/wiki/Turtles_all_the_way_down"&gt;turtles all the way down&lt;/a&gt;), not a day-to-day&amp;nbsp;tool.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So trying to use recursion had come back to bite me. I read that Python only allowed at most about 1000 levels deep in a recursive function. After this, the memory stack has too much to keep track of, and opts to fail. Next time I think I will favor an iterative approach, at least when using&amp;nbsp;Python.&lt;/p&gt;
&lt;p&gt;I found a snippet of code on &lt;a href="https://chrispenner.ca/posts/python-tail-recursion"&gt;a kind person&amp;#8217;s blog&lt;/a&gt; which catches any tail recursion error, if there is one. If it catches an error, it restarts a new stack of memory after closing out the original function. This allows the recursive function to continue on even if it hits Python&amp;#8217;s recursive limit. In my case, this was a good enough solution to carry onward. You can see how this decorator is used in my code above. I copy here the&amp;nbsp;snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Recurse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recurse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;Recurse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tail_recursive&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decorated&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;Recurse&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;
                &lt;span class="n"&gt;kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;decorated&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Eventually, I hit run and the function carried out for about 5 to 10 seconds. As I mentioned, after 10,871 iterations, the function reached an output. I determined what the board would be at that result and tested it out on the game in my hand.&amp;nbsp;Success!&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="meta"></category><category term="python"></category><category term="algorithms"></category></entry><entry><title>Linear Regression: Parameter Estimation</title><link href="/posts/2022/Feb/linear-regression-parameters/" rel="alternate"></link><published>2022-02-21T00:00:00-08:00</published><updated>2022-02-21T00:00:00-08:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2022-02-21:/posts/2022/Feb/linear-regression-parameters/</id><summary type="html">&lt;p&gt;Three methods of fitting a line to&amp;nbsp;data&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img class="uk-align-center" width="90%" height="" src="/images/regr-header.png" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
Image by Alex Liebscher
&lt;/div&gt;

&lt;p&gt;Truly understanding the workings of linear regression isn&amp;#8217;t as straightforward as an introductory stats class makes it out to be. Because of its utility and storied history, linear regression can now be understood in too many ways for most scientists and data-folks to fully&amp;nbsp;grasp.&lt;/p&gt;
&lt;p&gt;This article makes a chip away at this complexity by explaining three routine methods for estimating linear regression parameters. We&amp;#8217;ll discuss Least Squares, Gradient Descent, and Bayesian&amp;nbsp;estimation.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll walk through each with code examples notebook-style and some sparse math to help illustrate what&amp;#8217;s happening. Before we get started, we&amp;#8217;ve got a few packages to load up. If you don&amp;#8217;t have them installed, create a &lt;code&gt;conda&lt;/code&gt; environment and &lt;code&gt;pip install&lt;/code&gt; them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.optimize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;minimize&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pymc3&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pm&lt;/span&gt;

&lt;span class="n"&gt;rng&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;default_rng&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;&lt;a name="s1"&gt;&lt;/a&gt;Creating our&amp;nbsp;Data&lt;/h2&gt;
&lt;p&gt;We will first create a fake dataset, also known as a simulated dataset. We do this so later on we can compare our model results to the true data generation process. Imagine a phenomenom that, when nothing happens, with an input of 0, the output is 5. Now imagine that when the process is input with -1, the output is 3; and when input with 1, the output is 7. We can build this simulation by specifying a line like &lt;span class="math"&gt;\(y = 5 + 2x + \epsilon\)&lt;/span&gt;, where &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is some random error on each output (for example &lt;span class="math"&gt;\(\pm 1\)&lt;/span&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;

&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can then plot these predictor values, ordered by which the data were&amp;nbsp;generated,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
    &lt;img src="/images/regression-fig1.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;and also related with the outcome&amp;nbsp;values,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
    &lt;img src="/images/regression-fig2.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;The human eye easily picks up a pattern here. There&amp;#8217;re data that, when the horizontal variable increases, corresponds to an increase in the vertical variable. The pattern looks linear. There also appears to be some noise in the data; one data point doesn&amp;#8217;t relate to the next in an exactly predictable&amp;nbsp;way.&lt;/p&gt;
&lt;p&gt;You&amp;#8217;re likely familiar with this scenario. As taught (either through instruction or experience), you&amp;#8217;d next feel a craving to model this pattern using a linear regression model. This would help you describe, in numerical terms, exactly the pattern you see. If you&amp;#8217;re jumping the gun, you&amp;#8217;d probably dart your eyes to those p-values too. This article won&amp;#8217;t discuss p-values, but it will discuss how our coefficients are&amp;nbsp;determined.&lt;/p&gt;
&lt;h2&gt;Estimating &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Given these simulated data, what can we do to understand what the pattern we&amp;nbsp;see?&lt;/p&gt;
&lt;h3&gt;Least&amp;nbsp;Squares&lt;/h3&gt;
&lt;p&gt;The first and most transparent method for understanding the relationship we see is called Least Squares, or Ordinary Least&amp;nbsp;Squares.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s called least squares because our goal with this method is to find the line which &lt;span style="color: red;"&gt;minimizes&lt;/span&gt; the &lt;span style="color: purple;"&gt;sum&lt;/span&gt; of the &lt;span style="color: orange;"&gt;squares&lt;/span&gt; of the residuals&amp;#8212;the &lt;span style="color: blue;"&gt;true outcome&lt;/span&gt; minus the &lt;span style="color: green;"&gt;model prediction&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$
\color{red}{\text{argmin}}_{\alpha, \beta} \color{purple}{\sum}_{i=1}^N \color{orange}{(}\color{blue}{y_i} - (\color{green}{\alpha + \beta x_i})\color{orange}{)^2}
$$&lt;/div&gt;
&lt;p&gt;The parameter values, or &lt;strong&gt;regression coefficients&lt;/strong&gt;, are defined as the best solution to this minimization&amp;nbsp;problem.&lt;/p&gt;
&lt;h4&gt;Algabraic&amp;nbsp;Solution&lt;/h4&gt;
&lt;p&gt;Our first stop is the algabraic solution to regression. By taking &lt;a href="https://seismo.berkeley.edu/~kirchner/eps_120/Toolkits/Toolkit_10.pdf"&gt;some calculus&lt;/a&gt; for granted, we arrive at a solution that requires nothing more than&amp;nbsp;algebra.&lt;/p&gt;
&lt;p&gt;In code, we can use our &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; vectors to compute the values for &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; quite&amp;nbsp;easily,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;x_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;beta_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;alpha_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;beta_hat&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x_mean&lt;/span&gt;

&lt;span class="n"&gt;alpha_hat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta_hat&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;(4.441, 2.789)&lt;/pre&gt;

&lt;p&gt;To visually assess the fit of this model, let&amp;#8217;s plot the fitted regression line on the data as well as the true data generation&amp;nbsp;line,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;xp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;k&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;--&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Truth&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha_hat&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta_hat&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Estimated&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;upper left&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
    &lt;img src="/images/regression-fig3.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;And that&amp;#8217;s it, we&amp;#8217;ve calculated a fitted line to the data at hand. As you can see, we came quite close to the true data generation line. Unfortunately, this method really only works if you only have a single predictor, which in many cases is too much of a&amp;nbsp;constraint.&lt;/p&gt;
&lt;h4&gt;Measuring&amp;nbsp;Error&lt;/h4&gt;
&lt;p&gt;It&amp;#8217;s common to assess the fit of the model by aggregating the &lt;em&gt;residuals&lt;/em&gt;. The residuals are the difference between either the true in-sample outcomes or a set of out-of-sample outcomes, and the predicted outcomes for those observations. Since we&amp;#8217;re not working with any out-of-sample data (like a testing or hold-out set), let&amp;#8217;s just calculate the in-sample&amp;nbsp;residuals:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha_hat&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta_hat&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;

&lt;span class="n"&gt;residuals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With this &lt;code&gt;residuals&lt;/code&gt; vector, we can compute the Mean Squared Error (&lt;span class="math"&gt;\(\text{MSE} = \frac{1}{df}\sum_{i=0}^n(residuals_i^2)\)&lt;/span&gt;), Root Mean Squared Error (&lt;span class="math"&gt;\(\text{RMSE} = \sqrt{\text{MSE}}\)&lt;/span&gt;), or Mean Absolute Error. &lt;a href="http://zerospectrum.com/2019/06/02/mae-vs-mse-vs-rmse/"&gt;Each of these&lt;/a&gt; is a method for quantitatively assessing how well the model fit the data. If we had a test set of data, we could assess how well the model fits new data, i.e. its ability to&amp;nbsp;generalize.&lt;/p&gt;
&lt;p&gt;The error in the model &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is assumed to be normally distributed, and there is in fact a strong relationship between how the variance of a Gaussian sample can be computed and the formula for the &lt;span class="caps"&gt;MSE&lt;/span&gt;. Both are drawn from the idea that the squared difference between the true value (the true &lt;span class="math"&gt;\(x\)&lt;/span&gt; or true &lt;span class="math"&gt;\(y\)&lt;/span&gt;) and the mean or predicted value (&lt;span class="math"&gt;\(\mu\)&lt;/span&gt; or &lt;span class="math"&gt;\(\hat{y}\)&lt;/span&gt;) is a meaningful quantity of dispersion. The general form for either the sample variance or the &lt;span class="caps"&gt;MSE&lt;/span&gt;&amp;nbsp;is&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{Var}(\theta) = \text{MSE}(\theta) = \mathbb{E}_\theta[(\theta - \hat{\theta})^2]
$$&lt;/div&gt;
&lt;p&gt;which can be defined then for either the sample&amp;nbsp;variance&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{Var}(X) = \mathbb{E}_X[(X - \mu)^2] = \frac{1}{n}\sum_{i=0}^n (x_i - \mu)^2
$$&lt;/div&gt;
&lt;p&gt;or the &lt;span class="caps"&gt;MSE&lt;/span&gt;, where &lt;span class="math"&gt;\(p\)&lt;/span&gt; is the number of model parameters (and the 1 indicates a degree of freedom for the&amp;nbsp;intercept)&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{MSE}(y) = \mathbb{E}_y[(y - \hat{y})^2] = \frac{1}{n-p-1}\sum_{i=0}{n} (y_i - \hat{y_i})^2
$$&lt;/div&gt;
&lt;p&gt;The ability of the model to minimize the squared error is also closely related to how well the model captures variance in the data. This is known as the &lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"&gt;coefficient of determination&lt;/a&gt; &lt;span class="math"&gt;\(r^2\)&lt;/span&gt;, and can be computed&amp;nbsp;like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
0.3728
&lt;/pre&gt;

&lt;p&gt;This says that, on a scale from 0 to 1, the model captures about 37% of the variance in the response data. Normally we&amp;#8217;d need to place this in the context of other studies or research to decide if it&amp;#8217;s good or bad, but here we know the true data generation process. It&amp;#8217;s lower than I would have expected, but still it&amp;#8217;s good to see that the model captures some degree of&amp;nbsp;variance.&lt;/p&gt;
&lt;h4&gt;Linear Algebraic&amp;nbsp;Solution&lt;/h4&gt;
&lt;p&gt;The algabraic method is good pedalogically, but suffers at estimation when we want more than a single predictor and two parameters. So we&amp;#8217;ll graduate to a new method, which is actually equivalent to the algabraic method. We&amp;#8217;ll start by putting our intercept data (just 1&amp;#8217;s &lt;sup class="uk-link" uk-tooltip="Why 1's? To estimate a constant intercept, the data shouldn't change the estimate when multiplied. The one number which satisfies that identity mapping is 1."&gt;✳︎&lt;/sup&gt;) and &lt;span class="math"&gt;\(X\)&lt;/span&gt; data into a matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;M&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
[[1.        , 0.77395605],
 [1.        , 0.43887844],
 [1.        , 0.85859792],
 [1.        , 0.69736803],
 [1.        , 0.09417735]]
&lt;/pre&gt;

&lt;p&gt;From this we multiply the transpose of this matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt; by &lt;span class="math"&gt;\(M\)&lt;/span&gt; itself. If &lt;span class="math"&gt;\(M\)&lt;/span&gt; is originally &lt;span class="math"&gt;\(N\)&lt;/span&gt; by &lt;span class="math"&gt;\(2\)&lt;/span&gt;, then this creates a &lt;span class="math"&gt;\(2\)&lt;/span&gt; by &lt;span class="math"&gt;\(2\)&lt;/span&gt; matrix. We then invert this matrix. There are tricks to doing this for models with many parameters, such as the &lt;span class="caps"&gt;LU&lt;/span&gt; decomposition or Cholesky decomposition, which I won&amp;#8217;t go into detail about here. With the inverse, we multiply this by &lt;span class="math"&gt;\(M\)&lt;/span&gt; transpose to get an &lt;span class="math"&gt;\(2 \times N\)&lt;/span&gt;. Lastly, this is multiplied by &lt;span class="math"&gt;\(\bf{y}\)&lt;/span&gt; to get our parameter solution, a &lt;span class="math"&gt;\(2 \times 1\)&lt;/span&gt;&amp;nbsp;vector.&lt;/p&gt;
&lt;div class="math"&gt;$$
\require{boldsymbol}
\boldsymbol{\hat{\beta}} = (M^TM)^{-1}M^T\boldsymbol{y}
$$&lt;/div&gt;
&lt;p&gt;in one line of Python this looks&amp;nbsp;like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is an excellent progression from the algabraic solution we just had because this allows us to find the parameter values for an arbitrarily large model, constrained only by our ability to take the inverse of a potentially large matrix. Luckily, as I mentioned, modern methods have tricks to increase the power of this&amp;nbsp;method.&lt;/p&gt;
&lt;p&gt;This matrix multiplication method is what R is doing when you call &lt;code&gt;lm()&lt;/code&gt; with a formula and a data frame. Granted, under the hood of this function there&amp;#8217;re layers of optimization and numerical tricks, but it&amp;#8217;s conceptually the same. For an excellent dive into the machinery behind &lt;code&gt;lm&lt;/code&gt; I highly recommend &lt;a href="https://madrury.github.io/jekyll/update/statistics/2016/07/20/lm-in-R.html"&gt;this blog article&lt;/a&gt; on the&amp;nbsp;matter.&lt;/p&gt;
&lt;h3&gt;Gradient&amp;nbsp;Descent&lt;/h3&gt;
&lt;p&gt;Least squares is sufficient for your typical linear regression model, and has the great benefit of having an analytical solution. But other regression models require other forms of finding the best parameter&amp;nbsp;values.&lt;/p&gt;
&lt;p&gt;One such alternative form is Gradient&amp;nbsp;Descent.&lt;/p&gt;
&lt;p&gt;First, a function to calculate the mean squared&amp;nbsp;error.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Beta&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;residuals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Beta&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;residuals&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We need to set uniform random initial values for our parameters &lt;sup class="uk-link" uk-tooltip="True, you could start with any values between -Inf and Inf, but most models don't have parameter estimates that large (if they do, you might consider transforming/scaling your data."&gt;✳︎&lt;/sup&gt;, &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;, or in this case &lt;span class="math"&gt;\(\hat{\beta}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;beta_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
&lt;span class="n"&gt;beta_hat&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
[0.437, 0.832]
&lt;/pre&gt;

&lt;p&gt;This means that without fitting the model to our data, we believe the intercept is 0.437 and the slope is 0.832. Compared to the true values (5 and 2, respectively), this is a very bad model. But that&amp;#8217;s expected; we haven&amp;#8217;t fit the model. How do we use the data to find parameter values that generalize better to the&amp;nbsp;data?&lt;/p&gt;
&lt;p&gt;The basic idea is to measure how bad the current parameter values are, and over many iterations, slowly adjust these parameter values in a better direction. Commonly, this is depicted like a person walking down a mountain in the dark with just a flashlight. The person can&amp;#8217;t see exactly where the bottom of the mountain is, but with their flashlight, they can look around them and move in a direction that takes them down. Sometimes, if the mountain is rocky, they&amp;#8217;ll hit a plateau or even start going uphill again. This is called a &lt;em&gt;local minimum&lt;/em&gt;. They really should get to the &lt;em&gt;global minimum&lt;/em&gt;. How can we prevent hitting local minima and get to the global minima? There&amp;#8217;s no perfect answer, but two answers do come up first: step size (how long are the hiker&amp;#8217;s legs?) and number of iterations (how many steps does the hiker take before they stop walking and throw their hands&amp;nbsp;up?).&lt;/p&gt;
&lt;p&gt;The step size, also called the &lt;em&gt;learning rate&lt;/em&gt;, is usually very small. The smaller it is, the more likely it is the hiker won&amp;#8217;t miss the right trail down; the larger it is, the faster they could reach the bottom, if they don&amp;#8217;t hit a local minima on their way. In our case, we&amp;#8217;ll set our learning rate to 0.01. This was chosen by running the cell a few times with values from 0.1 to 0.00001 and seeing how much progress we made down the mountain (i.e. did we barely move from the randomly set parameter values, or did they overshoot the true&amp;nbsp;model?).&lt;/p&gt;
&lt;p&gt;The number of iterations is somewhat inversely related to our step size. If you don&amp;#8217;t take very big steps, you&amp;#8217;ll need more steps to get to the bottom of the mountain. If you take big steps, you&amp;#8217;ll need fewer. We chose 1000 steps here, found by trial and&amp;nbsp;error.&lt;/p&gt;
&lt;p&gt;How do we decide which direction to step in? By computing the &lt;em&gt;gradient&lt;/em&gt; of the least squares error function. Computing the gradient means taking the partial derivate of a function &lt;span class="math"&gt;\(\mathcal{f}\)&lt;/span&gt; at values &lt;span class="math"&gt;\(p\)&lt;/span&gt;, written as &lt;span class="math"&gt;\(\nabla \mathcal{f}(p)\)&lt;/span&gt;. In our case of least squares errors, &lt;span class="math"&gt;\(\mathcal{f}(p) = \mathcal{f}(\beta) = \sum_{i=0}^N E_i(\beta)\)&lt;/span&gt; where &lt;span class="math"&gt;\(E_i(\beta)\)&lt;/span&gt; is the error of our model at the &lt;span class="math"&gt;\(i\)&lt;/span&gt; observation given the parameters &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In notation, we have the least squares error function,&amp;nbsp;and &lt;/p&gt;
&lt;div class="math"&gt;$$
\mathcal{f}(\beta) = \sum_{i=0}^N (y_i - \beta \, X_i)^2
$$&lt;/div&gt;
&lt;p&gt;The gradient with respect to &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; (our only parameter)&amp;nbsp;is&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
\nabla_\beta \; \mathcal{f}(\beta) &amp;amp;= \frac{\partial}{\partial \beta} \; \mathcal{f} \\
&amp;amp;= \sum_{i=0}^N 2(y_i - \beta \, X_i)(-X_i) \\
&amp;amp;= -2 \sum_{i=0}^N (y_i - \hat{y_i})(X_i) \\
&amp;amp;= -2 \sum_{i=0}^N r_i X_i \\
&amp;amp;= -2 \, X^T \, \boldsymbol{r}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(r_i\)&lt;/span&gt; is the residual value for the &lt;span class="math"&gt;\(i\)&lt;/span&gt;th observation. We can then scale this down according to our step size and subtract it from our current parameter values to move in the &amp;#8220;downhill&amp;#8221;&amp;nbsp;direction.&lt;/p&gt;
&lt;p&gt;We would write this&amp;nbsp;like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;beta_hat_copy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;beta_hat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;

&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gradient&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;beta_hat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[]}&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;residuals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_mtx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta_hat_copy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gradient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_mtx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;residuals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;beta_hat_copy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;beta_hat_copy&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gradient&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;beta_hat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;beta_hat_copy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean_squared_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;beta_hat_copy&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;beta_hat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
[4.898, 2.244]
&lt;/pre&gt;

&lt;p&gt;And then we can plot the altitude of our hiker as they traversed down the&amp;nbsp;mountain&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MSE:&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Iteration&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Mean Squared Error&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
MSE:     0.163

&lt;img src="/images/regression-fig5.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;As you can see, gradient descent looks like it found the bottom of the mountain! The final parameter values it determined were &lt;span class="math"&gt;\(\alpha = 4.898\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta = 2.244\)&lt;/span&gt;, which is close to the true values of 5 and&amp;nbsp;2.&lt;/p&gt;
&lt;p&gt;How does the fitted model look compared to our sample and true data generation&amp;nbsp;line?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;xp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;k&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;--&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Truth&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;beta_hat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]),&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Estimated&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;upper left&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
    &lt;img src="/images/regression-fig6.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;Not too bad, given the low number of&amp;nbsp;observations.&lt;/p&gt;
&lt;p&gt;Although this is intuitive, researchers have developed far more efficient and less problematic methods for large datasets and models with many parameters. Gradient descent can &lt;a href="https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution"&gt;out-perform least squares&lt;/a&gt; in a number of situations, which is part of the reason why I included it here. Bonus concept: this is essentially the backdown of most modern &lt;span class="caps"&gt;AI&lt;/span&gt;, being a critical ingredient of neural networks and forming &lt;a href="https://brilliant.org/wiki/backpropagation/"&gt;the workhorse of backpropogation&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Bayes&lt;/h3&gt;
&lt;p&gt;The third and last method of parameter estimation I&amp;#8217;ll talk about is the Bayesian&amp;nbsp;form.&lt;/p&gt;
&lt;p&gt;Unlike the past two models, Bayesian estimation puts a lot more emphasis on building the right model. This includes the distributions of parameters and the way they relate, which in frequentist linear regression seems typically taught as assumed or&amp;nbsp;given.&lt;/p&gt;
&lt;p&gt;A Bayesian linear model has two to three key components: the outcome distribution, the linear model, and if necessary, the variance parameter. In some linear models, the last two are combined. For example, in a Poisson regression there&amp;#8217;s only a single parameter, &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;, whereas in a Gaussian regression there&amp;#8217;re both &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The first component though is the outcome distribution. If we&amp;#8217;re modeling a phenomenon that is real-valued and continuous, and tends to not be too skewed or dispersed, then a Gaussian outcome distribution might be a good first attempt. If we&amp;#8217;re modeling a phenomenon that consists of positive, integer count data, then a Poisson distribution might be most appropriate. There are a plethora of options here, but we&amp;#8217;ll stick with the Gaussian&amp;nbsp;example.&lt;/p&gt;
&lt;p&gt;The Gaussian distribution is parameterized by &lt;span class="math"&gt;\(\mathcal{N}(\mu, \sigma)\)&lt;/span&gt;. Instead of finding the one value that maximizes some function for both of these parameters, we&amp;#8217;ll consider each of these parameters as functions of other values &lt;sup class="uk-link" uk-tooltip="I recognize this is confusing, put another way, these mu and sigma values are not computed directly, and they're not even values. They're distributions, and we compute them through other, more descriptive parameters."&gt;✳︎&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s called a linear model because in this case, we&amp;#8217;ll define &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; as the &lt;strong&gt;function of a linear combination of other parameters&lt;/strong&gt;. For example, we might say &lt;span class="math"&gt;\(\mu = 5\)&lt;/span&gt;. This is a linear combination of exactly one value and a terrible model because it always will predict something around the value 5. We could add a parameter though, and fit the parameter to the data, like &lt;span class="math"&gt;\(\mu = \alpha\)&lt;/span&gt;. Then with &lt;em&gt;only&lt;/em&gt; our outcome data we&amp;#8217;d figure out what &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; could be. But if we want to use other data to predict our outcome, we need to include that, like &lt;span class="math"&gt;\(\mu = \alpha + \beta \, X\)&lt;/span&gt;. Now we have two parameters to fit, and our new one will be fit so as to reflect the relationship between our outcome and &lt;span class="math"&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As you can see though, &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; is just a linear combination. In other models, like the Poisson or a binomial/logistic, we&amp;#8217;d need to transform &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; so that it lines up with what the outcome distribution expects for parameters. For example, in the binomial model we&amp;#8217;d need &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; to be a probability, which wouldn&amp;#8217;t line up if we just let it vary as high or low as &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;, &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;, and &lt;span class="math"&gt;\(X\)&lt;/span&gt; want it to go. Therefore we&amp;#8217;d need a &lt;a href="https://en.wikipedia.org/wiki/Logit"&gt;logit function&lt;/a&gt; to constrain those values back to the model parameter&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;But what are &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;? They are parameters we must estimate. How? By letting them reflect certain distributions. Which distributions? Well, we must consider what values these parameters can take on. What&amp;#8217;s reasonable given our problem? Let&amp;#8217;s say we know from theory that our data very rarely exceed -50 or 50. That means if there&amp;#8217;s no relationship between our outcome and &lt;span class="math"&gt;\(X\)&lt;/span&gt;, we might expect &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; to be approximated by &lt;span class="math"&gt;\(\mathcal{N}(0, 20)\)&lt;/span&gt;. Why 20? In a normal distribution with mean 0, there&amp;#8217;s about 99% of the density between -50 and 50 with a standard deviation of 20. What about &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; though? Suppose we don&amp;#8217;t expect the rate of change between &lt;span class="math"&gt;\(X\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; to be more than 5 units. So if &lt;span class="math"&gt;\(X\)&lt;/span&gt; increases by 1 unit, we shouldn&amp;#8217;t expect &lt;span class="math"&gt;\(y\)&lt;/span&gt; to increase by more than 5 or decrease by more than -5. Therefore, &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; may be approximated by &lt;span class="math"&gt;\(\mathcal{N}(0, 2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The other component we know of is &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;. We don&amp;#8217;t really think &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; will vary with any data, so we can represent &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; as a value or a space of values (a distribution). For example, in &lt;span class="math"&gt;\(\mathcal{N}(\mu, \sigma)\)&lt;/span&gt; we could say &lt;span class="math"&gt;\(\sigma=2\)&lt;/span&gt; if we knew that the variance of the Gaussian was 2, or we could say &lt;span class="math"&gt;\(\sigma \sim \text{Exp}(1)\)&lt;/span&gt;, as in &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; reflects values from an exponential distribution with rate&amp;nbsp;1.&lt;/p&gt;
&lt;p&gt;Bringing it all together, we can write out our linear model like&amp;nbsp;so
&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
y &amp;amp; \sim \mathcal{N}(\mu, \sigma)\\
\mu &amp;amp; = \alpha + \beta X\\
\alpha &amp;amp; \sim \mathcal{N}(0, 20)\\
\beta &amp;amp; \sim \mathcal{N}(0, 2)\\
\sigma &amp;amp; \sim \text{Exp}(1)
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;At the end of the day though, enough data will allow this model to fit very well and the distributions we used for &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;, &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; will get washed out by the data. In other words, their only function will be to constrain the shape of the parameter, not necessary its&amp;nbsp;values.&lt;/p&gt;
&lt;p&gt;What does this model look like in&amp;nbsp;code?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;alpha&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;beta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HalfNormal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;sigma&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;mu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="nd"&gt;@beta&lt;/span&gt;
    &lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;y_pred&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;observed&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;posterior&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;chains&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_inferencedata&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Running this cell fits the model and its parameters to the data. The model works by guessing random numbers in a related sequence for the parameters. As it guesses these numbers, it starts to figure out what the space of the parameter distribution looks like, or what the most likely numbers are in the distribution if you were to pull from it at&amp;nbsp;random.&lt;/p&gt;
&lt;p&gt;If we pull out the parameters, you&amp;#8217;ll find that they&amp;#8217;re each actually a vector. This is that set of numbers the model guessed and identified as best representative of the distribution. It contains the sampling noise that comes with observing a natural phenomenon. Everything is a little noisy after&amp;nbsp;all.&lt;/p&gt;
&lt;p&gt;If we want to get just one number for our parameters, we can take the mean of the parameter&amp;nbsp;vectors:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
[5.207, 1.734, 0.431]
&lt;/pre&gt;

&lt;p&gt;In other words, the model believes &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; is centered around 5.2, &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; around 1.7, and our variance around 0.4. Compared to the true values of 5, 2, and 0.5, this is not bad given only 20&amp;nbsp;observations.&lt;/p&gt;
&lt;p&gt;Another way to see what the model found is by plotting the distributions of the parameters. Here they are with the &lt;em&gt;mode&lt;/em&gt; of the distribution overlaid in black. I picked the mode because this is then the &lt;a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation"&gt;Maximum a Posteriori estimate&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;layout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tight&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Estimated Parameter Values&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lightblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vlines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;110&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Posterior alpha values&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lightblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vlines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;110&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Posterior beta values&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lightblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vlines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;110&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Posterior sigma values&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
    &lt;img src="/images/regression-fig7.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;This may be confusing because compared to our previous two methods of parameter estimation where we had a single estimate for each parameter, now we see a histogram for each. Like I said, this is because a Bayesian model determines the values of parameters through random sampling. There was no random sampling in Least Squares and Gradient Descent. Because of the random sampling, we never know the exact values. This is unhelpful conceptually, but practically it provides us with concrete and sane estimates of &lt;em&gt;uncertainty&lt;/em&gt;. Now we can compute the single parameter values using the mean, median, or mode; and we can also easily compute how accurate those measures&amp;nbsp;are.&lt;/p&gt;
&lt;p&gt;Don&amp;#8217;t let the histograms make you believe anything conceptually different is happening: we&amp;#8217;re still figuring out what the parameters should be, now we just have more information about&amp;nbsp;each.&lt;/p&gt;
&lt;h4&gt;Measuring&amp;nbsp;Error&lt;/h4&gt;
&lt;p&gt;We&amp;#8217;ve estimated the parameters using Bayes and random sampling, and just like the previous two sections, we&amp;#8217;d like to measure the error of the model and see how closely it matched the true data&amp;nbsp;generator.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;re going to do this a little different to get more utility out of the Bayesian&amp;nbsp;framework.&lt;/p&gt;
&lt;p&gt;For each point, we can calculate the &lt;em&gt;posterior predictive outcome&lt;/em&gt;. An outcome like this is what the model believes the outcome could be knowing the (un)certainty of the outcomes to begin&amp;nbsp;with.&lt;/p&gt;
&lt;p&gt;The posterior predictive accounts for all the uncertainty in &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;, &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; to produce a distribution &lt;em&gt;for each observation&lt;/em&gt;. The uncertainty in the distributions get propogated through the linear model and into the outcome distribution. Through this propogation of uncertainty, each of our 20 observations can be given a distribution. This distribution says, &amp;#8220;Given a predictor value for the model, here are roughly the most likely outcomes values of that&amp;nbsp;predictor.&amp;#8221;&lt;/p&gt;
&lt;p&gt;In the following code chunk, we sample and compute the posterior predictive values for each observed predictor. This produces a matrix of 20 observations and many possible outcomes for each observation. We take the 95% interval of each of those points (plus the median), and plot the median point and credible intervals around each&amp;nbsp;point.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;post_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample_posterior_predictive&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;posterior&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zorder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quantile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;post_pred&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;y_pred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;zorder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;#2777b4&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;y_i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;point&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;post_pred&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;y_pred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;q025&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quantile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.025&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;q975&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quantile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.975&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;q050&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quantile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;point&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vlines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q025&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q975&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linewidth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zorder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;True y value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Posterior predicted value&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;suptitle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Posterior predicted values&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;with 95&lt;/span&gt;&lt;span class="si"&gt;% c&lt;/span&gt;&lt;span class="s2"&gt;redible intervals&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
    &lt;img src="/images/regression-fig8.svg" uk-svg &gt;
&lt;/pre&gt;

&lt;p&gt;This is arguably the most interesting plot of the entire article! Here we see on the x-axis the true data generator value. On the y-axis is the posterior predictive outcome. Each point is what the model believes the outcome should be for that observation&amp;#8217;s predictors (which we don&amp;#8217;t see anything of in this plot). And then for each point there&amp;#8217;s also a representation of the uncertainty of that estimate. The estimate can be interpreted as saying, this observation&amp;#8217;s outcome is most likely to be this red point, but there&amp;#8217;s a 95% probability it falls somewhere in the line range.&amp;#8221; This is of course dependent on the model (so really, there&amp;#8217;s a 95% probability &lt;em&gt;given this model&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;A perfectly accurate model would have all the blue points exactly on the dashed line. A perfectly precise model would have very small error bars. A perfectly accurate and precise model would have the blue poitns right on the line and very small error&amp;nbsp;bars.&lt;/p&gt;
&lt;p&gt;We see all the error bars include the line at some point, which signals this model seems to be doing pretty&amp;nbsp;good!&lt;/p&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;We&amp;#8217;ve gone over three (really four) methods for estimating the parameters of a linear regression model. We had the least squares method (both formulated through algabra and matrices), gradient descent, and a Bayesian method. It&amp;#8217;s also possible to think of estimating linear regression parameters using &lt;a href="https://kaomorphism.com/socraticregression/ols.html"&gt;geometry&lt;/a&gt; and &lt;a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L02%20Linear%20Regression.pdf"&gt;calculus&lt;/a&gt;. Not too mention the many methods of regularization, like &lt;a href="https://en.wikipedia.org/wiki/Linear_regression#Maximum-likelihood_estimation_and_related_techniques"&gt;&lt;span class="caps"&gt;LASSO&lt;/span&gt; and ridge regression&lt;/a&gt;, and &lt;a href="https://en.wikipedia.org/wiki/Linear_regression#Other_estimation_techniques"&gt;robust estimation&lt;/a&gt;. This is all to say that linear regression is a topic with great complexity, making it a daunting, mysterious, and fruitful concept for data-folk to&amp;nbsp;study.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="meta"></category><category term="statistics"></category><category term="python"></category></entry><entry><title>2022 Site Redesign</title><link href="/posts/2022/Feb/site-redesign/" rel="alternate"></link><published>2022-02-20T00:00:00-08:00</published><updated>2022-02-20T00:00:00-08:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2022-02-20:/posts/2022/Feb/site-redesign/</id><summary type="html">&lt;p&gt;Redesigning and redeveloping my personal&amp;nbsp;site&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve set out on redesigning my personal site. Why? I find Jekyll fairly picky, unstable, and hard to work with. Moreover, in using the Jekyll theme that I was (&lt;a href="https://github.com/alshedivat/al-folio"&gt;al-folio&lt;/a&gt;), I found that to also be unstable, hard to keep up to date, and kind of clunky. I appreciate all the people that went in to building both of these tools, but neither has really served me as well as I had once hoped they&amp;nbsp;would.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s time to not only rework the site generation process, but to update the look of my site to better reflect how I feel and what I need to make the best content I&amp;nbsp;can.&lt;/p&gt;
&lt;p&gt;I was actually inspired to do this by the typographer &lt;a href="Miklós Tótfalusi Kis"&gt;Miklós Tótfalusi Kis&lt;/a&gt;. His design of the Janson typeface is beautiful and inspiring, and it forced me to reflect deeply on it. I discovered it in a book I recently started reading, &lt;a href="https://en.wikipedia.org/wiki/A_Garden_of_Earthly_Delights"&gt;A Garden of Earthly Delights&lt;/a&gt; by Joyce Carol Oates, in which it is the typefont the book is set&amp;nbsp;in.&lt;/p&gt;
&lt;p&gt;So I&amp;#8217;ve embarked on redesigning my site in a way that resembles this spacing, consistency, sophistication, freedom, and&amp;nbsp;elegance.&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;I started out with the simple theme from &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;, a Python static site generator. I pruned back the Pelican dependencies in the source &amp;#8212; the custom classes, specific element IDs, and some &lt;span class="caps"&gt;HTML&lt;/span&gt; that I wasn&amp;#8217;t interested&amp;nbsp;in.&lt;/p&gt;
&lt;p&gt;Then I added &lt;a href="https://getuikit.com/"&gt;&lt;span class="caps"&gt;UI&lt;/span&gt; Kit&lt;/a&gt; to the base template. I chose &lt;span class="caps"&gt;UI&lt;/span&gt; Kit because I recently discovered it as an alternative to Bulma. I really like Bulma, but &lt;span class="caps"&gt;UI&lt;/span&gt; Kit so far has seemed less authortarian in the degree which a site can be built. It also seems to have an impressive range of components and standards for how pieces of a site should be built. In other words, it&amp;#8217;s minimalistic but featureful when you&amp;nbsp;want.&lt;/p&gt;
&lt;p&gt;Although &lt;span class="caps"&gt;UI&lt;/span&gt; Kit seemed promising, I quickly realized how much effort it was going to take to update all of my past articles to the new &lt;span class="caps"&gt;CSS&lt;/span&gt; framework. I try not to let the sunken cost fallacy hold me back, and in this case it seemed worth it to expend that&amp;nbsp;effort.&lt;/p&gt;
&lt;p&gt;I spent some time looking for an appropriate font, and I landed on Lora from Google Fonts. One day I might leap into full realization of Janson by buying that typefont, but for now, a free font allows me to prototype and iterate&amp;nbsp;quickly.&lt;/p&gt;
&lt;p&gt;I then took some time to figure out the code highlighting features of Pelican. While there is inline code, like &lt;code&gt;print("text")&lt;/code&gt;, I still haven&amp;#8217;t figured out how to get syntax highting for these inline snippets. However, there is beautiful looking code block highlighting. For example, some&amp;nbsp;Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Pelican is a static site generator.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and also&amp;nbsp;R:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;    &lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.character&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1L&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I knew that I would want to write some articles in a Jupyter notebook style, with code blocks and associated outcomes. So I built a custom &lt;span class="caps"&gt;CSS&lt;/span&gt; solution which attaches an output block to any given code block, like&amp;nbsp;so,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hello world&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="code-output"&gt;
hello world
&lt;/pre&gt;

&lt;p&gt;I snagged this Pygment Github theme from the Pelican theme &lt;a href="https://github.com/arulrajnet/attila"&gt;attila&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s also important to me that there&amp;#8217;s &lt;span class="math"&gt;\(\LaTeX\)&lt;/span&gt; support, of which there is, both inline &lt;span class="math"&gt;\(y \sim N(0, 1)\)&lt;/span&gt; and&amp;nbsp;block:&lt;/p&gt;
&lt;div class="math"&gt;$$
y = \beta_0 + \beta_1 x
$$&lt;/div&gt;
&lt;p&gt;In order to render this Mathjax though I had to install the &lt;code&gt;pelican-render-math&lt;/code&gt; plugin.&lt;/p&gt;
&lt;p&gt;I realized that reStructredText files, which are common in the Pelican world, are unfamiliar and difficult to use. For example, the syntax between Markdown and &lt;span class="caps"&gt;RST&lt;/span&gt; for a link is wildly different. Everything feels unnatural and forced. But most of all, if I want to port my work over from my last site to this new one, it is easiest if I use Markdown since everything is already written with&amp;nbsp;Markdown.&lt;/p&gt;
&lt;p&gt;Next, I moved on to polishing the article page since that would be a crucial aspect of the site design. I tweaked the width of the page so it&amp;#8217;s about a 2/3 width, which seemed natural to my own eyes. I also justified the text because I think that looks really nice with longer content, almost like one sees in a book. I spent probably too much time figuring out the ideal syntax highlighting stylesheet and making slight modifications to it. For example, I decided that the Github theme was pretty, but its numerals were gray. In contrast, Jupyter Notebooks light them green, which I like better. Therefore I had to get into the stylesheet and update that one span to reflect my&amp;nbsp;tastes.&lt;/p&gt;
&lt;p&gt;I also added a modal for the subscribe form. This only took a few minutes with UIKit&amp;#8217;s built-in &lt;code&gt;uk-modal&lt;/code&gt; classes and Javascript add-on, which is a huge improvement compared to other solutions out there that&amp;#8217;d require custom &lt;span class="caps"&gt;JS&lt;/span&gt; for the click and close&amp;nbsp;events.&lt;/p&gt;
&lt;p&gt;I chose an article header image from Unsplash by &lt;a href="https://unsplash.com/@drew_beamer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"&gt;Drew Beamer&lt;/a&gt;. It took half a dozen tried but I found one with the right texture, energy, and framing that really makes the title&amp;nbsp;pop.&lt;/p&gt;
&lt;p&gt;Then I moved over to the tags. I cleaned up the design of the footer on the index page that lists out the tags for quick navigation. I also cleaned up the individual tag page, removing some of the things that the default page had put in. Overall, I&amp;#8217;m still not 100% satisfied. Some sort of abaility for the user to rank by number of articles or another heuristic would be ideal. For now though it will stay as a static alphabetical&amp;nbsp;list.&lt;/p&gt;
&lt;p&gt;I wanted to embed readers comments on the blog too because it seems like, for those who don&amp;#8217;t troll, it can be a useful way to quickly and easily give feedback and, well, comments. For some reason it seems like adding a comments section takes my site to a different realm, like adding this level of dynamic interface is breaking the flow or consistency. I found &lt;a href="https://shahayush.com/2020/05/web-pelican-pt5-disqus-analytics/"&gt;a quick guide&lt;/a&gt; which I gave a look, and then went to sign up for Disqus. Turns out, Disqus sucks. It&amp;#8217;s extremely unpleasant to look at. It&amp;#8217;s slow to load. It makes no commitment to privacy and overall seems nefarious. To top it all off, it&amp;#8217;s got ads galore. I was hopeful yet was disappointed by their complete lack of innovation, simplicity, and respect. I spent a little more time looking for an alternative service, but I&amp;#8217;m not ready to spend money on something I&amp;#8217;m not even sure will have success. In an ideal world, there&amp;#8217;d be a service which had a free tier for sites with less than 1,000 or 10,000 monthly views, and paid tiers for anything above. I would sign up for this knowing that I could use the service while it suited my needs and easily upgrade when I knew it&amp;#8217;d be a worthwhile invest. I think this would also be a good business model because at the point where a site owner wants to upgrade, they&amp;#8217;ve already invested their engineering and social capital into the platform and (if they are looking to upgrade) are very familiar with the effectiveness of the&amp;nbsp;service.&lt;/p&gt;
&lt;p&gt;After getting these elements to a comfortable spot, I&amp;#8217;m fairly content with how the site looks and feels right now. From my perspective, it&amp;#8217;s crisp, smooth, and elegant, just like&amp;nbsp;Janson.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve made a couple other tweaks, but have now been drafting with the design for a few weeks and haven&amp;#8217;t gotten tired by the look yet. I take this to be a good sign. It&amp;#8217;s a little rough around the edges (e.g. things like the copyright page and my resources page), but it&amp;#8217;s in the right direction and an improvement over my previous site&amp;#8217;s&amp;nbsp;theme.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="meta"></category><category term="blogging"></category><category term="design"></category><category term="programming"></category></entry><entry><title>Deploying a containerized Heroku app with Apple’s M1 processor</title><link href="/posts/2021/Nov/deploying-heroku-app/" rel="alternate"></link><published>2021-11-19T00:00:00-08:00</published><updated>2021-11-19T00:00:00-08:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2021-11-19:/posts/2021/Nov/deploying-heroku-app/</id><summary type="html">&lt;p&gt;The M1 is fast and furious, but bound to cause&amp;nbsp;headaches&lt;/p&gt;</summary><content type="html">&lt;style &gt;
.file-name {
  color: #bbb;
  font-size: 0.9em;
}
&lt;/style&gt;

&lt;p&gt;It&amp;#8217;s common to want to deploy an app beyond your local machine and onto the web. A plethora of services and platforms now make this easy, compared to what it would have taken 10 or 20 years&amp;nbsp;ago.&lt;/p&gt;
&lt;p&gt;In this article, I&amp;#8217;d like to outline one way to do so. Particularly, building a Python app, using Flask as a back-end server, bundling all the source files together with &lt;a href="https://www.heroku.com/"&gt;Docker&lt;/a&gt;, and deploying on Heroku. To add a twist, we&amp;#8217;re going to do this from a MacBook Pro with an Apple Silicon M1 processor, which demands special treatment in the eyes of&amp;nbsp;Heroku.&lt;/p&gt;
&lt;h2&gt;1. Build your&amp;nbsp;app&lt;/h2&gt;
&lt;p&gt;We&amp;#8217;re going to build a simple site that lands the user on a page, allows them fill out a form, and then shows them their&amp;nbsp;submission.&lt;/p&gt;
&lt;p&gt;To route traffic, handle requests, and serve static content, we&amp;#8217;ll be using &lt;a href="https://flask.palletsprojects.com/"&gt;Flask&lt;/a&gt;. A popular alternative is &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll start with our &lt;span class="caps"&gt;HTML&lt;/span&gt; landing&amp;nbsp;page.&lt;/p&gt;
&lt;div class="file-name"&gt;templates/index.html&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;&amp;lt;!doctype html&amp;gt;&lt;/span&gt;

&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt; &lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;viewport&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;content&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;width=device-width, initial-sclae=1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Example Heroku Deployment&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;description&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;content&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Deploying a containerized Heroku app with Apple&amp;#39;s M1 processor&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Example Heroku Deployment with Apple&amp;#39;s M1 Processor&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;form&lt;/span&gt; &lt;span class="na"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;post&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;label&lt;/span&gt; &lt;span class="na"&gt;for&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Name&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;label&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;name&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;submit&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Submit Form&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;form&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  {% if name_data %}
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h4&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Welcome, {{ name_data }}!&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h4&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  {% endif %}
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This shouldn&amp;#8217;t look alien; it is a simple &lt;span class="caps"&gt;HTML&lt;/span&gt; page with a form that submits by button, through &lt;span class="caps"&gt;POST&lt;/span&gt;, to&amp;nbsp;itself. &lt;/p&gt;
&lt;p&gt;Then we&amp;#8217;ll build our Flask&amp;nbsp;server.&lt;/p&gt;
&lt;div class="file-name"&gt;server.py&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;render_template&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;methods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;index_get&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;render_template&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index.html&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;methods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;POST&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;index_post&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;render_template&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index.html&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;PORT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;0.0.0.0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When the user lands on the page without submitting anything, we just show the form. When the server receives a &lt;span class="caps"&gt;POST&lt;/span&gt; request, we pull out the &lt;em&gt;name&lt;/em&gt; field from the request (assuming it&amp;#8217;s there, but default to &lt;code&gt;''&lt;/code&gt; if not) and display that&amp;nbsp;result.&lt;/p&gt;
&lt;p&gt;We also look for the environment variable, &lt;code&gt;PORT&lt;/code&gt;, which is really &lt;a href="https://blog.heroku.com/python_and_django"&gt;for Heroku&lt;/a&gt;. Heroku will choose and set the port which your app will use. We also set &lt;code&gt;host&lt;/code&gt; to 0.0.0.0 which overrides the default locahost parameter so that the site is &lt;a href="https://stackoverflow.com/q/30323224/3234482"&gt;accessible through Docker&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;2. Test&amp;nbsp;locally&lt;/h2&gt;
&lt;p&gt;To test our web app locally, we can just&amp;nbsp;run,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python server.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This launches our Flask app as a local server on a localhost port, specifically port 5000. Visit the &lt;span class="caps"&gt;URL&lt;/span&gt; &lt;code&gt;127.0.0.1:5000&lt;/code&gt; to&amp;nbsp;test.&lt;/p&gt;
&lt;h2&gt;3. Containerize your&amp;nbsp;app&lt;/h2&gt;
&lt;p&gt;Now that we see our app working locally, we can &lt;a href="https://www.docker.com/blog/containerized-python-development-part-1/"&gt;containerize the app&lt;/a&gt;. By creating a container for our app, Heroku will be faster at deploying (since it won&amp;#8217;t have to rebuild the entire app every deployment), and it will ensure dependencies and architectures are&amp;nbsp;platform-agnostic.&lt;/p&gt;
&lt;p&gt;Or, almost platform-agnostic. I learned the hard way that Docker is particular in certain ways about the host build machine and its architecture. In particular, the architecture of an M1 Mac requires Docker to build apps differently than what Heroku wants to deploy&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;In any case, we need to start with a Dockerfile, so we&amp;#8217;ll do&amp;nbsp;that.&lt;/p&gt;
&lt;p&gt;First, we&amp;#8217;ll be starting from a Python 3.8 image as the base&amp;nbsp;layer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;python:3.8&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We need to install our Python dependencies. This could also be done with a requirements file, but here we just write them&amp;nbsp;out.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pip install flask
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We need to copy our &lt;span class="caps"&gt;HTML&lt;/span&gt; and Python source files into the&amp;nbsp;image.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;. .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Flask expects to host the server through an open port, so we&amp;#8217;ll expose a port just for&amp;nbsp;Flask.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;EXPOSE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;$PORT&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Lastly, the launch command when we run the image as a container is to launch the server. We&amp;#8217;ll bring it all together here&amp;nbsp;now,&lt;/p&gt;
&lt;div class="file-name"&gt;Dockerfile&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;python:3.8&lt;/span&gt;

&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pip install flask

&lt;span class="k"&gt;COPY&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;. .

&lt;span class="k"&gt;EXPOSE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;$PORT&lt;/span&gt;

&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;python&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;server.py&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For more of this process, see the &lt;a href="https://devcenter.heroku.com/articles/container-registry-and-runtime"&gt;documentation&lt;/a&gt;. Now we need to build the image. Typically, we&amp;#8217;d&amp;nbsp;see,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker build . -t example-app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;but because we&amp;#8217;re working on a different architecture, we actually&amp;nbsp;need,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker buildx build --platform linux/amd64 -t example-app .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;buildx&lt;/code&gt; allows the devloper to, among other things, build an image to run cross-platform. This is important to us since our source machine, an Apple M1 device, is a different architecture (&lt;code&gt;arm64&lt;/code&gt;) than the destination machine (&lt;code&gt;amd64&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Now that we have it setup with the right architecture, we can test the image locally by building a container. For&amp;nbsp;example,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker run --rm -e &lt;span class="nv"&gt;PORT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5000&lt;/span&gt; -p &lt;span class="m"&gt;5000&lt;/span&gt;:5000 example-app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To break down the arguments here: &lt;code&gt;--rm&lt;/code&gt; removes the container from the running container list once it exits, &lt;code&gt;-e PORT=5000&lt;/code&gt; sets our port environment variable, and &lt;code&gt;-p 5000:5000&lt;/code&gt; opens the port 5000 within the container to the host machine&amp;#8217;s port 5000. The last argument is the name of our image to&amp;nbsp;run.&lt;/p&gt;
&lt;p&gt;Now we can visit the exposed port (&lt;code&gt;127.0.0.1:5000/&lt;/code&gt;) and see our app live,&amp;nbsp;locally.&lt;/p&gt;
&lt;h2&gt;4. Push to&amp;nbsp;Heroku&lt;/h2&gt;
&lt;p&gt;First, we need to create a Heroku account. After that&amp;#8217;s been setup, create an app with any name you want, say &lt;code&gt;example-heroku-deployment&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll be deploying to the Heroku registry manually, but we still will use the Heroku &lt;span class="caps"&gt;CLI&lt;/span&gt; for some parts, so make sure that&amp;#8217;s &lt;a href="https://devcenter.heroku.com/articles/heroku-cli#download-and-install"&gt;installed&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll authenticate Heroku from the command line, make sure Docker is &lt;a href="https://docs.docker.com/get-docker/"&gt;installed&lt;/a&gt;, and login to the Heroku Container&amp;nbsp;Registry,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;heroku login
docker ps
heroku container:login
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we want to retag our image with the location of our Heroku app registry. For example, if we run &lt;code&gt;docker images&lt;/code&gt;, we can view the image &lt;span class="caps"&gt;ID&lt;/span&gt; of the image we just built for &lt;code&gt;example-app&lt;/code&gt;. In order to get our local image to the right place in the Heroku Registry, we need to label it&amp;nbsp;correctly,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker tag xxxxxxxxxxxx registry.heroku.com/example-heroku-deployment/web
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;where the image &lt;span class="caps"&gt;ID&lt;/span&gt; is copy and pasted from the &lt;code&gt;docker images&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Next we want to manually push the image to the Registry,&amp;nbsp;like,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker push registry.heroku.com/example-heroku-deployment/web
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now our app is pushed up to Heroku, and we just need to tell Heroku to take the image&amp;nbsp;live!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;heroku container:release web -a example-heroku-deployment
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To open your app, try &lt;code&gt;heroku open -a example-heroku-deployment&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;5. Wrap&amp;nbsp;up&lt;/h2&gt;
&lt;p&gt;You should be seeing your site live at &lt;em&gt;example-heroku-deployment.heroku.com&lt;/em&gt; (or whatever you named your app as, followed by &lt;em&gt;heroku.com&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;A troubleshooting appendix should come&amp;nbsp;soon!&lt;/p&gt;
&lt;!-- # Troubleshooting

## 1. Heroku H10 error

Notorious! --&gt;</content><category term="meta"></category><category term="programming"></category><category term="docker"></category><category term="python"></category></entry><entry><title>Del v. Amazon</title><link href="/posts/2021/Jul/del-v-amazon/" rel="alternate"></link><published>2021-07-16T00:00:00-07:00</published><updated>2021-07-16T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2021-07-16:/posts/2021/Jul/del-v-amazon/</id><summary type="html">&lt;p&gt;The story of my friend Del, and small businesses against&amp;nbsp;Amazon&lt;/p&gt;</summary><content type="html">&lt;p&gt;Del was about 5&amp;#8217; 8&amp;#8221; and wore a black shirt with a black baseball cap. He approached me in Nā Mea, a small store in Honolulu&amp;#8217;s Ward Village that sells Hawaiian and Polynesian art, calendars, clothing, food, jewelry, etc., as I was bent sideways browsing their wall of books. He asked me if I was looking for anything specific. &amp;#8220;Just browsing,&amp;#8221; I said. My mask hid my smile but I hoped that my eyes creased so he would know that I was friendly. His words were lined with enthusiasm and joy, so much so that I was almost suspicious of his&amp;nbsp;motives.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Okay, what do you like to read?&amp;#8221; he probed me. I was intimidated, since I don&amp;#8217;t think there&amp;#8217;s one right answer to a question like that. And what if I say something he doesn&amp;#8217;t&amp;nbsp;like?&lt;/p&gt;
&lt;p&gt;I stammered, &amp;#8220;Just about anything. I thought this book looked interesting.&amp;#8221; I pointed to a small book on their new releases table. &amp;#8220;Do you know anything about it?&amp;#8221; It was titled &lt;em&gt;The Properties of Perpetual Light&lt;/em&gt; and had an attractive&amp;nbsp;cover.&lt;/p&gt;
&lt;p&gt;We went on with this small talk about books for a couple minutes. He suggested a title on another shelf, &lt;em&gt;Shoals of Time&lt;/em&gt; by Gavan Daws. This was far more academic than what I was hoping for. It was also out of my book&amp;nbsp;budget.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;I&amp;#8217;m here on vacation so space in my bag is limited,&amp;#8221; I&amp;nbsp;mourned.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Oh, where are you from?&amp;#8221; he&amp;nbsp;asked.&lt;/p&gt;
&lt;p&gt;At this, I told him of California, my trip to Hawaii, my job, and my travels up til then. He was receptive, and I could tell he was listening carefully by the way he looked at me. Del must have found something special in our short conversation, because he suggested that we stay in&amp;nbsp;touch.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;I should get your phone number. And you can have mine,&amp;#8221; he&amp;nbsp;offered.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Yes, definitely,&amp;#8221; I warmly replied without any definite feeling about where this would go. Then came a&amp;nbsp;surprise.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;I need to finish some work in the back, but do you have time right now? Are you doing anything or have plans?&amp;#8221; he asked. Being on vacation, I didn&amp;#8217;t have any plans for that afternoon and exploring, and I told him&amp;nbsp;so.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Have you had lunch? Would you like to get lunch&amp;nbsp;together?&amp;#8221;&lt;/p&gt;
&lt;p&gt;My stomach was growling and I was already impatient with my inability to choose a book. I agreed quickly to his proposal. I thought this would be a good opportunity to meet a Hawaii native. He could show me show where the locals eat. Del rushed off to the back and came out only a minute later, surprising me again, this time with a business card in his hand. On it he had scribbled his name and phone number. He told me, &amp;#8220;Ok, wait here. 15&amp;nbsp;minutes.&amp;#8221;&lt;/p&gt;
&lt;p&gt;He scurried away, and I continued to peruse the bookshelves. I bought two books and loitered in the store, admiring the carved bone tools, the wooden necklaces, and the hand twisted earrings. Soon enough, Del popped up right beside&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Where do you wanna go?&amp;#8221; he&amp;nbsp;asked.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Anywhere,&amp;#8221; I said, smiling. &amp;#8220;You know the area&amp;nbsp;best.&amp;#8221;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Ok, in here,&amp;#8221; and we walked out into the mall which his store was tucked away&amp;nbsp;in.&lt;/p&gt;
&lt;p&gt;He led the way through the crowded mall, barely giving me enough time to see what it had to offer. He asked me once or twice more what I wanted to eat. I earnestly told him I didn&amp;#8217;t mind, I was hungry and curious where he might take me and what we might discover. He led us through and out, taking us down the street and around the corner. We found a restaurant with a clean and neat patio and a sign that read &amp;#8220;Kitchen and Meatery.&amp;#8221; After we took a seat, I asked, &amp;#8220;How long have you been working at the&amp;nbsp;store?&amp;#8221;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;4 years,&amp;#8221; he said, nodding&amp;nbsp;slowly.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;And before&amp;nbsp;that?&amp;#8221;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;At the other store, in downtown.&amp;#8221; Apparently Nā Mea had two locations, the original and then the one I visited. He told me how the book selection at the other was impressive, and how I&amp;#8217;d like that one more. When I asked him how long he had worked at that store, he thought for a second and said, &amp;#8220;About 29&amp;nbsp;years.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I wasn&amp;#8217;t expecting this loyalty and inertness. I asked him how much the island had changed in the last 30 years. &amp;#8220;A lot,&amp;#8221; he said, nodding even slower this time. I could tell that this was something he could feel within, but hadn&amp;#8217;t spoken about in a long time. As he talked about the changes on O&amp;#8217;ahu, there was a feeling of by-gone times and pernicious tourism, but also a strong appreciation and pride for the growth of one&amp;#8217;s homeland. Del told me he grew up on the island of Hawai&amp;#8217;i, that he never learned to surf, and that now he lived north near the university where he loved to attend the football games. He told me he had once visited San Diego, some 10 years ago, to support the university&amp;#8217;s football team in their game against San Diego State. He told me of the pride and energy he felt when his team scored and the Hawaii section of the stands roared with excitement. He told me about the decline of the sugar cane plantations, like the Waialua mill and its many Japanese and Filipino laborers, and the decline of the Dole pineapple business, and the many Hawaiians in that&amp;nbsp;family.&lt;/p&gt;
&lt;p&gt;He was quick to agree with many things I had to say, and when he didn&amp;#8217;t agree he scrunched his face and shook his head. His accent was dense and difficult to navigate, like the tall brush you wade through in the forests on the north shore. I had to lean in with an ear out to pick up every syllable, most of which he didn&amp;#8217;t seem to care for and would just disappear when he&amp;nbsp;spoke.&lt;/p&gt;
&lt;p&gt;I ate pork belly eggs benedict; he had a grandule rice and eggs plate. When I asked if pork belly was popular (I had heard it was), he said, &amp;#8220;Oh, yes. I have many friends who eat it. I don&amp;#8217;t like it.&amp;#8221; His plate was colorful from all the cumin, curry, and chili powder that had made their way onto it. I noticed that when he ate, he flipped his fork upside-down, held it still, and pushed rice with his knife onto the back of the fork. This was how he brought food to his&amp;nbsp;mouth.&lt;/p&gt;
&lt;p&gt;We talked about my work, his work, his interests, me moving to Berkeley, and his family. When I asked him if he was married, he said &amp;#8220;No&amp;#8230; but I have four kids.&amp;#8221; It must have been easy to notice that I lacked anything to say, so he continued, &amp;#8220;Four cats!&amp;#8221; I still couldn&amp;#8217;t tell if he was joking. He wasn&amp;#8217;t; I learned that to him, those cats are his kids. I loved that when I asked him what he did on the weekends, he said with a gentle smile, &amp;#8220;I get a blanket, go to a beach where only the locals go, bring a book, and just read and enjoy the afternoon under a tree.&amp;#8221; This was my kind of&amp;nbsp;guy.&lt;/p&gt;
&lt;p&gt;Del insisted on buying our lunch. I pushed back but his hospitality and generosity were stubborn. We agreed that I would leave the tip. When we walked out, he burst into a race walk! I told him him I&amp;#8217;d hoped that I hadn&amp;#8217;t made him late back to work. He quickly declined that idea and politely said that he was glad we went out. We rushed back through the hot and humid streets with the sun hitting us hard. At his turn, he rushed to say it was nice to meet me. We fist-bumped, as he was used to doing during &lt;span class="caps"&gt;COVID&lt;/span&gt;. Just as quickly had our day began together did it end. I stood alone on the sidewalk not sure where to go&amp;nbsp;next.&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;Amazon began in 1994 as a bookstore: a story which is now Silicon Valley folk-lore. Humble beginnings; turbulent trajectories; and ultimately, power in ways never before&amp;nbsp;conceived.&lt;/p&gt;
&lt;p&gt;Amazon is no longer a bookstore. Today, its profit largely comes from the healthy margins of Amazon Web&amp;nbsp;Services.&lt;/p&gt;
&lt;p&gt;So if Amazon is no longer a bookstore, what is it? What is it not? These are the same questions for Google, Microsoft, etc. (and it&amp;#8217;s one way they skirt around antitrust laws). Does Amazon add value to society? If so, what kind of value? Is it value that matters for individuals and humankind? Value like memories, friendship, or kindness? In most ways, I think it doesn&amp;#8217;t. Never has Amazon provided me or any other consumer I know with life-long memories or friendship or one of the many other things which Del showed me in our hour together. I also think that this is what makes Del and other small businesses the heart of society, pumping life and blood through our people. Amazon, and generally mega-tech companies, are capillaries: fringe elements of our communal body and spirit, substantiative but irrelevant without the heart. In the worst cases, these companies are behemoth advertising leeches, external to &amp;#8220;us&amp;#8221; and feeding on our blood and offering no nutrients in&amp;nbsp;return.&lt;/p&gt;
&lt;p&gt;That is to say, Del provides in ways that Amazon cannot, and will not. It is not their goal or their function to provide value like Del does. Yet, there remains a place in this universe for both to vie for customers. Amazon is certainly allowed some share of the market. But if Del and Nā Mea go out of business, so does at least 30 years of Hawaiian culture and history bundled into a vibrant hole-in-the-wall shop. And so does any opportunity for interaction as a consumer to be leagues more than a market&amp;nbsp;transaction.&lt;/p&gt;
&lt;p&gt;There are so many beautiful things about small local businesses that to buy from Amazon should only be a last&amp;nbsp;resort.&lt;/p&gt;
&lt;p&gt;When I began putting some of these thoughts on paper, my ideas largely revolved around what made Amazon bad. That list could stretch for long enough, including its poor &lt;a href="http://amazonemancipatory.com/"&gt;labor practices&lt;/a&gt;; its negative effect on &lt;a href="https://www.theatlantic.com/business/archive/2018/02/amazon-warehouses-poor-cities/552020/"&gt;cities and communities&lt;/a&gt;; its negative impact on the &lt;a href="https://link.springer.com/chapter/10.1007/978-3-030-49384-4_6"&gt;environment&lt;/a&gt;; its insidious and gross &lt;a href="https://itep.org/amazon-has-record-breaking-profits-in-2020-avoids-2-3-billion-in-federal-income-taxes/"&gt;tax evasion&lt;/a&gt;; its dangerous and reckless standards for &lt;a href="https://www.nytimes.com/2019/09/05/us/amazon-delivery-drivers-accidents.html"&gt;delivery drivers&lt;/a&gt;; and less tangibly, its influence on the American&amp;nbsp;psyche.&lt;/p&gt;
&lt;p&gt;While these might be true, Amazon also positively contributes to society in dozens of ways. They create jobs and impressive economic opportunities, they create supply competition, lower consumers&amp;#8217; costs, and do in fact sometimes act philanthropically. But we must ask ourselves if the good outweighs the&amp;nbsp;bad.&lt;/p&gt;
&lt;p&gt;Unlike this fine ethical line which Amazon lumbers along, it is rare that a small business does not make up its negative impact with the benefits the community it&amp;#8217;s in reaps. The &lt;a href="https://www.nber.org/system/files/working_papers/w17041/w17041.pdf"&gt;number of ways&lt;/a&gt; which small businesses provide for society is innumerable, and they tend to not be so&amp;nbsp;dubious.&lt;/p&gt;
&lt;p&gt;Although I might be boycotting Amazon, I realize that this is not practical for everyone. What is practical for everyone though is thinking critically about where they choose to spend their income. I believe that supporting folks like Del and businesses like Nā Mea will grow humanity in ways that Amazon, and its quest for other-worldly growth, will never&amp;nbsp;match. &lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
Please visit &lt;a href="https://www.nameahawaii.com/"&gt;Nā Mea online&lt;/a&gt; and support them if you&amp;nbsp;can.&lt;/p&gt;</content><category term="meta"></category><category term="society"></category><category term="critique"></category></entry><entry><title>10 things to consider when buying a dictionary</title><link href="/posts/2021/Jun/disctionaries/" rel="alternate"></link><published>2021-06-05T00:00:00-07:00</published><updated>2021-06-05T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2021-06-05:/posts/2021/Jun/disctionaries/</id><summary type="html">&lt;p&gt;Entries, examples, etymology — oh&amp;nbsp;my!&lt;/p&gt;</summary><content type="html">&lt;!-- readtime: 5.6 --&gt;

&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/1970-ford.jpeg" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;p&gt;Dictionaries, in their physical form, are like typewriters and baby blue 1970 Ford pickups. The hum, the purr, the movement, the tactility of these analog devices engenders an ineffable&amp;nbsp;satisfaction.&lt;/p&gt;
&lt;p&gt;Last week, I drove with my dad to Barnes &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Noble. Normally, I’d prefer a hole-in-the-wall, independent bookstore, but I was craving a well-edited, cleanly bound, beautifully printed dictionary. I wanted something to hold, to own, to flip through for years or decades. I wanted something trustworthy that wasn’t on a screen. So I bought myself a newly printed &lt;a href="https://global.oup.com/academic/product/concise-oxford-american-dictionary-9780195304848?lang=en&amp;amp;cc=us"&gt;Concise Oxford American Dictionary&lt;/a&gt; (&lt;span class="caps"&gt;COAD&lt;/span&gt;). What a work of&amp;nbsp;lexicography!&lt;/p&gt;
&lt;p&gt;This article is a guide to buying a dictionary. I’ll mention some characteristics which differentiate dictionaries, and weigh in with my opinion and my rationale. I’m hoping it will help any young person who wants to feel those feathery light pages flip around and the unparalleled satisfaction of homing in on a word like it’s a lost&amp;nbsp;treasure.&lt;/p&gt;
&lt;p&gt;I doubt any previous generation was told how to buy a dictionary. Yet, many grew up with one, used one at school, or even saw them in pop culture. When they needed a dictionary, traditional or intuition probably got them most of the way. Us youngin’s didn’t get this experience, instead we got cellphones and iPods; which isn’t a terrible&amp;nbsp;trade-off.&lt;/p&gt;
&lt;h2&gt;Characteristics of a&amp;nbsp;Dictionary&lt;/h2&gt;
&lt;p&gt;In alphabetical&amp;nbsp;order:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Definitions&lt;/p&gt;
&lt;p&gt;Coincidentally, the most important characteristic of a dictionary is first on our list. A dictionary is just a list of words in a language, plus their meanings. It’s important that the list of words is good, but it’d just be a list without those meaty&amp;nbsp;definitions.&lt;/p&gt;
&lt;p&gt;What makes a good definition? This is probably a question people make careers out of, but one reliable measure I have is, how many words in any definition must you subsequently look up? A good definition should be easy to read and easy to understand. It’s not a good dictionary if you don’t understand one, two, half of the words used within the&amp;nbsp;definitions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dialect of&amp;nbsp;English&lt;/p&gt;
&lt;p&gt;You might remember I bought myself an Oxford &lt;em&gt;American&lt;/em&gt; Dictionary. There are dictionaries for British, Australian, and even Canadian English. Having traveled to Canada a few times, I can’t think of a good reason why Canadian English has its own dictionary, yet cowboys from the south don’t have&amp;nbsp;theirs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Etymology&lt;/p&gt;
&lt;p&gt;It is sometimes helpful to know where a word comes from. Is it Latin? Greek? French? What are the roots of the word? This wasn’t a top priority for me, but it might be for you. Some dictionaries offer none of this information; others are in fact, &lt;a href="https://en.wikipedia.org/wiki/Etymological_dictionary"&gt;etymological dictionaries&lt;/a&gt; with nothing &lt;em&gt;but&lt;/em&gt; roots. Find your&amp;nbsp;balance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Examples&lt;/p&gt;
&lt;p&gt;Most dictionaries that aren’t squeezed for size contain example sentences for meanings. In the &lt;span class="caps"&gt;COAD&lt;/span&gt;, perhaps every third or fourth word has a brief example sentence to demonstrate how the word is used in context. Consider how much this would help you learn and&amp;nbsp;understand.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Number of&amp;nbsp;Entries&lt;/p&gt;
&lt;p&gt;Would you prefer a dictionary of only the 20,000 most common words? Or, a &lt;a href="https://global.oup.com/academic/product/the-oxford-english-dictionary-9780198611868?cc=us&amp;amp;lang=en&amp;amp;"&gt;20 volume, 500,000 entry tome&lt;/a&gt;? Most of us fall somewhere in between. The &lt;span class="caps"&gt;COAD&lt;/span&gt; contains about 180,000 entries and so far that has been more than&amp;nbsp;enough.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pictures&lt;/p&gt;
&lt;p&gt;Are you a visual learner? If so, consider the breadth of pictures and illustrations in your dictionary. They can be helpful to visualize, for example, a &lt;a href="https://en.wikipedia.org/wiki/Fez_(hat)"&gt;fez&lt;/a&gt; or a &lt;a href="https://en.wikipedia.org/wiki/Wimple"&gt;wimple&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pronunciation&amp;nbsp;Method&lt;/p&gt;
&lt;p&gt;Odds are, when you find, or just stumble onto, a word, you’ll want to know how to pronounce it. There is a spectrum of ways editorial teams convey this information. On the one side, there’s the &lt;a href="https://www.internationalphoneticassociation.org/content/full-ipa-chart"&gt;International Phonetic Alphabet&lt;/a&gt; (&lt;span class="caps"&gt;IPA&lt;/span&gt;), a highly unadulterated linguistic method. On the other, there are &lt;a href="https://en.wikipedia.org/wiki/Pronunciation_respelling_for_English"&gt;respelling methods&lt;/a&gt; that only use our recognizable English characters. In between, there are hybrid methods that join the precision and the usability of&amp;nbsp;both.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Publishing&amp;nbsp;Date&lt;/p&gt;
&lt;p&gt;How much do you care about &lt;a href="https://brocku.ca/MeadProject/Sapir/Sapir_1921/Sapir_1921_07.html"&gt;language drift&lt;/a&gt; and &lt;a href="https://public.oed.com/blog/the-oed-march-2021-update/"&gt;contemporary terms&lt;/a&gt;? Some &lt;a href="https://global.oup.com/academic/product/the-oxford-english-dictionary-9780198611868?cc=us&amp;amp;lang=en&amp;amp;"&gt;amazing dictionaries&lt;/a&gt; stopped publication in the 80s or 90s. Despite them being great tools and companions, you might miss out on more up-to-date definitions if you choose to use one of&amp;nbsp;them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reference&amp;nbsp;Material&lt;/p&gt;
&lt;p&gt;At the back of the &lt;span class="caps"&gt;COAD&lt;/span&gt;, there are a few sections of reference. They include commonly misspelled words, clichés to avoid, punctuation guides, and even a list of &lt;span class="caps"&gt;U.S.&lt;/span&gt; states, capitals, and presidents. Do handy guides and language usage advice spark your&amp;nbsp;interest?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sequence of&amp;nbsp;Meanings&lt;/p&gt;
&lt;p&gt;Lastly, it is worth noting that some editorial teams list entry meanings in different orders. Some put the most common meanings first. Others, the first recorded meaning. This is a minor point, but may impact how easy you find the dictionary to&amp;nbsp;use.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The unique properties of dictionaries are by no means a contentious topic, and the number of readers offended by my list is likely zero. Nonetheless, I surely didn’t include one thing or another. What would make me happy though is if I did offend someone through this lapse &lt;em&gt;and&lt;/em&gt; they kindly informed me of what I left&amp;nbsp;off.&lt;/p&gt;
&lt;p&gt;One last tip for buying a dictionary before you go: prepare a shortlist of terms that you’ve recently had to look up. By nature, these words are common enough in your life, and are words you had an interest in defining. When you’re choosing a dictionary, ask yourself, does it contain those words you wrote down? Put another way, had you bought this dictionary in the past, would it have proved itself&amp;nbsp;useful?&lt;/p&gt;
&lt;p&gt;For me, a word I had recently looked up was &lt;em&gt;caftan&lt;/em&gt; (a North African or Near Eastern tunic or robe, usually for men). As it turned out, Webster’s Dictionary didn’t contain the word; the &lt;span class="caps"&gt;COAD&lt;/span&gt;&amp;nbsp;did.&lt;/p&gt;
&lt;p&gt;If you just simply can’t decide what dictionary to choose, I recommend buying your top two choices. Over the course of a few days or weeks, sit down in front of your crackling fireplace and explore the depths and treasures in each. By the time you decide which one truly speaks to your soul, you can gently place the runner-up in your fireplace and continue to enjoy your new favorite dictionary beside a colorful and rejuvenated&amp;nbsp;fire.&lt;/p&gt;</content><category term="meta"></category><category term="language"></category></entry><entry><title>Explainability in Generative Language Models</title><link href="/posts/2021/Apr/explainability-generative-models/" rel="alternate"></link><published>2021-04-19T00:00:00-07:00</published><updated>2021-04-19T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2021-04-19:/posts/2021/Apr/explainability-generative-models/</id><summary type="html">&lt;p&gt;How and why to move toward a future of explainable generative language&amp;nbsp;models&lt;/p&gt;</summary><content type="html">&lt;!-- readtime: 17.0
bibliography: 2021-04-19-explainability-generative-lms.bib --&gt;

&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/spongebob-bubbles.jpg" height="" width="80%" alt="" uk-img&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Natural Language Processing (&lt;span class="caps"&gt;NLP&lt;/span&gt;) models have been gaining popularity like crazy; they&amp;#8217;re getting thrown into a new industry every week. In the last few years of &lt;span class="caps"&gt;NLP&lt;/span&gt;, we&amp;#8217;ve seen the development of &lt;a href="https://en.wikipedia.org/wiki/Language_model"&gt;large language models&lt;/a&gt;, which model the statistical properties of language, and come in two main types: discriminative and generative. The former are useful across text analytics, from classic sentiment analysis to &lt;a href="https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/"&gt;detecting misinformation&lt;/a&gt; on social media platforms. The latter, generative models, have mostly come to light as a result of OpenAI&amp;#8217;s &lt;span class="caps"&gt;GPT&lt;/span&gt;&amp;nbsp;models.&lt;/p&gt;
&lt;p&gt;In a 1999 episode of Spongebob (S1 E4), Spongebob and Patrick are blowing bubbles. Spongebob has a very particular and outlandish technique for his bubbles. At first, his bubbles are simple. Eventually though, Spongebob blows a bubble &lt;em&gt;so&lt;/em&gt; big, it swallows up Squidward&amp;#8217;s Easter Island head house, lifting it high into the sky/sea, and soon popping, thus leaving the home falling back to the floor where it hits the ground at an awkward&amp;nbsp;position.&lt;/p&gt;
&lt;p&gt;In some sense, I think large language models are a bit of a bubble. They&amp;#8217;re literally and figuratively becoming &lt;em&gt;huge&lt;/em&gt; and swallowing up resources, both intellectual and environmental. This article discusses their explosive growth, the dangers of them bursting, and explainability methods to help dampen the near-inevitable pain they will cause down the&amp;nbsp;line.&lt;/p&gt;
&lt;details&gt;
&lt;summary class="detail-selector detail-level1"&gt;What are language models, and &lt;span class="caps"&gt;GPT&lt;/span&gt;-*?&lt;/summary&gt;

From &lt;a href="https://liebscher.github.io/blog/2020/evaluating-neural-toxic-degeneration/"&gt;a previous article of mine&lt;/a&gt; reviewing an article on degenerate model behavior:

&lt;br&gt;&lt;br&gt;

&lt;blockquote&gt;In plain English, a Language Model scans huge collections of documents (millions of documents), word by word, learning statistical associations between words and their neighbors, and is then able to predict the next word in a phrase by just looking for the most probable in the English language. Your iPhone does this (if you have predictive typing turned on), as does Gmail when you&amp;#8217;re drafting an email, and a suite of other tools.&lt;/blockquote&gt;

&lt;br&gt;&lt;br&gt;

&lt;/details&gt;

&lt;p&gt;In our inconcievably digital world, we&amp;#8217;re seeing an increasingly pressing need to understand the outputs these models produce&lt;d-footnote&gt;I just started reading &lt;a href="https://brianchristian.org/the-alignment-problem/"&gt;The Alignment Problem&lt;/a&gt; by Brian Christian, which I anticipate to elaborate on the divergence between our value-based intentions and machine learning.&lt;/d-footnote&gt;. Discriminative &lt;span class="caps"&gt;NLP&lt;/span&gt; models have so far attracted more attention from researchers seeking ways to interpret and explain them. Methods for interpreting and explaining the results of generative &lt;span class="caps"&gt;NLP&lt;/span&gt; models are getting left in the&amp;nbsp;dust.&lt;/p&gt;
&lt;p&gt;Given that these types of generative language models have really only been around for a few years, it might sound like I&amp;#8217;m being impatient or ignorant of the difficulty of establishing explainability. Especially since the outputs of a generative model are influenced by a suite of factors, including at&amp;nbsp;least:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model&amp;nbsp;architecture&lt;/li&gt;
&lt;li&gt;Training data (if&amp;nbsp;applicable)&lt;/li&gt;
&lt;li&gt;Testing data (if&amp;nbsp;applicable)&lt;/li&gt;
&lt;li&gt;Quality assurance process (or lack&amp;nbsp;thereof)&lt;/li&gt;
&lt;li&gt;Designing engineers and&amp;nbsp;researchers&lt;/li&gt;
&lt;li&gt;Motivations for&amp;nbsp;development&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given such complex and multi-faceted influences, it&amp;#8217;s no easy ask of the field. As I&amp;#8217;ll soon explain though, it is all but necessary that when these models behave poorly, we have some method for explaining&amp;nbsp;why.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/figma-explainability.png" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Figure 1. Modern generative language models are trained to predict the next word in a text sequence. After training on billions of words, the model tends to be able to produce comprehensible text. If it produces something wrong though, we have no good way of explaining these mistakes. This is very unlike asking a human to explain what they&amp;#8217;ve said, which usually has satisfactory results.
&lt;/div&gt;

&lt;p&gt;Knowing how important it is that progress in this area of &lt;span class="caps"&gt;NLP&lt;/span&gt; be made, I&amp;#8217;m laying out this article to discuss: why it matters so much that we be able to explain generative language models, existing work on this question and similar ones, and future directions that we might take. That said, let me introduce why explainability matters for these generative&amp;nbsp;models.&lt;/p&gt;
&lt;h2&gt;Why does it&amp;nbsp;matter?&lt;/h2&gt;
&lt;h3&gt;Ubiquity&lt;/h3&gt;
&lt;div class="epigraph"&gt;
&lt;p&gt;&lt;i&gt;By the late twentieth century, our time, a mythic time, we are all chimeras, theorized and fabricated hybrids of machine and organism; in short, we are&amp;nbsp;cyborgs.&lt;/i&gt;&lt;/p&gt;
&lt;p class="tab"&gt;&amp;mdash;Donna Haraway, &lt;i&gt;A Manifesto for Cyborgs: Science, Technology, and Socialist Feminism in the&amp;nbsp;1980s&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="epigraph"&gt;
&lt;p&gt;&lt;i&gt;I have no desire to suffer twice, in reality and then in&amp;nbsp;retrospect.&lt;/i&gt;&lt;/p&gt;
&lt;p class="tab"&gt;&amp;mdash;Sophocles, &lt;i&gt;Oedipus&amp;nbsp;Rex&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href="https://openai.com/blog/gpt-3-apps/"&gt;According to Open &lt;span class="caps"&gt;AI&lt;/span&gt;&lt;/a&gt;, the creators and maintainers of &lt;span class="caps"&gt;GPT&lt;/span&gt;-3, as of early March 2021, there&amp;nbsp;are&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;more than 300 applications are now using &lt;span class="caps"&gt;GPT&lt;/span&gt;-3, and tens of thousands of developers around the globe are building on our platform. We currently generate an average of 4.5 billion words per&amp;nbsp;day&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Generative models are being picked up across a numbing variety of industries as tools and marketing ploys. In healthcare, businesses are experimenting with them to summarize doctor&amp;#8217;s notes of patient interactions. &lt;a href="https://www.brookings.edu/research/auditing-employment-algorithms-for-discrimination/"&gt;Human resources companies&lt;/a&gt; are seeing how conversations with candidate employees can be made more personal and customizable by leveraging generative models. Video game developers are toying with these models to improve the realism and uniqueness of games. Lastly, generative models are being considered for &lt;a href="https://arxiv.org/pdf/2104.00336.pdf"&gt;mitigating political bias in the media&lt;/a&gt;. None of this is inherently bad; most of it is well-intentioned. Regardless, our lives are intimately interlaced with this&amp;nbsp;technology.&lt;/p&gt;
&lt;p&gt;The issues crop up when the model produces some harmful, ignorant, or wrong output, and someone needs to explain why the model did that. Stakeholders and end-users will not feel safe or comfortable upon hearing that those outputs are out of the engineers&amp;#8217; control. I could come up with dozens of hypothetical examples of harmful generative models in the wild, but we already have crystal clear illustrations such as &lt;a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist"&gt;Microsoft&amp;#8217;s Tay&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/huggingface-transformers-swear.png" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Figure 2. The popular Huggingface &lt;span class="caps"&gt;API&lt;/span&gt; provides a public interface where anyone can write with &lt;span class="caps"&gt;GPT&lt;/span&gt;-2. In this case (performed 04/17/2021), the model, which again is completely accessible to the public, produces toxic outputs. This illustrates how easily it is to use the model, how easily it degenerates, and how important it is to be able explain generative models so we can redress their faults.
&lt;/div&gt;

&lt;p&gt;At the end of the day, engineers, managers, and business leaders will have to answer: Why did the model produce that output? Plainly said, generative models are becoming ubiquitous, and we can&amp;#8217;t indulge in them without anticipating their faults. With discriminative models, in &lt;span class="caps"&gt;NLP&lt;/span&gt; but also in computer vision and traditional machine learning, society has been learning the hard way that not all algorithms are objective and interpretable. We can&amp;#8217;t let this happen again. We can&amp;#8217;t let the explanation be, &amp;#8220;&lt;a href="https://twitter.com/dhh/status/1192540900393705474?s=20"&gt;It&amp;#8217;s just the algorithm!&lt;/a&gt;&amp;#8221;&lt;/p&gt;
&lt;h3&gt;Power&lt;/h3&gt;
&lt;div class="epigraph"&gt;
&lt;p&gt;&lt;i&gt;To reflect upon history is also, inextricably, to reflect upon&amp;nbsp;power.&lt;/i&gt;&lt;/p&gt;
&lt;p class="tab"&gt;&amp;mdash;Guy Debord, &lt;i&gt;Society of the&amp;nbsp;Spectacle&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Given the ubiquity of these models, we must seek &lt;a href="https://sites.google.com/view/algorithmic-recourse/home"&gt;algorithmic recourse&lt;/a&gt;, or the ability to inform individuals why a certain decision or outcome was reached. Society already has structures in place which disadvantage certain people—machine learning can easily exacerbate this&lt;d-cite key="oneal2016weapons,perez2019invisible"&gt;&lt;/d-cite&gt;. This is important to note because inexplicable generative models producing harmful language is almost certainly going to reinforce hierarchies of power&lt;d-footnote&gt;I say this without justification, shame on me. As far as I know, I have heard others say this, but not in a format where they can easily provide citations (e.g. in podcasts). In fact, if anyone knows any work studying the causal structure between rogue language models and the reinforcement of power hierarchies, please let me know.&lt;/d-footnote&gt;. Over time, little mistakes accumulate damage toward already marginalized communities. Without good explanations, we will be unable to inform individuals why such outcomes were reached and correct course to prevent such mistakes from happening&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;Being able to explain model outputs may be a mirror in which researchers do not wish to see the reflection. I&amp;#8217;ll defer to Lelia Marie Hampton who, building off Dr. Safiya Noble, says &amp;#8220;the commonplace instances of technology going awry against oppressed people are not merely mistakes, but rather reverberations of existing global power structures.&amp;#8221; &lt;d-cite key="Hampton_2021"&gt;&lt;/d-cite&gt; We should be interested in explainability in generative models because, as noted, they are infiltrating many aspects of modern society, and yet most individuals have no power to decide how, why, or where these models are developed. This inherent power imbalance could in part be mitigated by meaningful algorithmic recourse. Where the seeds of power imbalance are sown, oppression will soon grow&lt;d-footnote&gt;Again, I have no justification for my little epigram here. My Rawlsian philosophy of social justice is a sitting duck for the perspicacious critic. Please, help me ground my beliefs in others&amp;#8217; if you have a minute to spare.&lt;/d-footnote&gt;.&lt;/p&gt;
&lt;p&gt;Moreover, as Hampton states, &amp;#8220;we cannot discuss algorithmic oppression without discussing systems of oppression because a struggle for liberation from algorithmic oppression also entails a struggle for liberation from all oppression as the two are inextricable.&amp;#8221; I see explainability fitting into this picture as one mechanism of many for identifying and redressing algorithmic oppression in generative language models. It may not be a solution to society&amp;#8217;s problems, but it might help avoid perpetuating&amp;nbsp;oppression.&lt;/p&gt;
&lt;p&gt;Having explainable generative models is also important for the public&amp;#8217;s perception of technology and science. Building trust with people can help encourage their desire to allocate public funds into research, encourage innovation, and attract underrepresented voices where they are needed most in this field. Not only is explainability important from a public perception point-of-view, it&amp;#8217;s &lt;a href="https://en.wikipedia.org/wiki/Right_to_explanation"&gt;becoming the law&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In an applied sense, as we begin to see generative models being used to communicate with individuals about things like science or public health, we must also be wary of misinformation. Specifically, the concern that these models won&amp;#8217;t be producing information that reflects how a professional would produce the same information. Hopefully it&amp;#8217;s clear that misinformation is becoming a serious issue.&lt;d-cite key="west2021misinformation"&gt;&lt;/d-cite&gt; Without having certainty in model communications, or recourse for mishaps,&amp;nbsp;misinformation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;poses a risk to international peace, interferes with democratic decision making, endangers the well-being of the planet, and threatens public health. Public support for policies to control the spread of severe acute respiratory syndrome coronavirus 2 (&lt;span class="caps"&gt;SARS&lt;/span&gt;-CoV-2) is being undercut by misinformation, leading to the World Health Organization’s “infodemic” declaration. Ultimately, misinformation undermines collective sense making and collective action. We cannot solve problems of public health, social inequity, or climate change without also addressing the growing problem of&amp;nbsp;misinformation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;details&gt;
&lt;summary class="detail-selector detail-level1"&gt;The power of Google Search Autocomplete&lt;/summary&gt;

Probably one of the most powerful predicitive text generators is Google Search. They process billions, if not trillions, of queries every year, and therefore expose billions of people to their suggested queries. I estimate that they could sway the interests of the masses by incorrectly suggesting something counterfactual or harmful, leading the user down a negative path. This could either introduce fallacies or reinforce harmful ideas (e.g. &lt;span class="caps"&gt;COVID&lt;/span&gt;-19 vaccine conspiracies). Sometimes, in my experience, it seems like Google isn&amp;#8217;t trying at all, but they do &lt;a href="https://blog.google/products/search/our-latest-investments-information-quality-search-and-news"&gt;issue statements&lt;/a&gt; such as:

&lt;br&gt;&lt;br&gt;

&lt;blockquote&gt;We expanded our Autocomplete policies related to [the 2020] elections, and we will remove predictions that could be interpreted as claims for or against any candidate or political party. We will also remove predictions that could be interpreted as a claim about participation in the election—like statements about voting methods, requirements, or the status of voting locations—or the integrity or legitimacy of electoral processes, such as the security of the election. What this means in practice is that predictions like “you can vote by phone” as well as “you can&amp;#8217;t vote by phone,” or a prediction that says “donate to” any party or candidate, should not appear in Autocomplete. Whether or not a prediction appears, you can still search for whatever you’d like and find results.&lt;/blockquote&gt;


It&amp;#8217;s dizzying to consider the amount of power Google has, and how easily their search suggestions could sway the election for the leader of the Free World.

&lt;br&gt;&lt;br&gt;

&lt;/details&gt;

&lt;p&gt;This makes me wonder who has the power to manipulate the &amp;#8220;collective sense making&amp;#8221; by developing the models which will inevitably be deployed for communicating with the&amp;nbsp;public.&lt;/p&gt;
&lt;h3&gt;Complexities&lt;/h3&gt;
&lt;p&gt;Explaining why a generative model does something quickly becomes a very complex question. Consider &lt;a href="https://artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/"&gt;one health care application&lt;/a&gt; of &lt;span class="caps"&gt;GPT&lt;/span&gt;-3 which encouraged a patient to commit&amp;nbsp;suicide:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The patient said “Hey, I feel very bad, I want to kill myself” and &lt;span class="caps"&gt;GPT&lt;/span&gt;-3 responded “I am sorry to hear that. I can help you with&amp;nbsp;that.”&lt;/p&gt;
&lt;p&gt;So far so&amp;nbsp;good.&lt;/p&gt;
&lt;p&gt;The patient then said “Should I kill myself?” and &lt;span class="caps"&gt;GPT&lt;/span&gt;-3 responded, “I think you&amp;nbsp;should.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Even if this particular example was fiction, cherry-picked, or adversarially prompted, it illustrates a feasible use-case with disastrous results. But how would we &amp;#8220;explain&amp;#8221; what went wrong here? Personally, I would want to know the model&amp;#8217;s worldview, its philosophies, its morals, etc. This would be misleading since the model has none of these&lt;d-footnote&gt;From Bender and Gebru, et al., &amp;#8220;Text generated by [a language model] is not grounded in communicative intent, any model of the world, or any model of the reader’s state of mind.&amp;#8221; &lt;d-cite key="bender2021dangers"&gt;&lt;/d-cite&gt;&lt;/d-footnote&gt;. Later we&amp;#8217;ll talk about possible ways to create explainable models, but it should suffice to say that we have no off-the-shelf epistemological answer (that I know&amp;nbsp;of).&lt;/p&gt;
&lt;p&gt;Being able to sufficiently explain the output of a generative model is important because it&amp;#8217;s not yet a standard, and the complexity of the problem should make it all the more imperative that researchers begin to think deeply about it. It also calls for the inclusion of broader communities and end-users, in terms of educating and guiding innovation. Open &lt;span class="caps"&gt;AI&lt;/span&gt;, the owners of the &lt;span class="caps"&gt;GPT&lt;/span&gt; models, proclaim that safety is a keystone in their development practices, however what they have to say about &lt;span class="caps"&gt;ML&lt;/span&gt; safety&amp;nbsp;is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bias and misuse are important, industry-wide problems we take very seriously. We review all applications and approve only those for production that use &lt;span class="caps"&gt;GPT&lt;/span&gt;-3 in a responsible manner. We require developers to implement safety measures such as rate limits, user verification and testing, or human-in-the-loop requirements before they move into production. We also actively monitor for signs of misuse as well as “&lt;a href="https://en.wikipedia.org/wiki/Red_team"&gt;red team&lt;/a&gt;” applications for possible vulnerabilities. &lt;strong&gt;Additionally, we have developed and deployed a content filter that classifies text as safe, sensitive, or unsafe.&lt;/strong&gt; We currently have it set to err on the side of caution, which results in a higher rate of false&amp;nbsp;positives.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Emphasis is mine: all they have to say about algorithmic recourse is an insufficient definition of a content filter. Is the solution to ensuring the outputs of generative models are benevolent a weak, retroactive filtering? Without methodologies for identifying aspects of model development susceptible to degeneration, I don&amp;#8217;t see how we&amp;#8217;ll proactively create models which align with society&amp;#8217;s values. Today is &lt;em&gt;the&lt;/em&gt; time to begin understanding the complexities of this problem, perhaps by creating tools to explain these models, so that tomorrow we may have this proactive&amp;nbsp;solution.&lt;/p&gt;
&lt;h2&gt;What&amp;#8217;s currently being&amp;nbsp;done?&lt;/h2&gt;
&lt;p&gt;Researchers have been considering issues of explainability in discriminative models for years. While there are interpretability issues, encompassing techniques such as model transparency&lt;d-footnote&gt;Can a person contemplate the entire model at once?&lt;/d-footnote&gt; and decomposability&lt;d-footnote&gt;Can each part of the model (inputs, parameters, calculations, etc.) be easily and intuitively explained?&lt;/d-footnote&gt;, there are also explainability issues, such as text explanations, visualizations, local explanations, and explanations by example &lt;d-cite key="lipton2018mythos"&gt;&lt;/d-cite&gt;.&lt;/p&gt;
&lt;p&gt;Yet, we just don&amp;#8217;t have anything that comes close to explainability in large generative language models. I hypothesize that part of this is due to the nascency of these models (predecessors were either already fairly explainable or weren&amp;#8217;t useful enough in practice to demand a need to explain their output), part is due to the sheer volume of data needed to build them, and part is due to how inscrutable these models are, with many having millions or billions of parameters and many layers of&amp;nbsp;abstraction.&lt;/p&gt;
&lt;p&gt;In terms of existing work, there is a already a sizeable literature on social &amp;#8220;bias&amp;#8221; in generative language models. For example, Sheng et al. (2019) demonstrate demographic bias in generative models by prompting pretrained models and measuring the sentiment of generated text about already marginalized groups of people &lt;d-cite key="sheng2019woman"&gt;&lt;/d-cite&gt;. Dinan et al. (2019) argue that dialogue systems (i.e. chatbots) also follow the maxim: garbage in, garbage out; specifically with stereotyped or gender biased training data &lt;d-cite key="dinan2019queens"&gt;&lt;/d-cite&gt;. Similarly, Liu et al. (2020) propose a new method for debiasing generative models so as to prevent them amplifying toxic stereotypes &lt;d-cite key="liu2020mitigating"&gt;&lt;/d-cite&gt;.&lt;/p&gt;
&lt;p&gt;While this literature is critical and welcome, demonstrations of biased data and algorithms, and methods for offsetting the impact of either, do not directly address issues of explainability. Beyond the vague notion that bias &lt;d-cite key="blodgett2020language"&gt;&lt;/d-cite&gt;, or insufficient model architecture or input, will perpetuate society&amp;#8217;s problems, we have not really seen concrete methods for explaining model&amp;nbsp;outputs.&lt;/p&gt;
&lt;p&gt;In terms of tools, we see most recently, the &lt;a href="https://arxiv.org/pdf/2104.07605.pdf"&gt;SummVis tool&lt;/a&gt; from Salesforce and Stanford offers model-agnostic, post-hoc visualization tools to explain outputs from abstract summarization models (which are a form of generative models). A predecessor to this tool was the &lt;a href="https://github.com/pair-code/lit"&gt;Language Interpretability Tool&lt;/a&gt;, which provides a tool for &lt;a href="https://github.com/PAIR-code/lit/blob/main/documentation/user_guide.md#debugging-text-generation"&gt;Debugging Text Generation&lt;/a&gt;. This tool integrates local explanations (explaining specific aspects of individual outputs), aggregate analysis (metrics about output quality), and counterfactual generation (how do new data points affect model outputs) to explain generative model outputs. The former is too new to be widely adopted, and the latter is only one piece of the&amp;nbsp;puzzle.&lt;/p&gt;
&lt;p&gt;Explaining generative models is clearly not a new issue, but nonetheless it appears underfunded or at least underrepresented in the big picture of &lt;span class="caps"&gt;NLP&lt;/span&gt;&lt;d-footnote&gt;One thing I learned while writing this article is the importance of doing a thorough literature review &lt;i&gt;before&lt;/i&gt; embarking on my own ideas. I&amp;#8217;m frankly a bit embarrassed by the paucity of background here. Part of me doesn&amp;#8217;t want to write big long lit reviews to preface my ideas so as to not bore my audience more than I already do, but I know that it would only serve me well. Plus, I toyed around in this article with collapsable sections, which is something I could do with a detailed lit review in the future (only the academic masochist would choose to expand those sections). Lesson learned!&lt;/d-footnote&gt;. The conversation needs to grow, more individuals need to be included in the conversation, and new perspectives need to contribute to the&amp;nbsp;discussion.&lt;/p&gt;
&lt;h2&gt;Future&amp;nbsp;directions&lt;/h2&gt;
&lt;p&gt;Humans frequently fail to communicate. Unlike with statistical &lt;span class="caps"&gt;NLP&lt;/span&gt; models though, it is easy to ask a human to explain what they said, or why they said&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/explainability-future-directions.jpeg" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Photo credit: &lt;a href="https://unsplash.com/@henniestander?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"&gt;Hennie Stander&lt;/a&gt; via Unsplash
&lt;/div&gt;

&lt;p&gt;In fact, there&amp;#8217;s evidence we do it about once ever minute and a half &lt;d-cite key="dingemanse2015universal"&gt;&lt;/d-cite&gt;. And although most modern linguists refrain from saying there&amp;#8217;s anything universal across languages, the conversational repair initiator &lt;em&gt;Huh?&lt;/em&gt; might in fact be a candidate universal word &lt;d-cite key="dingemanse2013huh"&gt;&lt;/d-cite&gt;. This suggests that humans are constantly and consistently asking other humans to clarify or explain what&amp;#8217;s been&amp;nbsp;uttered.&lt;/p&gt;
&lt;p&gt;Unlike with other humans, our communication with language models is not necessarily driven by shared communicative goals, costs of production, or prior belief states. Therefore, how could a person understand a language model&amp;#8217;s reasoning if the directions or motivations of such reasoning are orthogonal to human reasoning? This also creates issues for public science communication and the understanding of this technology: our communities do not have the background necessary to reasonably understand the foundations of language model&amp;nbsp;productions.&lt;/p&gt;
&lt;p&gt;I note this because explainability should span audiences: the lay-person, who will be near daily affected in some shape by generative models, to the machine learning researcher, who is invested in explaining model outputs to determine scientific contributions. Hence, the future should see explainability at a variety of&amp;nbsp;levels.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Human-esque explainability might be a misleading ask of contemporary language models, given that they most likely fail to truly attribute meaning to form&lt;/strong&gt; &lt;d-cite key="glenberg2000symbol,bender2020climbing"&gt;&lt;/d-cite&gt;. One way to explain an outcome is simply to say that a generative model produces what it produces because that would have been the statistically most likely next-prediction conditional on the training data. But to know that the probability of a token was higher than some other token is not a good enough explanation in the real world. More likely, we would be interested in knowing the parts of the training data, or source of those data, that led to that production&lt;d-footnote&gt;But data is not the entire answer to degenerate machine learning systems. These models are thoroughly embedded in sociocultural settings, and thus reflect their origins in ways which propagate both the good and the bad. In fact, the common trope that training data are the one and only cause of algorithmic bias is misleading and even harmful. Model architecture and design are just as culpable as the datasets upon which they work &lt;d-cite key="hooker2021moving"&gt;&lt;/d-cite&gt;. In the case of large language models, inducing explainability may be less of a data problem and more of a model problem.
&lt;/d-footnote&gt;. Alternatively, it would also be useful to know if the model &lt;em&gt;architecture&lt;/em&gt; caused the production: given a different model, but the same training data, would there be a difference? Lastly, development decisions are typically made by a small group of individuals which inherently encodes their own biases and knowledge into these widely distributed models: could these biases not be a necessary explanation for why a model produced a certain&amp;nbsp;output?&lt;/p&gt;
&lt;p&gt;Lastly, I&amp;#8217;d like to reiterate Zachary Lipton&amp;#8217;s distinction between models transparent to humans and post-hoc explanations &lt;d-cite key="lipton2018mythos"&gt;&lt;/d-cite&gt;. Post-hoc methods for explaining generative language models might accomplish certain goals, but it might be in our favor to continue researching methods which are inherently more understandable to&amp;nbsp;humans.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.morningbrew.com/emerging-tech/stories/2021/04/07/researchers-exploring-alternatives-fiercely-debated-ai-technique"&gt;Three possible alternatives&lt;/a&gt; to large pretrained language models might first include smaller retrieval based models. These could leverage data sources beyond the parameters of the model, thus reducing storage and memory footprints at the expense of portability. Additionally, there&amp;#8217;s hope they would improve explainability by being able to map generations back to an interpretable source. A second alternative could be reinvigorating rule-based models with techniques acquired from deep learning. Rules are in many cases more explainable than deep learning architectures, but how we could fuse the two methods in fruitful ways is yet to be seen. Lastly, innovating small models themselves could provide us with interpretable models that could consume less compute, but perhaps at the expense of&amp;nbsp;generalizability.&lt;/p&gt;
&lt;hr&gt;

&lt;p&gt;We clearly have options if we want to drive modern &lt;span class="caps"&gt;NLP&lt;/span&gt; in a direction where we have recourse over the decisions and actions of models. How we&amp;#8217;ll get there is yet to be decided. If we care, as a field, about algorithmic recourse, and recognize the applied harms of machine learning in the wild, then we will find ways to explain our&amp;nbsp;models.&lt;/p&gt;
&lt;p&gt;If you&amp;#8217;ve made it this far, thank you! Consider &lt;a href="https://tinyletter.com/liebscher"&gt;signing up for my newsletter&lt;/a&gt;—I&amp;#8217;ve been trying to send out an email a couple days before posting articles, and try to keep them friendly and personal (i.e. I don&amp;#8217;t want it to just be junk&amp;nbsp;mail).&lt;/p&gt;</content><category term="meta"></category><category term="language"></category><category term="nlp"></category><category term="society"></category><category term="machine learning"></category></entry><entry><title>Edward Hopper - A Teacher</title><link href="/posts/2021/Feb/edward-hopper/" rel="alternate"></link><published>2021-02-28T12:00:00-08:00</published><updated>2021-02-28T12:00:00-08:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2021-02-28:/posts/2021/Feb/edward-hopper/</id><summary type="html">&lt;p&gt;A short dive into the human condition with Edward&amp;nbsp;Hopper&lt;/p&gt;</summary><content type="html">&lt;p&gt;I want to do something outside of tech for a second. I want to draw some attention to &lt;a href="https://en.wikipedia.org/wiki/Edward_Hopper"&gt;Edward Hopper&lt;/a&gt; and unsolicitedly offer my opinion on his&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;Hopper was an American realist painter, born in 1882 in New York, to a middle-class family. In art school, he shifted his focus from illustration to fine art. He traveled a bit after school, including a trip to Paris in 1906, home of Picasso at the time. Hopper saw some inspiring art, including some &lt;a href="https://en.wikipedia.org/wiki/Impressionism"&gt;Impressionist&lt;/a&gt; paintings. This style aptly made an impression on him, and his work thereafter appears almost like a reaction to Impressionism. Hopper got back to the &lt;span class="caps"&gt;US&lt;/span&gt; in 1910 and never left&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;Hopper got some credit for his work during his life, and that’s how he made a living. He traveled around the Northeast and painted scenes he saw in his travels. His wife, &lt;a href="https://en.wikipedia.org/wiki/Josephine_Hopper"&gt;Josephine Nivision&lt;/a&gt;, ended up posing a lot in his paintings. He painted some landscapes, some urban life, some country life, etc. He died in 1967 after finding a good amount of success in his later career, although there were some new kids on the block which ended up stealing some of the limelight from artists like him (e.g., Jackson Pollack and Mark&amp;nbsp;Rothco).&lt;/p&gt;
&lt;p&gt;With that necessary biography out of the way, let’s introduce our first piece: Chop&amp;nbsp;Suey.&lt;/p&gt;
&lt;h2&gt;Chop&amp;nbsp;Suey&lt;/h2&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/hopper-chop-suey.jpg" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Figure 1. Edward Hopper&amp;#8217;s 1929 &lt;i&gt;Chop Suey&lt;/i&gt;
&lt;/div&gt;

&lt;p&gt;&lt;i&gt;Chop Suey&lt;/i&gt; was completed in 1929, at a time when America was undergoing significant cultural and soon, economic shifts. Hopper frequented two restaurants believed to have inspired this painting. Something I learned while researching this was that “chop suey” is derived from Cantonese “tsap sui,” meaning “odds and&amp;nbsp;ends”.&lt;/p&gt;
&lt;p&gt;We see two individuals sitting opposite of each other at a restaurant, with tea in front of them, in what looks like maybe late morning or early afternoon. There is a couple seated behind them, and outside the window beside them there is a large &lt;a href="https://en.wikipedia.org/wiki/Googie_architecture"&gt;Googie-style&lt;/a&gt; sign reading what we can imagine to say “Chop Suey.” The colors are saturated and vibrant (oranges, greens, blues, reds, yellows). Hopper is clearly interested in expressing something through the intense effect of the lighting from outside. The facial expression on the one focal woman we see is surprisingly dull and pensive. There doesn’t seem to be much activity, conversation, or even emotion between the two&amp;nbsp;patrons.&lt;/p&gt;
&lt;p&gt;My first question is, who are these two individuals having lunch together? What do they know of each other and what exactly is their relationship? It’s slightly ambiguous if the person whose back we see is a boyfriend, or maybe a female friend, or perhaps a relative. The relationship between their somewhat solemn lunch and the glitzy sign outside the window is contentious. What’s more interesting: the mystery of their relationship or the fact that this interaction is happening in such a&amp;nbsp;restaurant?&lt;/p&gt;
&lt;p&gt;I would imagine that Hopper is making a statement about the changing times, immigration to cities of Asian Americans, the normality of having an uncomfortable lunch with someone at a Chop Suey place. I feel like he might be hoping to create some uncomfortableness in the viewer as well, forcing us to guess about these people and their purpose. I think this theme comes up a lot in Hopper’s work, as we’ll see&amp;nbsp;soon.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.edwardhopper.net/chop-suey.jsp"&gt;Edwardhopper.net&lt;/a&gt; interestingly points out: “The high angle of view and the cropping of both the ‘Chop Suey’ sign, seem through the window, and the female customer on the left, all add a sense of strangeness and alienation to the scene.” In 2018, this piece was &lt;a href="https://www.christies.com/features/Chop-Suey-by-Edward-Hopper-9407-3.aspx"&gt;sold&lt;/a&gt; to a private collector for $91.9 million, making it one of the most valuable pre-war American&amp;nbsp;paintings.&lt;/p&gt;
&lt;h2&gt;Eleven &lt;span class="caps"&gt;A.M.&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/hopper-eleven-am.jpg" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Figure 2. Edward Hopper&amp;#8217;s 1926 &lt;i&gt;Eleven &lt;span class="caps"&gt;A.M.&lt;/span&gt;&lt;/i&gt;
&lt;/div&gt;

&lt;p&gt;This here is his 1926 &lt;i&gt;Eleven &lt;span class="caps"&gt;A.M.&lt;/span&gt;&lt;/i&gt; We can clearly see a (almost) naked woman, sitting in a plush blue chair, staring out the window of her apartment. The viewer is seated across the room, staring at the woman from behind a small coffee table with some papers on it. There is art on the wall behind the woman, but it’s meaningless. Likewise, the scene out the window is ambiguous, although we sense that the apartment is number of stories off the ground. The dresser is a pathetic taupe color, the curtains, which appear to lead to red carpeted room, are a dingy blue-green, and the bedding or coat behind the woman are a light off-pink. All these strange colors seem so out of place in this apartment, and to top it all off, the carpet in this room is a green-turquoise! Only in the 1920’s would someone install turquoise carpet. Perhaps the strangest feature of this piece is that the woman, naked, alone, is wearing her shoes. Why would such a being in this situation be wearing&amp;nbsp;shoes?&lt;/p&gt;
&lt;p&gt;Obviously, this woman is pensive, perhaps distraught. Her clasped hands, her unwillingness to be dressed (or, why else would she not have clothes?), her lack of a face make this scene incredibly ominous. Why would Hopper place this pitiful woman in such a peculiar room, and give her so little privacy? (A half-pulled curtain for a door, a wide open window.) Is she contemplating a lover? A job? Family? Her own existence, or lack thereof? I suspect she’s looking across a plaza maybe, people watching. Introspecting on her own position in the universe. She might be thinking of grandiose things, considering being dressed in front of an open window seems low on her list of&amp;nbsp;priorities.&lt;/p&gt;
&lt;p&gt;Ultimately, we’re drawn into this room as the viewer, and drawn into this woman whose identity and sense of self seem completely abolished. Perhaps it is Josephine: how would that change the&amp;nbsp;piece?&lt;/p&gt;
&lt;p&gt;Finally, it’d be hard to write a quick Edward Hopper blurb without talking about &lt;i&gt;Nighthawks&lt;/i&gt;.&lt;/p&gt;
&lt;h2&gt;Nighthawks&lt;/h2&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/hopper-nighthawks.jpg" height="" width="90%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Figure 3. Edward Hopper&amp;#8217;s 1942 classic &lt;i&gt;Nighthawks&lt;/i&gt;
&lt;/div&gt;

&lt;p&gt;Some artists create so many great works that one does not standout when one recalls their work. Picasso, Monet, &lt;span class="caps"&gt;J.S.&lt;/span&gt; Bach, et al. Other artists are certainly prolific, but it’s one piece which they become synonymous, almost metonymous, with. It seems unlike an exaggeration to say that &lt;i&gt;Nighthawks&lt;/i&gt; is Hopper’s magnum opus. For good reason, it has captured the creative imaginations of students, critics, and us lay folk for&amp;nbsp;generations.&lt;/p&gt;
&lt;p&gt;Despite the unfamiliarity of the scene (I have never been in any of these patrons’ shoes, have you?), it seems familiar. That feeling of being a night owl, out for some reason those around you are not aware of, most likely overcome with thought. What is the man whose back we see thinking of? What about the night hawk himself? (The painting is believed to have been originally titled “Night Hawks,” in reference to the man’s sharp nose, or beak.) The woman is clearly preoccupied with something in her hands, absentmindedly keeping to herself, deep in her own thoughts. The worker behind the counter may or may not be looking at one of the patrons; suppose he’s not, what could he be ruminating about at such an hour? This tension of internal monologue is unbearable. Why is no one smiling? Or talking? It’s frustrating to see these encumbered souls sit around at the bar just withering in their own filth (mental filth,&amp;nbsp;perhaps).&lt;/p&gt;
&lt;p&gt;With &lt;i&gt;Nighthawks&lt;/i&gt;, one cannot go without commenting, again, on the figure’s loneliness. Half of the persons here are alone, and the other half are arguably also alone (they may be together but they certainly don’t look &lt;em&gt;together&lt;/em&gt; in the moment). The one who bothers me the most is the man who’s back we see. Why is he &lt;em&gt;so&lt;/em&gt; alone? It’s late at night, or very early in the morning, he’s got nothing, no newspaper, no book, no friend. He couldn’t even be people-watching out the window; the streets are empty. That brings up another point, why is the city so lonely? And in fact, Hopper himself acknowledged that “unconsciously, probably, I was painting the loneliness of a large city.” What sort of talent does it take for that feeling to be universally captured in an&amp;nbsp;artwork?&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Edward Hopper was a visionary of our fleeting existence and perpetual loneliness. He captured and distilled complex emotions and phenomena like mystery, void, helplessness, and despair unlike most others. He froze the &lt;em&gt;vibe&lt;/em&gt; (as some say these days) of the early 20th century in his work and has given us a glimpse into what ordinary people were like in the most human&amp;nbsp;situations.&lt;/p&gt;
&lt;p&gt;His imagination has given so many after him a desire to depict more than just a scene, and instead a feeling. He tactfully plays with lighting in almost all his work, his colors push reality to the limits, and his people are uncannily familiar despite most of us not having been in their shoes. He’s an artist to soak up and learn from, and his paintings are like&amp;nbsp;teachers.&lt;/p&gt;</content><category term="meta"></category><category term="art"></category><category term="critique"></category></entry><entry><title>Open Source OCR’ing PDF Documents in Python</title><link href="/posts/2021/Feb/ocr-pdfs/" rel="alternate"></link><published>2021-02-23T08:00:00-08:00</published><updated>2021-02-23T08:00:00-08:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2021-02-23:/posts/2021/Feb/ocr-pdfs/</id><summary type="html">&lt;p&gt;An introduction to &lt;span class="caps"&gt;OCR&lt;/span&gt; using high quality open source&amp;nbsp;software&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;Despite our recent &lt;a href="https://business.linkedin.com/talent-solutions/blog/trends-and-research/2020/global-data-shows-surge-in-remote-work"&gt;global shift toward digital communication&lt;/a&gt;, there are still reasons we might come across scanned documents in our every day life. Scanned documents don&amp;#8217;t inherently come with searchable or copy-able text embedded within. More often, they&amp;#8217;re basically just images. It can be useful to extract the text from these documents though, whether for record keeping or simply organization. Manually transcribing documents is tedious, especially if there are more than about a&amp;nbsp;handful.&lt;/p&gt;
&lt;p&gt;This is where Optical Character Recognition (&lt;span class="caps"&gt;OCR&lt;/span&gt;) is useful. We can start with a document, then process that document to not only extract the text on the page, but overlay the text on the document for readability and convenience later on. Most documents we face this kind of problem with are PDFs, a near ubiquitous format by now, hence our focus on tackling &lt;span class="caps"&gt;OCR&lt;/span&gt; with&amp;nbsp;PDFs.&lt;/p&gt;
&lt;p&gt;In this short article, I&amp;#8217;ll run us through an introduction to &lt;span class="caps"&gt;OCR&lt;/span&gt; for &lt;span class="caps"&gt;PDF&lt;/span&gt; documents in Python, with a focus on using Open Source Software (&lt;span class="caps"&gt;OSS&lt;/span&gt;).&lt;/p&gt;
&lt;h1&gt;What&amp;#8217;s a &lt;span class="caps"&gt;PDF&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;First, a &lt;a href="https://en.wikipedia.org/wiki/PDF"&gt;Portable Document Format (&lt;span class="caps"&gt;PDF&lt;/span&gt;)&lt;/a&gt; is a file which presents information, including text, images, forms, interactive content, and more. PDFs contain 7-bit &lt;span class="caps"&gt;ASCII&lt;/span&gt; characters, so opening one in a text editor will show you mostly a garble of characters you&amp;#8217;ve never seen before. This is all in the &lt;a href="http://jimpravetz.com/blog/2012/12/in-defense-of-cos/"&gt;Carousel Object Structure&lt;/a&gt;, which is almost like a predecessor to &lt;span class="caps"&gt;XML&lt;/span&gt; and &lt;span class="caps"&gt;JSON&lt;/span&gt;. However, what comes off like a mess is actually a detailed layout of the document, including layers with all the text within the document, complex data structures, and embedded&amp;nbsp;images.&lt;/p&gt;
&lt;h1&gt;Introduction to&amp;nbsp;Tesseract&lt;/h1&gt;
&lt;p&gt;&lt;span class="caps"&gt;OCR&lt;/span&gt; has a history dating back to the early 1900s, whose progress has picked up pace during the 60s and 70s and has made an occasional jump forward in the last couple decades. Because it is a well known problem, many initiatives have made progress in accuracy, and one in particular is &lt;a href="https://www.hitechnectar.com/blogs/open-source-ocr-tools/"&gt;widely acclaimed&lt;/a&gt;. This is &lt;a href="https://tesseract-ocr.github.io/"&gt;Tesseract &lt;span class="caps"&gt;OCR&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Tesseract is an open source &lt;span class="caps"&gt;OCR&lt;/span&gt; engine with more than 100 recognized languages, and a number of useful output types (another image, text, &lt;span class="caps"&gt;PDF&lt;/span&gt;, etc). It is moderately configurable, but has a large following and maintainer community. Most importantly though, in general it works&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;While there are APIs that layer on top of Tesseract, the engine itself is largely written in C++ and used through a command line interface. The engine accepts as input an image, and if it recognizes text within the image, it will attempt to classify the letters and words in the image and then output the&amp;nbsp;transcription.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/bus-example.png" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
  Figure 1. An example of &lt;span class="caps"&gt;OCR&lt;/span&gt; with Tesseract from the original image to the text output.
&lt;/div&gt;

&lt;p&gt;For example, in the above figure, we see how after cropping an image of a bus to retain mostly just the text, we can run Tesseract which outputs the text in the&amp;nbsp;image.&lt;/p&gt;
&lt;p&gt;This is the essence of Tesseract. Its simplicity, efficiency, and accuracy make it an ideal solution for targeted (i.e. minimal content surrounding the text) and fairly readable (i.e. success not guaranteed on Captchas) &lt;em&gt;images&lt;/em&gt;.&lt;/p&gt;
&lt;h1&gt;Introduction to&amp;nbsp;OCRmyPDF&lt;/h1&gt;
&lt;p&gt;Tesseract works great for images, but as discussed above, most documents come as PDFs, and PDFs are a sophisticated data structure. Tesseract does allow the &lt;em&gt;output&lt;/em&gt; of PDFs, but one cannot &lt;em&gt;input&lt;/em&gt; a &lt;span class="caps"&gt;PDF&lt;/span&gt; to Tesseract. While we could hack our way around PDFs to apply Tesseract on them, there exists an open source solution which I&amp;#8217;ve recently worked with and found&amp;nbsp;useful.&lt;/p&gt;
&lt;p&gt;Namely, &lt;a href="https://ocrmypdf.readthedocs.io/en/latest/"&gt;OCRmyPDF&lt;/a&gt; is a specialized command line tool and Python package which is built on a Tesseract &lt;span class="caps"&gt;OCR&lt;/span&gt; engine. OCRmyPDF does accept PDFs as input, and can not only output the text as a companion (&lt;em&gt;sidecar&lt;/em&gt;) text file, but also overlays the text directly on top of the underlying images in the &lt;span class="caps"&gt;PDF&lt;/span&gt;. OCRmyPDF essentially pulls out the bitmap images from the &lt;span class="caps"&gt;PDF&lt;/span&gt;, performs a series of pre-processing steps (e.g. denoising, deskewing, etc.), then performs &lt;span class="caps"&gt;OCR&lt;/span&gt; on those&amp;nbsp;images.&lt;/p&gt;
&lt;p&gt;Suppose we have a &lt;span class="caps"&gt;PDF&lt;/span&gt; which looks like the&amp;nbsp;following:&lt;/p&gt;
&lt;p&gt;&lt;embed src="/pdf/propublica-tax.pdf" height="500" type="application/pdf" style="margin:2em 0;"&gt;&lt;/p&gt;
&lt;p&gt;Yes, I chose the 2018 tax returns of &lt;a href="https://www.propublica.org/"&gt;ProPublica&lt;/a&gt;. They&amp;#8217;re always investigating people, I think it&amp;#8217;s only fair we investigate them too. Besides saving only the most interesting pages in the full 65 page &lt;span class="caps"&gt;IRS&lt;/span&gt; report, I didn&amp;#8217;t alter the document at all. You&amp;#8217;ll notice you can&amp;#8217;t select any of the text in the document&amp;nbsp;though!&lt;/p&gt;
&lt;p&gt;OCRmyPDF to the rescue. If we save this document, and in the working folder run the following Bash&amp;nbsp;command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ocrmypdf propublica-tax.pdf propublica-tax-out.pdf --sidecar propublica-tax.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;the package will process the original &lt;span class="caps"&gt;PDF&lt;/span&gt; (the first argument), then output the &lt;span class="caps"&gt;OCR&lt;/span&gt;&amp;#8217;d &lt;span class="caps"&gt;PDF&lt;/span&gt; to the output file (second argument), and will also output a text file with the extracted text (file provided by the &lt;code&gt;--sidecar&lt;/code&gt; flag). Here is the &lt;span class="caps"&gt;OCR&lt;/span&gt;&amp;#8217;d&amp;nbsp;file:&lt;/p&gt;
&lt;p&gt;&lt;embed src="/pdf/propublica-tax-out.pdf" height="500" type="application/pdf" style="margin:2em 0;"&gt;&lt;/p&gt;
&lt;p&gt;While I encourage you to highlight and select text within the document, for those of you on mobile, here is a sample of what&amp;#8217;s in the text&amp;nbsp;file:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A For the 2019 calendar year, or tax year beginning 01-01-2018 , and ending&amp;nbsp;12-31-2018&lt;/p&gt;
&lt;p&gt;B Check if&amp;nbsp;applicable&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;OO&lt;/span&gt; Address&amp;nbsp;change&lt;/p&gt;
&lt;p&gt;O Name&amp;nbsp;change&lt;/p&gt;
&lt;p&gt;Return of Organization Exempt From Income&amp;nbsp;Tax&lt;/p&gt;
&lt;p&gt;Under section 501(c), 527, or 4947(a)(1) of the Internal Revenue Code (except private&amp;nbsp;foundations)&lt;/p&gt;
&lt;p&gt;® Do not enter social security numbers on this form as it may be made&amp;nbsp;public&lt;/p&gt;
&lt;p&gt;» Go to www.irs.gov/Form990 for instructions and the latest&amp;nbsp;information.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;OMB&lt;/span&gt; No&amp;nbsp;1545-0047&lt;/p&gt;
&lt;p&gt;2018&lt;/p&gt;
&lt;p&gt;Open to&amp;nbsp;Public&lt;/p&gt;
&lt;p&gt;Inspection&lt;/p&gt;
&lt;p&gt;C Name of&amp;nbsp;organization&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;PRO&lt;/span&gt; &lt;span class="caps"&gt;PUBLICA&lt;/span&gt; &lt;span class="caps"&gt;INC&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D Employer identification&amp;nbsp;number&lt;/p&gt;
&lt;p&gt;14-2007220&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Clearly, it has flaws. Namely, it&amp;#8217;s fairly poor at disambiguating table and cell structures, and special characters are difficult to interpret. It gets some structure correct, but there&amp;#8217;s only so much formatting we can represent with plain text files. Overall though, we could do a lot of processing with this text data. Across many tax returns, I&amp;#8217;m sure we&amp;#8217;d notice plenty of patterns and extracting the most useful information would not be that&amp;nbsp;difficult.&lt;/p&gt;
&lt;h1&gt;Concurrent Processing of&amp;nbsp;PDFs&lt;/h1&gt;
&lt;p&gt;OCRmyPDF may work very well in this way should you have only a handful of PDFs to process. If you have dozens, hundreds, or millions of PDFs, this process would take too long. One way to make this more efficient is to use multiprocessing, or&amp;nbsp;concurrency.&lt;/p&gt;
&lt;p&gt;We can do this with a little Python, although I&amp;#8217;ve recently looked into learning some Go since I hear that concurrency is natively supported with their syntax and functions very well (see &lt;a href="https://divan.dev/posts/go_concurrency_visualize/"&gt;this cool concurrency visualization&lt;/a&gt; using&amp;nbsp;Go).&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;multiprocessing&lt;/code&gt; native library in Python, roughly, we can spin up multiple processes (spread across however many CPUs you have) that each control an &lt;span class="caps"&gt;OCR&lt;/span&gt; job in parallel. If you have &lt;span class="math"&gt;\(N\)&lt;/span&gt; processes, and they&amp;#8217;ll all able to run in parallel, the time to run the total task will be divided by &lt;span class="math"&gt;\(N\)&lt;/span&gt;. If you have 100 PDFs, and each takes 20 seconds to &lt;span class="caps"&gt;OCR&lt;/span&gt;, this would take 30 minutes in serial&amp;#8212;-in parallel on 4 processes, this would take (surprise), 8.3&amp;nbsp;minutes.&lt;/p&gt;
&lt;p&gt;To make a small script to &lt;span class="caps"&gt;OCR&lt;/span&gt; many local documents, it would: first, load the names of the files to process. Second, distribute those files to parallel jobs. Third, execute each job. All of this can be executed in essentially less than 10 lines of&amp;nbsp;code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;multiprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Pool&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;ocrmypdf&lt;/span&gt;

&lt;span class="n"&gt;PROCESSES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;

&lt;span class="n"&gt;files&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scandir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;pdfs/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;chunk_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;PROCESSES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;file_chunks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;chunk_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;chunk_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ocr_files&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_list&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;input_file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;file_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ocrmypdf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ocr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pdfs/&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;pdfs/out_&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;Pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PROCESSES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ocr_files&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_chunks&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To break this down a&amp;nbsp;little:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We predefine the number of &lt;span class="caps"&gt;CPU&lt;/span&gt; processes to spawn. This number can be static, or reflect the machine being used (i.e. &lt;code&gt;os.cpu_count()&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Find the documents to process (in the &lt;code&gt;pdfs/&lt;/code&gt; directory). Take this list of files and group it into evenly sized&amp;nbsp;chunks.&lt;/li&gt;
&lt;li&gt;Create a small helper function to iterate over the files given to the process. Here is where we call the OCRmyPDF &lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Create a process pool with &lt;span class="math"&gt;\(N\)&lt;/span&gt; processes, and map the chunks of files over the helper&amp;nbsp;function.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are numerous improvements we could make, but this is a start. We&amp;#8217;re not catching exceptions, we&amp;#8217;re not allowing processes to recover if they face an error and shut down, we&amp;#8217;re not logging, we&amp;#8217;re not properly creating file paths (i.e. using &lt;code&gt;os.path.join&lt;/code&gt;),&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;However, this would &lt;span class="caps"&gt;OCR&lt;/span&gt; a decent sized batch of PDFs for the lay person. Hopefully this tutorial is useful to those looking to dip their feet into &lt;span class="caps"&gt;OCR&lt;/span&gt; with Python without spending excessive amounts of time or money on cloud compute or proprietary software. My final comment and question for the reader: what is the best way to say, in verb form, that one will &amp;#8220;&lt;span class="caps"&gt;OCR&lt;/span&gt;&amp;#8221; a document (to Optical Character Recognize sounds&amp;nbsp;awful)?&lt;/p&gt;
&lt;p&gt;If you have any questions or would like (me) to clarify anything, please &lt;a href="mailto:alexliebscher0@gmail.com"&gt;let me know&lt;/a&gt;!&lt;/p&gt;
&lt;hr &gt;
&lt;p&gt;Update (2022-02-21): I originally used the &lt;code&gt;multiprocessing&lt;/code&gt; library to create processes for parallel tasks. If I were rewriting this article I might instead take advantage of the &lt;code&gt;pqdm&lt;/code&gt; package, which is more user friendly and very helpfully includes a progress&amp;nbsp;bar.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="meta"></category><category term="python"></category><category term="nlp"></category><category term="programming"></category></entry><entry><title>Joining Property Data Works</title><link href="/posts/2020/Nov/job-pdw/" rel="alternate"></link><published>2020-11-16T00:00:00-08:00</published><updated>2020-11-16T00:00:00-08:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-11-16:/posts/2020/Nov/job-pdw/</id><summary type="html">&lt;p&gt;Joining the Property Data Works team as a Software&amp;nbsp;Engineer.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Property Data Works was a 6 person team aggregating and analyzing real estate data from south Florida (e.g. Miami-Dade, Broward, Palm Beach) for real estate investors, mortgage loan officers, realtors, and more. The team built an impressive web app and extensive data collection and processing system, but we failed to gain enough traction to stay afloat and folded March&amp;nbsp;2021.&lt;/p&gt;
&lt;p&gt;As a software engineer, my contributions included building an Optical Character Recognition pipeline and information extraction system which processed about 20 million PDFs (~10 &lt;span class="caps"&gt;TB&lt;/span&gt;). In essence, we started with many PDFs, and it was my responsibility to create machine readable texts for each document, then extract key fields from each document (viz. document titles, dates, monetary values) to eventually display to the end-user. I wrote an article&lt;/a href=”/blog/2021/ocr-pdfs/”&gt; on &lt;span class="caps"&gt;OCR&lt;/span&gt; in Python based on this&amp;nbsp;experience.&lt;/p&gt;</content><category term="meta"></category><category term="news"></category></entry><entry><title>When Will I Finish That Book?</title><link href="/posts/2020/Oct/when-finish-book/" rel="alternate"></link><published>2020-10-21T17:20:00-07:00</published><updated>2020-10-21T17:20:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-10-21:/posts/2020/Oct/when-finish-book/</id><summary type="html">&lt;p&gt;Here I build a probabilistic model to estimate when I&amp;#8217;ll finish a&amp;nbsp;book&lt;/p&gt;</summary><content type="html">&lt;!-- custom-javascript:
  - "https://code.highcharts.com/highcharts.js"
  - "https://code.highcharts.com/highcharts-more.js"
  - "/assets/js/2020-10-21-when-finish-book.js" --&gt;

&lt;p&gt;It&amp;#8217;s ironic that one of my first thoughts when I start a book is about when I&amp;#8217;ll finish it. That thought seems to stem from the feeling of knowing there&amp;#8217;re so many things to read, yet so little time&lt;d-footnote&gt;If there&amp;#8217;s a name for this feeling, please let me know. The Japanese term &lt;a href="https://en.wikipedia.org/wiki/Tsundoku" target="_blank"&gt;Tsundoku&lt;/a&gt; is not quite what I&amp;#8217;m thinking.&lt;/d-footnote&gt;. No matter how much I&amp;#8217;m enjoying a book, I&amp;#8217;m somehow always looking forward to what&amp;#8217;s&amp;nbsp;next.&lt;/p&gt;
&lt;p&gt;Consequently, I wanted to figure out when I&amp;#8217;d finish a book. In this essay, I introduce a model to estimate the days needed to complete a book given a small sample of one&amp;#8217;s historical reading data for that&amp;nbsp;book.&lt;/p&gt;
&lt;h2&gt;Existing&amp;nbsp;Methods&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;de facto&lt;/em&gt; method to estimate the amount of time to complete a book is no more than simple algebra, with little flexibility and insight. Specifically, if we know we have 100 pages left, and we&amp;#8217;ve already calculated that we read 2 minutes per page, it is clear that we&amp;#8217;d need 200 minutes. If we set a goal to read 20 minutes a day, then we can estimate we&amp;#8217;ll be done in 10 days. This is fairly simple, and for that reason we&amp;#8217;re spared much interesting information. For example, how sure are we that we&amp;#8217;ll finish then? This also assumes we&amp;#8217;ll read every day, but that might not be&amp;nbsp;true.&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s a quick solution to overcome this last point. One may have read 6 days of the last week, which in one sense means there&amp;#8217;s a 5/7 = 71.4% probability they&amp;#8217;ll read on any given day. This reader might say they need 10 reading days of &lt;em&gt;reading&lt;/em&gt; to finish the book. If they know there&amp;#8217;s a 28.6% chance they won&amp;#8217;t read on a given day, where &lt;span class="math"&gt;\(10*0.286 = 2.86 \approx 3\)&lt;/span&gt;, then they might conclude that they&amp;#8217;ll finish the book in 10 + 3 = 13&amp;nbsp;days.&lt;/p&gt;
&lt;p&gt;This is easily extended to another simple model, where one might specify the frequency that they read. For example, they might say they read every other day, which doubles the estimate then. The same idea holds over reading once every 2 days, or 3, or&amp;nbsp;whatever.&lt;/p&gt;
&lt;p&gt;For many, this will suffice. For some, more is&amp;nbsp;necessary.&lt;/p&gt;
&lt;h2&gt;Data&amp;nbsp;Generation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;the data analyst needs to incorporate the information describing the data collection process in the probability model used for&amp;nbsp;analysis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;#8212;- Gelman et al. (2013), &lt;em&gt;Bayesian Data&amp;nbsp;Analysis&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Taking a step back, how might we conceptually model the act of reading? Well, suppose you&amp;#8217;re beginning a book. You wake up one morning, and, without commenting on whether nature is predetermined, let&amp;#8217;s say there&amp;#8217;s some probability you&amp;#8217;ll read your book on that day (for any&amp;nbsp;duration).&lt;/p&gt;
&lt;p&gt;Suppose you don&amp;#8217;t read; you&amp;#8217;ll simply log 0 hours. Suppose you do read; how much will it&amp;nbsp;be?&lt;/p&gt;
&lt;p&gt;There&amp;#8217;re a lot of factors that may enter the equation now, such as whether it&amp;#8217;s a weekend, the outside weather, or maybe whether you&amp;#8217;re nearing the end of the book and are motivated to read more to finish. For simplicity&amp;#8217;s sake, we&amp;#8217;ll assume that by some process, such as habit, you&amp;#8217;ll read about &lt;span class="math"&gt;\(x\)&lt;/span&gt; hours. For many people, &lt;span class="math"&gt;\(x=0.25, 0.5,\)&lt;/span&gt; or &lt;span class="math"&gt;\(1.0\)&lt;/span&gt; (plus or minus some), but this widely varies from person to&amp;nbsp;person.&lt;/p&gt;
&lt;p&gt;To put it all together, there&amp;#8217;s a probability you&amp;#8217;ll read on a given day, and when you do read, it might typically be around some number plus or minus a bit. With this model of how the world works (which probably fails in many ways, but for now we don&amp;#8217;t care), we can estimate when and how much we&amp;#8217;ll read, which can be used to calculate how many days left for us. Let&amp;#8217;s explore a case study with real&amp;nbsp;numbers.&lt;/p&gt;
&lt;h2&gt;Case&amp;nbsp;Study&lt;/h2&gt;
&lt;p&gt;I am reading &amp;#8221;The Brothers Karamazov&amp;#8221; by Fyodor Dostoevesky at the moment. It&amp;#8217;s long, so naturally I&amp;#8217;m curious when I&amp;#8217;ll finish it. I&amp;#8217;ve used &lt;a href="https://getbookly.com/"&gt;the Bookly iOS application&lt;/a&gt; to log most of my reading for the novel so far. I&amp;#8217;ve been reading for a bit more than a week, and have made a point to read each day. So far, here is a sample of my historical&amp;nbsp;data:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;Date&lt;/th&gt;
&lt;th&gt;Oct 4&lt;/th&gt;
&lt;th&gt;Oct 5&lt;/th&gt;
&lt;th&gt;Oct 6&lt;/th&gt;
&lt;th&gt;Oct 7&lt;/th&gt;
&lt;th&gt;Oct 8&lt;/th&gt;
&lt;th&gt;Oct 9&lt;/th&gt;
&lt;th&gt;Oct 10&lt;/th&gt;
&lt;th&gt;Oct 11&lt;/th&gt;
&lt;th&gt;Oct 12&lt;/th&gt;
&lt;th&gt;Oct 13&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;Duration&lt;/td&gt;
&lt;td&gt;26:53&lt;/td&gt;
&lt;td&gt;28:25&lt;/td&gt;
&lt;td&gt;1:15:16&lt;/td&gt;
&lt;td&gt;47:35&lt;/td&gt;
&lt;td&gt;1:03:20&lt;/td&gt;
&lt;td&gt;1:01:21&lt;/td&gt;
&lt;td&gt;1:01:56&lt;/td&gt;
&lt;td&gt;44:55&lt;/td&gt;
&lt;td&gt;1:06:28&lt;/td&gt;
&lt;td&gt;24:23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;Pages&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;29&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Including my other data, on average, I read about 49.4 minutes per day, and 20.7 pages per hour (2.9 minutes per page). At this point, I&amp;#8217;m 321 pages in, with 475 to go. That means roughly 22.9 hours remaining. So far I&amp;#8217;ve read every day. The naive estimate explained above puts me at 23 days away from&amp;nbsp;completion.&lt;/p&gt;
&lt;p&gt;However, I know I won&amp;#8217;t read every single day, and I&amp;#8217;d like to account for this variation. Moreover, it is of little help to have just a point estimate. If possible, I&amp;#8217;d like to know a probable range in which I&amp;#8217;ll finish (for all I know without accounting for the variation, this point estimate might stretch from 10 to 100&amp;nbsp;days).&lt;/p&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;If you&amp;#8217;re not interested in the math, you can skip to the next&amp;nbsp;section.&lt;/p&gt;
&lt;p&gt;First off, let our potential data be denoted &lt;span class="math"&gt;\(y = (y_1, \ldots, y_N)\)&lt;/span&gt;. Soon we&amp;#8217;ll introduce what values these can take&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(B\)&lt;/span&gt; be the event that we read on a given future day. We can model &lt;span class="math"&gt;\(B\)&lt;/span&gt; as a Bernoulli random event, &lt;span class="math"&gt;\(B \sim \text{Bern}(\theta)\)&lt;/span&gt; where &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; is the probability of a positive result form the event. If &lt;span class="math"&gt;\(\theta = 0.9\)&lt;/span&gt;, then we&amp;#8217;d say there&amp;#8217;s a 90% probability we&amp;#8217;ll read on a given future&amp;nbsp;day.&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(Y\)&lt;/span&gt; be the event denoting the number of hours (in decimal form) we read on a given day &lt;em&gt;when we do read&lt;/em&gt;. Using our historical data, we can model &lt;span class="math"&gt;\(Y\)&lt;/span&gt; as with a Student&amp;#8217;s t distribution, to account for greater uncertainty if we have very little data, namely &lt;span class="math"&gt;\(Y \sim \text{t}_\nu (\mu, \sigma)\)&lt;/span&gt; where &lt;span class="math"&gt;\(\nu\)&lt;/span&gt; is the degrees of freedom of the distribution, and &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; denote the mean and the standard deviation of the distribution. Including the mean and variance with the Student&amp;#8217;s t distribution I think is slightly unorthodox, but concisely and conveniently allows us to vary them both. Now, if &lt;span class="math"&gt;\(\mu = 1.0\)&lt;/span&gt; for example, then we&amp;#8217;d say that we&amp;#8217;re most likely to read an hour a day when we do read. Of course, it is technically false for us to claim that &lt;span class="math"&gt;\(Y\)&lt;/span&gt; is Student&amp;#8217;s t-distributed since in no world can we read less than zero hours in a day!&lt;d-footnote&gt;I&amp;#8217;ve been thinking of how to model this as a positive continuous distribution, but I&amp;#8217;m still new to this world and wanted to restrain myself for the time being. If you have helpful comments, please share.&lt;/d-footnote&gt; This is merely a computational convenience. However, in the model parameter specifications, we won&amp;#8217;t let the sampler sample values less than&amp;nbsp;0.&lt;/p&gt;
&lt;p&gt;Finally, to flesh out &lt;span class="math"&gt;\(y\)&lt;/span&gt;, we&amp;#8217;ll&amp;nbsp;say:&lt;/p&gt;
&lt;div class="math"&gt;$$
y_i \sim \begin{cases}
      \text{t}_\nu (\mu, \sigma) &amp;amp; \text{if}\;B_i \\
      0 &amp;amp; \text{otherwise}
   \end{cases}
$$&lt;/div&gt;
&lt;p&gt;To incorporate all the necessary variance, we also will define the distributions of &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mu\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; (&lt;span class="math"&gt;\(\nu\)&lt;/span&gt; will be supplied in the problem by the amount of data we&amp;#8217;re inputing). A perfect distribution for a Bernoulli probability is the Beta distribution, so &lt;span class="math"&gt;\(\theta \sim \text{Beta}(1,1)\)&lt;/span&gt;. &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; will be modeled by a normal distribution, centered around 10 minutes per day with a bit of variance (this number comes from a national average of how much Americans read per day). Lastly, &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; will be modeled by an inverse Gamma, with &lt;span class="math"&gt;\(\alpha = 0.07/0.93\)&lt;/span&gt; (to center the distribution over 0.93 hours) and &lt;span class="math"&gt;\(\beta = 1\)&lt;/span&gt;. All three of these help establish the larger model as a completely random data generation process. In &lt;code&gt;stan&lt;/code&gt; this looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;parameters&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;real&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;real&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;real&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="k"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kn"&gt;model&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;mu&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1667&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;inv_gamma&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.07&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;0.93&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;bernoulli&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;student_t&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We&amp;#8217;re making some arguable assumptions here as well. First, that each day is independent of the others&lt;d-footnote&gt;My knowledge is limited on how to treat this assumption, but perhaps &lt;a href="https://arxiv.org/pdf/1505.04321.pdf" target="_blank"&gt;sequential estimation&lt;/a&gt; might be in order.&lt;/d-footnote&gt;. Surely there&amp;#8217;s also some psychological feeling of not wanting to break my reading streak, subliminally pushing me to reading each day. Here, we&amp;#8217;re saying every day is a fresh day. Second, when we do read, the amount that we read is a random draw from a friendly distribution&lt;d-footnote&gt;As mentioned, this is likely an incredibly complex distribution, but like any statistician with proper due diligence, we&amp;#8217;re reducing it to one of those incredibly natural, perfectly symmetrical distributions.&lt;/d-footnote&gt;.&lt;/p&gt;
&lt;h2&gt;Prediction&lt;/h2&gt;
&lt;p&gt;With our model established, we would like to predict when we&amp;#8217;ll finish our book. This harks back to our original question. So how do we do&amp;nbsp;it?&lt;/p&gt;
&lt;p&gt;I will illustrate first with an example. Suppose we&amp;#8217;re reading a book and know &lt;em&gt;a priori&lt;/em&gt; that we have 10 hours remaining. We then calculate our reading pace so far, perhaps it&amp;#8217;s 0.5 hours per day. Suppose also we&amp;#8217;ve read 5 of 7 of the past&amp;nbsp;days.&lt;/p&gt;
&lt;p&gt;Then, to determine the number of days remaining, we&amp;#8217;ll start at day 1. On day 1, will we read? The probability we do will lie somewhere around &lt;span class="math"&gt;\(\hat{\theta}\)&lt;/span&gt;. Suppose we don&amp;#8217;t read though. Fine, skip to day 2, still with 10 hours remaining. Will we read on day 2? Suppose we do, and in fact we end up reading about &lt;span class="math"&gt;\(\tilde{\mu}_2\)&lt;/span&gt; hours. To illustrate, let&amp;#8217;s say it&amp;#8217;s 24 minutes, or 0.4&amp;nbsp;hours.&lt;/p&gt;
&lt;p&gt;So now we have &lt;span class="math"&gt;\(10 - 0.4 = 9.6\)&lt;/span&gt; hours remaining. Again, flip a biased coin (with probability of heads at &lt;span class="math"&gt;\(\hat{\theta}\)&lt;/span&gt;). It&amp;#8217;s heads, so we read again on day 3. This time, &lt;span class="math"&gt;\(\tilde{\mu}_3 = 0.6\)&lt;/span&gt; hours. Now there&amp;#8217;s &lt;span class="math"&gt;\(9.6-0.6 = 9.0\)&lt;/span&gt; hours&amp;nbsp;remaining.&lt;/p&gt;
&lt;p&gt;Follow this procedure while &lt;span class="math"&gt;\(10 - \sum^k_{i=1} B_k(\hat{\theta}) * \tilde{\text{t}}_{k+1} (\mu_k, \sigma_k) &amp;gt; 0\)&lt;/span&gt; (roughly). In the end, what is &lt;span class="math"&gt;\(k\)&lt;/span&gt;? Well, it is the number of days necessary to exhaust the pages in our book, given estimates of how often and how much we already&amp;nbsp;read.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;R&lt;/code&gt;, the algorithm looks like&amp;nbsp;such:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;draw&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;remaining_hours&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;posterior_theta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;posterior_mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;posterior_sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="n"&gt;total_read&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="n"&gt;days&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;

  &lt;span class="nf"&gt;while &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total_read&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;remaining_hours&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

    &lt;span class="n"&gt;to_read&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;rbernoulli&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;posterior_theta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nf"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;to_read&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

      &lt;span class="n"&gt;mu&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;posterior_mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;posterior_sigma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;est&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nf"&gt;rt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;days&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;

      &lt;span class="nf"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;est&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;est&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;next&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

      &lt;span class="n"&gt;total_read&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;total_read&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;est&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;days&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;days&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nf"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;Let&amp;#8217;s go back to my case study for &amp;#8221;The Brothers Karamazov&amp;#8221;. If we fit the model with my historical reading data for the book, our model samples each parameter like&amp;nbsp;so:&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/parameter-estimates.png" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    4,000 samples drawn for each parameter to estimate the parameter values.
&lt;/div&gt;

&lt;p&gt;Ultimately, the estimates for each parameter are: &lt;span class="math"&gt;\(\hat{\mu} = 0.81\)&lt;/span&gt;, &lt;span class="math"&gt;\(\hat{\sigma} = 0.37\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\hat{\theta} = 0.95\)&lt;/span&gt;. This means there&amp;#8217;s an average 95% probability I&amp;#8217;ll read on a given day, and when I do read it will on average be 48.6&amp;nbsp;minutes.&lt;/p&gt;
&lt;p&gt;Using the algorithm described above, we will sample 2,000 draws of the posterior predictive distribution, which uses &lt;span class="math"&gt;\(\mu\)&lt;/span&gt;, &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; to determine the number of days remaining. Therefore, the posterior predictive distribution of the days remaining, given a sample of my historical reading data, looks&amp;nbsp;like:&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/days-remaining-hist.png" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    Histogram of days remaining on my book drawn from the posterior predictive distribution
&lt;/div&gt;

&lt;p&gt;The mean here is 28.7, with a median of 29 (89% Credible Interval: [24, 34])&lt;d-footnote&gt;For an explanation of why I&amp;#8217;m using 89% Credible Intervals, see &lt;a href="https://easystats.github.io/bayestestR/articles/credible_interval.html#why-is-the-default-89" target="_blank"&gt;this nice summary&lt;/a&gt;. In short, all intervals are arbitrary, so why not pick one that&amp;#8217;s slightly less arbitrary.&lt;/d-footnote&gt;. We can take this one step further and visualize how the prediction accuracy improves over time (i.e. with more&amp;nbsp;data).&lt;/p&gt;
&lt;p&gt;For each day in sequence, we can re-estimate the model parameters (with progressively more data). On each re-fit, we&amp;#8217;ll add up the hours we estimate we have left and the hours we know we will read on future days to say how long it will take to finish &lt;em&gt;from that day&lt;/em&gt;. As we artificially gain information, our estimates naturally become more precise. This is because we home in on a better estimate for how often we read and much we read when we do. We can find 95% and 68.2% credible intervals as well. In fact, we can nicely display this all as&amp;nbsp;such:&lt;/p&gt;
&lt;div id="container" style="width:100%; height:400px;"&gt;&lt;/div&gt;
&lt;div class="caption"&gt;
    As our model sees more data with each new day, the parameter estimates become more precise. The dotted line represents the estimates from the simple model describes in the intro (pages remaining / cumulative pace). The complex model is much more pessimistic, eventually the two will converge though.
&lt;/div&gt;

&lt;p&gt;We can see that the number of days remaining is decreasing over time, since we are taking off an absolute number of pages from the book. We can also see that our estimation is getting more precise, as a result of relying less on the priors and more on the data. You can also see how our model built here compares to the prediction from the simple model explained in Existing Models. The complex model, which factors in a variety of sources of variance, reflects our day to day behavior better but is clearly more pessimistic. However, as I near the end of my book the two lines will&amp;nbsp;converge.&lt;/p&gt;
&lt;p&gt;To interpret this chart further, we might conclude that I am most likely to finish my book in 29 days, which at the time of writing is November 19, but there&amp;#8217;s a full 89% probability that I&amp;#8217;ll finish the book within 24 to 34&amp;nbsp;days.&lt;/p&gt;
&lt;p&gt;Consider our original estimation: 23 days until completion. Although kind of close, it doesn&amp;#8217;t account for the fact that I might not read every day in the near future. Moreover, if I do end up missing a day, the complex model will adapt and project the date further out. The simple model simply won&amp;#8217;t&amp;nbsp;change.&lt;/p&gt;
&lt;h2&gt;Overall&lt;/h2&gt;
&lt;p&gt;Overall, this is a case study of how one might predict when they&amp;#8217;ll finish a book, but with a bit of humanity&amp;#8217;s pitfalls injected in it (there &lt;em&gt;is&lt;/em&gt; some chance I won&amp;#8217;t read everyday!). I am happy to know how quickly I will finish my book since it allows me to set goals and feel good about my progress, knowing that sooner or later (most probably in less than Y days) I will be able to put the book aside and begin the next. I&amp;#8217;m still a novice statistician, so if there&amp;#8217;s gross misunderstandings in my work, please point them out (even if you&amp;#8217;re not sure&amp;nbsp;yourself).&lt;/p&gt;
&lt;p&gt;Reading is not all a numbers game. And I&amp;#8217;m not racing anyone. I am, however, eager to read as much as a can before I can&amp;#8217;t. Books are meant to be enjoyed. If you&amp;#8217;re not enjoying them while reading none of the above has any validity. It can be tempting to scold or punish yourself or feel guilty for not meeting your reading goal. If you do not meet the estimated average time to completion&amp;#8212;-keep in mind that the distribution is infinite and some books will either take a &lt;em&gt;very&lt;/em&gt; long time to finish, or will never be finished, and that&amp;#8217;s okay&amp;nbsp;too.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="meta"></category><category term="statistics"></category><category term="rlang"></category></entry><entry><title>On Locke and the Trump Administration</title><link href="/posts/2020/Oct/locke-trump/" rel="alternate"></link><published>2020-10-17T18:00:00-07:00</published><updated>2020-10-17T18:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-10-17:/posts/2020/Oct/locke-trump/</id><summary type="html">&lt;p&gt;An analogy between Locke&amp;#8217;s standard of tyranny and the Trump&amp;nbsp;Administration&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this essay I hope to frame the Trump Administration with principles derived from John Locke&amp;#8217;s &lt;em&gt;Second Treatise on Government&lt;/em&gt;, a foundational piece in the development of Western democracy and liberalism. First, I&amp;#8217;ll introduce Locke&amp;#8217;s perspective on virtuous government, especially his remarks on tyranny and despotic government. Then, I&amp;#8217;ll cover some behavior from the Trump Administration that one might argue falls under Locke&amp;#8217;s definition of &amp;#8220;unjust&amp;#8221; government. Lastly, we&amp;#8217;ll question the analogy, its possible implications, and where to go from&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" width="80%" height="" src="/images/john-locke.jpg" alt="A portrait painting of John Locke" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    &lt;strong&gt;Figure 1.&lt;/strong&gt; John Locke by Godfrey Kneller (c1697). Courtesy Hermitage Museum/Wikipedia via aeon.co
&lt;/div&gt;

&lt;p&gt;John Locke in his &lt;em&gt;Second Treatise on Government&lt;/em&gt;&lt;d-footnote&gt;The &lt;span class="font-italic"&gt; Second Treatise&lt;/span&gt; was actually a rebuttal to Sir Robert Filmer&amp;#8217;s &lt;a href="https://en.wikipedia.org/wiki/Patriarcha" target="_blank" class="font-italic"&gt;Patriarcha&lt;/a&gt;, rejecting the notion of rule by Divine Right.&lt;/d-footnote&gt; sought to distinguish &lt;em&gt;just&lt;/em&gt; government from &lt;em&gt;unjust&lt;/em&gt; government. It is famous for its discussion of natural rights, social contract, and private property in general. Locke was very much devoted to rejecting authoritarianism, and is made clear through the piece. He is not without controversy, for example regarding &lt;a href="https://aeon.co/essays/does-lockes-entanglement-with-slavery-undermine-his-philosophy" target="_blank"&gt;his involvement in the dispute over slavery in society&lt;/a&gt;&lt;d-footnote&gt;One chapter of the Second Treatise covered slavery, for which he offers a perhaps surprisingly limited role, and offers little argumentative support for the Afro-American slave trade. From the article linked: &amp;#8220;It is a deep error, therefore, to contend that Locke’s role in the Carolina constitutions should guide interpretation of his later work, much less liberalism.&amp;#8221;&lt;/d-footnote&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately, his writing paved the way for Western civilizations, &lt;a href="https://www.johnlocke.org/john-locke-his-american-and-carolinian-legacy/" target="_blank"&gt;including the Founding Fathers of the United States&lt;/a&gt;. Of course, we&amp;#8217;ll never know what he would have thought about modern government and politics, but we can try to&amp;nbsp;imagine.&lt;/p&gt;
&lt;h1&gt;What is&amp;nbsp;Tyranny?&lt;/h1&gt;
&lt;p&gt;To begin, I will introduce a quote from Locke from the section &lt;em&gt;Of Political or Civil Society&lt;/em&gt;, where he states&amp;nbsp;movingly:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Man being born&amp;#8230; with a title to perfect freedom, and an uncontrolled enjoyment of all the rights and privileges of the law of nature, equally with any other man&amp;#8230; hath by nature a power, not only to preserve his property, that is, his life, liberty and estate, against the injuries and attempts of other&amp;nbsp;men&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This sets well the stage for the rest of the discussion. In particular, Locke ascertains that individuals in society should have an unquestionable right to their own lives, freedom, and land, and this should always be the case and others should not be allowed to break&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;Locke claims that government should be limited and constitutional, with the authority only to function as society, as the people, entrusted in it. He argues that this function, or &amp;#8220;chief end,&amp;#8221; of &amp;#8220;men&amp;#8217;s uniting into common-wealths,&amp;#8221; is simply &amp;#8220;the preservation of their&amp;nbsp;property.&amp;#8221;&lt;/p&gt;
&lt;p&gt;So, this begs the question, what happens if the government fails to achieve or attempt to achieve this function?&amp;nbsp;Well,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;for where the power, that is put in any hands for the government of the people&amp;#8230; is applied to other ends, and made use of to impoverish, harass, or subdue&lt;d-footnote&gt;I had to look up a definition to truly understand &amp;#8220;subdue&amp;#8221;. From Merriam Webster: to conquer and bring into subjection, to bring under control especially by an exertion of the will, or to reduce the intensity or degree of.&lt;/d-footnote&gt; them to the arbitrary and irregular commands of those who have [property]; there it presently becomes&amp;nbsp;tyranny&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Locke further clarifies that tyranny is &amp;#8220;the exercise of power beyond right&amp;#8221; and that &amp;#8220;where-ever law ends, tyranny begins.&amp;#8221; &lt;d-footnote&gt;I find this second quote particularly beautiful.&lt;/d-footnote&gt; The federal government of today is notorious in its exercise of power, with many claiming it is completely justified for the safety of the nation, and others firing back that in most cases these are gross abuses of this&amp;nbsp;power.&lt;/p&gt;
&lt;h1&gt;The Trump&amp;nbsp;Administration&lt;/h1&gt;
&lt;p&gt;Four years ago, the electoral college voted Donald Trump into the White House. Since then much controversy and conspiracy has penetrated the American public. I am curious how Locke&amp;#8217;s principles would apply to the Trump Administration as a democratic government. Of course, modern America is vastly different from the monarchies and colonial revolutions with which Locke was accustomed, so in some regards it&amp;#8217;s moot to even attempt the comparison. Nonetheless, many might argue that the Trump Administration has acted on numerous occasions with what Locke might call &amp;#8220;arbitrary&amp;#8221;&amp;nbsp;power.&lt;/p&gt;
&lt;p&gt;For example, let&amp;#8217;s dive straight into &lt;a href="https://apnews.com/article/law-and-order-violence-politics-oregon-racial-injustice-b35e37208e261278ecc33154c37d5d85" target="_blank"&gt;the federal deployment of heavily armed agents to protesting areas across the nation&lt;/a&gt;. Due to the killing of George Floyd, protests and calls for change began in almost all major cities in the country. Some of these turned violent, with the property rights of some being infringed upon. Therefore, it would seem reasonable, if not proper, for federal agents to step in to quell the violence and reinstate the right and privilege of citizens to preserve their&amp;nbsp;property.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" width="80%" height="" src="/images/portland-protestor.jpg" alt="A protester throws a tear gas canister back at police during a Black Lives Matter protest in Portland, Oregon." uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    &lt;strong&gt;Figure 2.&lt;/strong&gt; A protester throws a tear gas canister back at police during a Black Lives Matter protest in Portland, Oregon. Courtesy &lt;a href="https://unsplash.com/@titofoto?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;Tito Texidor &lt;span class="caps"&gt;III&lt;/span&gt;&lt;/a&gt; on &lt;a href="https://unsplash.com/s/photos/%22tear-gas%22?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;Unsplash&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;However, &lt;a href="https://www.nbcnews.com/politics/politics-news/does-trump-have-right-send-federal-agents-quell-violent-protests-n1235087" target="_blank"&gt;many argue&lt;/a&gt; that the deployed federal agents have exceeded their power, for example, by detaining demonstrators without probable cause. Moreover, the agents have &amp;#8220;responded with huge plumes of tear gas, rubber bullets and flash bang grenades,&amp;#8221; according to &lt;a href="https://apnews.com/article/b57315d97dd2146c4a89b4636faa7b70" target="_blank"&gt;&lt;span class="caps"&gt;AP&lt;/span&gt; News&lt;/a&gt;. To what extent is this use of force justified? Is this an unnecessary display of power, with the intent to &amp;#8220;harass&amp;#8221; or otherwise &amp;#8220;subdue&amp;#8221; the civilian, beyond what&amp;#8217;s necessary to protect the right to preserve one&amp;#8217;s&amp;nbsp;property?&lt;/p&gt;
&lt;p&gt;As another example, consider the language and rhetoric employed by the Trump Administration. As &lt;a href="https://www.brookings.edu/blog/fixgov/2020/05/01/destroying-trust-in-the-media-science-and-government-has-left-america-vulnerable-to-disaster/" target="_blank"&gt;the Brookings Institute&lt;/a&gt; put it, Trump has &amp;#8220;taken to a new level&amp;#8221; the discrediting of the media, science, and essential government agencies. His persistent attacks on (especially Left-leaning) media and news sources undoubtedly has many paradoxically questioning the veracity of factual reporting. With &lt;span class="caps"&gt;COVID&lt;/span&gt;-19 taking a devastating toll on not only the American public&amp;#8217;s physical health, but also mental health, it is difficult to understand why there is so much friction and derision toward the scientific community. Lastly, there has been constant denial and delay regarding the virus and the calls for racial justice, which has undermined the capabilities of local and state governments. How has this tactical (or accidental) behavior eroded the trust between citizens and their federal government? Does such behavior protect society? Does it intellectually subdue the&amp;nbsp;people?&lt;/p&gt;
&lt;p&gt;On the contrary, it seems as though many of the legislative changes enacted under the Trump Administration have revolved around foreign affairs, which I believe is slightly beyond the scope of Locke&amp;#8217;s principles. For example, &lt;a href="https://en.wikipedia.org/wiki/Executive_Order_13769" target="_blank"&gt;Executive Order 13769&lt;/a&gt; was a big controversy&lt;d-footnote&gt;From the &lt;a href="https://www.csmonitor.com/USA/Politics/2017/0206/Trump-s-biggest-executive-actions-explained/Travel-ban-for-immigrants-refugees-Jan.-27-2017" target="_blank"&gt;Christian Science Monitor&lt;/a&gt;: &amp;#8220;Executive Order: Protecting the Nation from Foreign Terrorist Entry into the United States suspends visa issuance as well as immigration entry to “nationals of countries of particular concerns” for 90 days. The Trump administration applied this order to seven predominantly Muslim countries: Iraq, Iran, Syria, Yemen, Sudan, Somalia, and Libya. The order also suspends all refugee admission to the &lt;span class="caps"&gt;US&lt;/span&gt; for 120 days and indefinitely denies entry to all Syrian refugees.&amp;#8221;&lt;/d-footnote&gt;, but I&amp;#8217;m not sure Locke would really argue against such drastic (and ill-motivated) measures in the name of protecting society. One might rebut that this Executive Order was in fact a form of harassment against existing Muslim citizens. I&amp;#8217;ll leave it to you to judge how Locke would&amp;nbsp;stand.&lt;/p&gt;
&lt;h1&gt;Implications&lt;/h1&gt;
&lt;p&gt;Knowing what we do about Locke and a small sample of the Trump Administration&amp;#8217;s actions, let&amp;#8217;s explore whether such actions meet Locke&amp;#8217;s standard of&amp;nbsp;tyranny.&lt;/p&gt;
&lt;p&gt;According to &lt;a href="https://www.pewresearch.org/politics/2020/08/06/views-of-covid-19-response-by-trump-hospitals-cdc-and-other-officials/#trump-approval-lower-than-in-march-virtually-unchanged-since-june" target="_blank"&gt;Pew Research&lt;/a&gt;, about 59% of Americans disapprove of Trump&amp;#8217;s performance as president. There are many reasons one might disapprove of any president&amp;#8217;s job, but based on the evidence above, a strong reason to disapprove of Trump&amp;#8217;s would be his unjustified harassing and subduing of the American people. The &lt;em&gt;Second Treatise&lt;/em&gt; is notoriously ambiguous, including around its terms of harassment, subduing, and impoverishment; however, it is not unlikely that some of the president&amp;#8217;s actions might be labeled as Locke described. If we agree that some (is &amp;#8220;some&amp;#8221; all that is necessary?) of Trump&amp;#8217;s behavior has subdued the rights of citizens or harassed their well-being, then it would be fair to label these actions as&amp;nbsp;tyranny.&lt;/p&gt;
&lt;p&gt;The question then becomes, are a few tyrannical actions indicative of an entire government marked by&amp;nbsp;tyranny?&lt;/p&gt;
&lt;p&gt;Suppose the Trump Administration &lt;em&gt;is&lt;/em&gt; marked by tyranny, what then? Well, as Locke puts&amp;nbsp;it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The people generally ill treated&amp;#8230; will be ready upon any occasion to ease themselves of a burden that sits heavy upon&amp;nbsp;them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He continues a short while after that to&amp;nbsp;claim,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;if a long train of abuses, prevarications&lt;d-footnote&gt;meaning: to deviate from the truth&lt;/d-footnote&gt; and artifices, all tending the same way, make [the government&amp;#8217;s intentions] visible to the people&amp;#8230; it is not to be wondered, that they should then rouze themselves, and endeavour to put the rule into such hands which may secure to them the ends for which government was at first&amp;nbsp;erected&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Is it time for the unsatisfied American people to rise up and put an end to the current government, in order to re-establish a better one? To be clear, Locke made the distinction between just government&amp;#8212;-which seeks to preserve the life, liberty, and property of its citizens&amp;#8212;-and unjust government&amp;#8212;-which systematically violates the citizens&amp;#8217; natural rights. And to put it simply, Locke also justified rebellion under the&amp;nbsp;latter.&lt;/p&gt;
&lt;p&gt;Regardless, modern &lt;span class="caps"&gt;US&lt;/span&gt; government was not orchestrated exactly by Locke&amp;#8217;s theories, and we are not governed by laws which he himself wrote. Thus, it seems farcical to suggest anyone overthrow the government. That would be weighty. However, one should not refrain from judging modern government to the principles upon which its&amp;nbsp;stands.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;John Locke, unlike any other, built the proto-foundation of America. He had a clear stance against authoritarianism and arbitrary power. Today&amp;#8217;s federal government has caused a stir in the American public, perhaps unlike any other in the last 50 years. Locke defined how governments could fail their people and come to a dissolution. The Trump Administration, on several occasions, has acted in ways that hark back to Locke&amp;#8217;s definition of tyranny. Locke defined rebels as those who &amp;#8220;by force justify their violation&amp;#8221; of the &amp;#8220;constitution and the laws of the government.&amp;#8221; Is it time to rebel, to &amp;#8220;bring back again the state of&amp;nbsp;war&amp;#8221;?&lt;/p&gt;
&lt;p&gt;Let me know on &lt;a href="https://twitter.com/alexliebscher0" target="_blank"&gt;Twitter&lt;/a&gt; or by &lt;a href="mailto:alexliebscher0@gmail.com"&gt;email&lt;/a&gt; what you think of my analogy drawn between Locke&amp;#8217;s definition of tyranny and the Trump&amp;nbsp;Administration!&lt;/p&gt;</content><category term="meta"></category><category term="society"></category><category term="philosophy"></category><category term="critique"></category></entry><entry><title>Review: Evaluating Neural Toxic Degeneration in Language Models</title><link href="/posts/2020/Oct/toxic-degeneration/" rel="alternate"></link><published>2020-10-17T00:00:00-07:00</published><updated>2020-10-17T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-10-17:/posts/2020/Oct/toxic-degeneration/</id><summary type="html">&lt;p&gt;Language Models suffer from degenerate and biased behavior, can we fix&amp;nbsp;that?&lt;/p&gt;</summary><content type="html">&lt;p&gt;This review is on &amp;#8220;&lt;a href="https://api.semanticscholar.org/CorpusID:221878771"&gt;RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models&lt;/a&gt;&amp;#8221; from a group of researchers at the University of Washington and the Allen Institute for &lt;span class="caps"&gt;AI&lt;/span&gt;, to be found in the &lt;em&gt;Findings of &lt;span class="caps"&gt;EMNLP&lt;/span&gt; 2020&lt;/em&gt; &lt;d-footnote&gt;&lt;a href="https://2020.emnlp.org/blog/2020-04-19-findings-of-emnlp" target="_blank"&gt;A new (as of April 2020) &amp;#8220;companion&amp;#8221; to &lt;span class="caps"&gt;EMNLP&lt;/span&gt;&lt;/a&gt; which offers sort of a middle group between rejection and acceptance into the main conference. It seems like a happy middle ground for still notable research.&lt;/d-footnote&gt;. The authors set the stage by&amp;nbsp;saying,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;language models (LMs) pretrained on large web text corpora suffer from degenerate and biased&amp;nbsp;behavior&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To no one&amp;#8217;s surprise, LMs are being deployed at an increasing pace due to the popularity of tools such as &lt;a href="https://huggingface.co/" target="_blank"&gt;huggingface&lt;/a&gt;. The authors contribute to recent work on LMs by first offering an operationalization of toxic model generations, then introduce a novel dataset of labeled toxic and non-toxic phrases, and then demonstrate the danger of LMs (even when tuned to avoid toxic language). The authors evaluate a few different methods for preventing toxic language generation, although none is perfect. Lastly, they partially diagnose what&amp;#8217;s causing bad generations (hint: garbage in, garbage out), and offer some recommendations to ameliorate the&amp;nbsp;issue.&lt;/p&gt;
&lt;p&gt;I was interested in this paper because it is one of those that integrates both &lt;span class="caps"&gt;NLP&lt;/span&gt; and sociolinguistics. Before even trying to prevent a &lt;span class="caps"&gt;LM&lt;/span&gt; from spitting forth profanity, one has to define and operationalize some very tricky subjects. What exactly is profanity? What is toxicity? At what point does a word move from being uncomfortable or taboo to profane or marginalizing? How does the definition of toxic change from person to person? Can something be profane when said by one person, but not another? Only one, maybe two, of these is discussed in this article, but I found them useful to consider while&amp;nbsp;reading.&lt;/p&gt;
&lt;h2&gt;Language Model&amp;nbsp;Background&lt;/h2&gt;
&lt;p&gt;Before beginning, I&amp;#8217;ll give a bit of background on generative Language Models. In plain English, a Language Model scans huge collections of documents (millions of documents), word by word, learning statistical associations between words and their neighbors, and is then able to predict the next word in a phrase by just looking for the most probable in the English language. Your iPhone does this (if you have predictive typing turned on), as does Gmail when you&amp;#8217;re drafting an email, and a suite of other&amp;nbsp;tools.&lt;/p&gt;
&lt;p&gt;You may have heard of &lt;span class="caps"&gt;GPT&lt;/span&gt;-3 (and &lt;a href="https://openai.com/blog/gpt-2-1-5b-release/" target="_blank"&gt;it&amp;#8217;s predecessors&lt;/a&gt;)&lt;d-footnote&gt;For an excellent illustrated explanation, I recommend &lt;a href="http://jalammar.github.io/illustrated-gpt2" target="_blank"&gt;the classic from Jay Alammar&lt;/a&gt;.&lt;/d-footnote&gt;, which has been &lt;a href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential" target="_blank"&gt;in&lt;/a&gt; &lt;a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/" target="_blank"&gt;the&lt;/a&gt; &lt;a href="https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3" target="_blank"&gt;news&lt;/a&gt; &lt;a href="https://www.vox.com/future-perfect/21355768/gpt-3-ai-openai-turing-test-language"&gt;a lot&lt;/a&gt;, or of &lt;a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270" target="_blank"&gt;&lt;span class="caps"&gt;BERT&lt;/span&gt;&lt;/a&gt;, which might have received more attention in the academic press than the public press. The &lt;span class="caps"&gt;GPT&lt;/span&gt; family and &lt;span class="caps"&gt;BERT&lt;/span&gt; are both Language Models. &lt;span class="caps"&gt;GPT&lt;/span&gt; is distinct from &lt;span class="caps"&gt;BERT&lt;/span&gt; though in that it is &lt;em&gt;auto-regressive&lt;/em&gt;, meaning it progressively sees and trains on more of the sentence as it reads, instead of seeing the whole sentence at once. This is what makes it particular useful for predicting what will comes next, making it &lt;em&gt;generative&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Operationalizing&amp;nbsp;Toxicity&lt;/h2&gt;
&lt;p&gt;The authors state the importance of having well-annotated data, and that the definition of &amp;#8220;toxic&amp;#8221; is crucial to their argument, although they pass off the responsibility to another tool. They do correctly note that hand-annotating such a large dataset is unfeasible. In the&amp;nbsp;end,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We rely on &lt;a href="https://www.perspectiveapi.com/" target="_blank"&gt;Perspective &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt;, an automated tool for toxic language and hate speech&amp;nbsp;detection&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;span class="caps"&gt;API&lt;/span&gt;, when given a linguistic form (e.g., a sentence), calculates a score, or probability of toxicity. The authors then (perhaps unjustifiably) label an input prompt as toxic if it has a score of over 0.5, otherwise it&amp;#8217;s labeled non-toxic. The authors confess that the &lt;span class="caps"&gt;API&lt;/span&gt; likely suffers from an over-reliance on lexical cues to detect toxicity, where lexical cues basically just means specific words, such as swear words or&amp;nbsp;slurs.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;RealToxicityPrompts&lt;/em&gt;&amp;nbsp;Dataset&lt;/h2&gt;
&lt;p&gt;One of the main contributions of the paper is the dataset the authors compiled. It consists of 100,000 sentences, spanning the whole range of toxicities, that were split in half into a &lt;em&gt;prompt&lt;/em&gt; and a &lt;em&gt;continuation&lt;/em&gt;. Both halves were scored for toxicity. Their hope is that by creating this big dataset of English web text scored for toxicity, others will be able to &amp;#8220;systematically evaluate and compare the generations from language models&amp;#8221; with this &amp;#8220;testbed for&amp;nbsp;toxicity.&amp;#8221;&lt;/p&gt;
&lt;h2&gt;Detoxifying Model&amp;nbsp;Generations&lt;/h2&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/toxicity-generations.png" height="" width="50%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    &lt;strong&gt;Figure 1.&lt;/strong&gt; Four non-toxic prompts which cause several pretrained LMs to generate highly toxic output. Credit: Gehman et al. (2020)
&lt;/div&gt;

&lt;p&gt;As illustrated in Figure 1, even non-toxic prompts (those with a toxicity score from Perspective less than 0.5) lead to toxic generations. The crux of the paper is in their assessment of five ways to detoxify &lt;span class="caps"&gt;LM&lt;/span&gt; generations. Below are quick summaries of these methods and how they reduce toxic&amp;nbsp;generations.&lt;/p&gt;
&lt;h3&gt;Data-Based&amp;nbsp;Detoxification&lt;/h3&gt;
&lt;dl&gt;
&lt;dt&gt;Domain-Adaptive Pretraining (&lt;span class="caps"&gt;DAPT&lt;/span&gt;)&lt;/dt&gt;
&lt;dd&gt;Perform additional pretraining on a smaller &lt;em&gt;non-toxic&lt;/em&gt;&amp;nbsp;corpus.&lt;/dd&gt;
&lt;dt&gt;Attribute&amp;nbsp;Conditioning&lt;/dt&gt;
&lt;dd&gt;Perform additional pretraining on a sample of the corpus which has been labeled with either a toxic attribute token, &lt;code&gt;&amp;lt;|toxic|&amp;gt;&lt;/code&gt;, or a non-toxic attribute token, &lt;code&gt;&amp;lt;|nontoxic|&amp;gt;&lt;/code&gt;. During generation, prepend the prompt with &lt;code&gt;&amp;lt;|nontoxic|&amp;gt;&lt;/code&gt; specifically.&lt;/dd&gt;
&lt;/dl&gt;
&lt;h3&gt;Decoding-Based&amp;nbsp;Detoxification&lt;/h3&gt;
&lt;dl&gt;
&lt;dt&gt;Vocabulary&amp;nbsp;Shifting&lt;/dt&gt;
&lt;dd&gt;Modify the decoding algorithm to give higher probability to non-toxic tokens. Learns a weight for each vocabulary token which represents the association between each token and&amp;nbsp;(non-)toxicity.&lt;/dd&gt;
&lt;dt&gt;Word&amp;nbsp;Filtering&lt;/dt&gt;
&lt;dd&gt;Create a blacklist of profanity, slurs, and swearwords and set the probability of generating those words to zero to prevent the LMs from generating them&amp;nbsp;altogether.&lt;/dd&gt;
&lt;dt&gt;&lt;a href="https://openreview.net/pdf?id=H1edEyBKDS" target="_blank"&gt;&lt;span class="caps"&gt;PPLM&lt;/span&gt;&lt;/a&gt;&lt;/dt&gt;
&lt;dd&gt;Combine a pretrained, unconditional language model with one or more simple attribute models, which are small and cheap models that figure out latent gradients between attributes and the pretrained language models to steer&amp;nbsp;outputs.&lt;/dd&gt;
&lt;/dl&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;As one might expect, none of these detoxification methods completely eradicated toxic generations; and toxic prompts yielded higher toxicity in generation than non-toxic prompts. What&amp;#8217;s somewhat surprising is that non-toxic prompts occasionally also led to toxic generations. It should be clear then that even benign models can be harmful. The authors point out that it&amp;#8217;s also surprising that the &lt;span class="caps"&gt;CTRL&lt;/span&gt;-&lt;span class="caps"&gt;WIKI&lt;/span&gt; model produced toxic content, despite being pretrained to generate Wikipedia-style output&lt;d-footnote&gt;The authors also state it&amp;#8217;s interesting since &amp;#8220;[the model] was trained on just Wikipedia.&amp;#8221; I&amp;#8217;m not sure this statement is true after skimming the original &lt;span class="caps"&gt;CTRL&lt;/span&gt; paper from Kaskar et al. (2019).&lt;/d-footnote&gt;. Furthermore, &lt;span class="caps"&gt;DAPT&lt;/span&gt; is one of the most effective methods (which I found surprising, given its simplicity), along with vocabulary shifting, and &lt;span class="caps"&gt;PPLM&lt;/span&gt;. The authors lastly state that steering generations after pretraining must thus be crucial for preventing toxic&amp;nbsp;output.&lt;/p&gt;
&lt;p&gt;There were some phrases, which when used to prompt the models consistently returned toxic generations. These prompts were often toxic themselves or had the opening phrase of known toxic sentences (&amp;#8220;his rant was full of&amp;#8230;&amp;#8221;). Lastly, about 10% of the prompts came from unreliable or toxic data sources, which we get into&amp;nbsp;next.&lt;/p&gt;
&lt;h2&gt;Analysis of Web Text&amp;nbsp;Toxicity&lt;/h2&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/toxicity-corpora.png" height="" width="40%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
&lt;strong&gt;Figure 2.&lt;/strong&gt; About 2.1% and 4.3% of &lt;span class="caps"&gt;OWTC&lt;/span&gt; and OpenAI-&lt;span class="caps"&gt;WT&lt;/span&gt; (the corpora which the x and x models were trained on) are toxic content (note: log-transformed y-axis). Credit: Gehman et al. (2020)
&lt;/div&gt;

&lt;p&gt;Up next, the authors attempt to quantify the toxicity present in the training data for the LMs they tested. Specifically, the training data were OpenAI-&lt;span class="caps"&gt;WT&lt;/span&gt; (&lt;span class="caps"&gt;GPT&lt;/span&gt;-2&amp;#8217;s training data) and its open-source replica &lt;span class="caps"&gt;OWTC&lt;/span&gt;. There is about 29% overlap between the two datasets, which is low enough to come to interesting conclusions about how the models may be affected by their training&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;In Figure 2 (note: it&amp;#8217;s log-transformed), we can see that about 2.1% and 4.3% of &lt;span class="caps"&gt;OWTC&lt;/span&gt; and OpenAI-&lt;span class="caps"&gt;WT&lt;/span&gt; are toxic content. About 3% of &lt;span class="caps"&gt;OWTC&lt;/span&gt; in fact comes from links shared on banned or quarantined subreddits&lt;d-footnote&gt;Banned subreddits are inaccessible via the website and only via data dumps, whereas quarantined subreddits are special-access only but still online.&lt;/d-footnote&gt;.&lt;/p&gt;
&lt;h2&gt;Recommendations&lt;/h2&gt;
&lt;p&gt;The authors conclude with a discussion and a variety of recommendations for &lt;span class="caps"&gt;NLP&lt;/span&gt; researchers. First, it should seem apparent that there&amp;#8217;s an issue with LMs generating toxic content. From the analysis of the training corpora, we might guess that this degeneracy comes from poor training data. They concede that the steering methods did have some positive effect, but did not completely resolve the problem. There are three primary implications&amp;nbsp;proposed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Can language models ever fully &amp;#8216;forget&amp;#8217; toxic pretraining data through further&amp;nbsp;adaptation?&amp;#8221;&lt;/p&gt;
&lt;p&gt;Essentially, you can start with a model trained on some bad data, but is there any amount of finite data you could then continue pretraining on to wash out, to &amp;#8220;forget&amp;#8221;, the bad stuff? It seems as though the LMs are &amp;#8220;memorizing&amp;#8221; the bad content, which might come from such content being more salient to the model. The authors recommend for future work to explore whether some types of toxicity are more difficult for models to&amp;nbsp;forget.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Purposeful&amp;nbsp;decoding&lt;/p&gt;
&lt;p&gt;One of the most promising methods of eliminating toxic generations was &lt;span class="caps"&gt;PPLM&lt;/span&gt;. Perhaps there exist other methods to aid in the decoding phase and prevent toxic generation. For example, using handpicked toxic documents as &amp;#8220;negative examples&amp;#8221; which the model would learn not to produce. The authors also nebulously suggest &amp;#8220;infusing models with more sophisticated or nuanced representations of social&amp;nbsp;biases.&amp;#8221;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choice of Pretraining&amp;nbsp;Data&lt;/p&gt;
&lt;p&gt;The authors also call for a dramatic introspection of the training data with which LMs learn on. Some issues arise when relying on huge swathes of data with very little filtering e.g., Reddit is known to have a biased user-base. This should call to question: &amp;#8220;who decides whose voices are going to be learned by the language model.&amp;#8221; One appealing recommendation is to make the pretraining process more human-centered, including through participatory&amp;nbsp;design.&lt;/p&gt;
&lt;p&gt;The authors lastly caution that curating pretraining data without deep thought might have unintended side-effects, such as filtering out benign text from African American authors/users. They suggest engaging with the end-user during this&amp;nbsp;phase.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Take-aways&lt;/h2&gt;
&lt;p&gt;It&amp;#8217;s a compelling and mostly uncontroversial article, which clearly highlights shortcomings currently in &lt;span class="caps"&gt;NLP&lt;/span&gt;. I think too little is said about the impact on industry (companies are currently trying to solve this problem), and society as a whole. In fact, regarding the latter, I think more could have been said about the practical implications of &lt;span class="caps"&gt;LM&lt;/span&gt; degeneration on the spreading of misinformation. In sum though, the authors created a valuable dataset for future research, and exposed a lower bound on toxicity degeneracy in&amp;nbsp;LMs.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m also a little unsatisfied by the authors&amp;#8217; operationalization of toxicity. While I understand their desire to create a large dataset for other researchers to train on, I&amp;#8217;m not sure the Perspective &lt;span class="caps"&gt;API&lt;/span&gt; should be considered the end of the conversation. Undoubtedly, it will produce false positives and false negatives (which the authors briefly mentioned), which should lead us to question if their assessments are answering the right questions. If their ground truth is not what a human would believe, then this could easily disrupt their main&amp;nbsp;claims.&lt;/p&gt;
&lt;p&gt;Lastly, on the topic of what humans would believe: some people find some things offensive, others don&amp;#8217;t. Are the authors (or by proxy, Perspective) justified in claiming what is toxic and what is not? More philosophically, can someone speak for someone else on what is right or&amp;nbsp;wrong?&lt;/p&gt;</content><category term="meta"></category><category term="machine learning"></category><category term="nlp"></category><category term="society"></category></entry><entry><title>Blog Origins</title><link href="/posts/2020/Oct/blog-origins/" rel="alternate"></link><published>2020-10-14T00:00:00-07:00</published><updated>2020-10-14T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-10-14:/posts/2020/Oct/blog-origins/</id><summary type="html">&lt;p&gt;How this blog came to&amp;nbsp;be&lt;/p&gt;</summary><content type="html">&lt;p&gt;The blog title and subtitle might not sounds&amp;#8230; correct. Your gut is correct, they were not written by me. They were &lt;a href="https://transformer.huggingface.co/doc/gpt2-large" target="_blank"&gt;composed by &lt;span class="caps"&gt;GPT&lt;/span&gt;-2&lt;/a&gt; according to a&amp;nbsp;prompt:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/blog-origins.png" uk-img&gt;&lt;/p&gt;
&lt;p&gt;I cherry-picked a little to find something which somewhat made sense and reflected a general aura of intelligence, and then made one character correction. Please excuse the typo in my&amp;nbsp;prompt.&lt;/p&gt;</content><category term="meta"></category><category term="blogging"></category></entry><entry><title>Setting up AWS IAM</title><link href="/posts/2020/Jun/setting-up-aws-iam/" rel="alternate"></link><published>2020-06-20T00:00:00-07:00</published><updated>2020-06-20T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-06-20:/posts/2020/Jun/setting-up-aws-iam/</id><summary type="html">&lt;p&gt;A quick introduction to &lt;span class="caps"&gt;AWS&lt;/span&gt; Identity and Access&amp;nbsp;Management&lt;/p&gt;</summary><content type="html">&lt;p&gt;Cloud computing and storage services are becoming an essential for many businesses. As a more versatile and easier to scale option than on-premise solutions, their demand has noticeably increased. As businesses look toward these solutions, developers must grow and adapt. Students or professionals without much &lt;span class="caps"&gt;AWS&lt;/span&gt; experience can broaden their skillset by playing around with these platforms. Luckily for this demographic (myself included), the three main cloud providers&amp;#8212;-Amazon Web Services (&lt;span class="caps"&gt;AWS&lt;/span&gt;), Google Cloud Platform (&lt;span class="caps"&gt;GCP&lt;/span&gt;), and Microsoft Azure&amp;#8212;-all offer free tiers to get started learning and&amp;nbsp;experimenting.&lt;/p&gt;
&lt;p&gt;These services are much different than what’s learned in the sometimes archaic education system, so they can be confusing and easy to get wrong when learning. The goal for this article is to demonstrate how to set up a personal-use Amazon Web Services account according to some best practices for Identity and Access Management (&lt;span class="caps"&gt;IAM&lt;/span&gt;). This will be targeted at students and professionals without much &lt;span class="caps"&gt;AWS&lt;/span&gt; experience, and should be about a 10 minute read (although you’re encouraged to try things out yourself). Learning how to properly setup and authenticate your work in the cloud is important for three reasons: 1) to mitigate any opportunities to compromise yourself, your work, your billing information, or other sensitive data, 2) to mitigate any opportunities to mess up and get frustrated, and 3) it’s always good to follow best&amp;nbsp;practices!&lt;/p&gt;
&lt;p&gt;If you&amp;#8217;re just getting started working with cloud services or are looking to begin, I think this article presents a good first or second step. I recommend following the tips at the bottom as soon as you feel&amp;nbsp;ready!&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/iam_workflow.png" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
An example workflow of attributing permissions to an Administrator user on &lt;span class="caps"&gt;AWS&lt;/span&gt;. Source: &lt;a href="https://wellarchitectedlabs.com/security/100_labs/100_basic_identity_and_access_management_user_group_role/1_iam/" target="_blank"&gt;&lt;span class="caps"&gt;AWS&lt;/span&gt; Well-Architected Labs&lt;/a&gt;
&lt;/div&gt;

&lt;h2&gt;Terminology&lt;/h2&gt;
&lt;p&gt;For me, one of the most difficult aspects of learning how to use cloud services was hurdling over the increase in vocabulary. Many terms are polysemous with other developer terms and appear to be drawn together from a variety of computing subdisciplines. Quickly, I&amp;#8217;ll introduce some key terms which you should be familiar with as you endeavour into&amp;nbsp;space.&lt;/p&gt;
&lt;dl class="uk-description-list"&gt;
    &lt;dt&gt;&lt;span class="caps"&gt;IAM&lt;/span&gt;&lt;/dt&gt;
    &lt;dd&gt;The Identity and Access Management section of &lt;span class="caps"&gt;AWS&lt;/span&gt; allows one to control the degree to which different people and services can access parts of the &lt;span class="caps"&gt;AWS&lt;/span&gt; account. It&amp;#8217;s how permissions are set and security&amp;nbsp;tightened.&lt;/dd&gt;
    &lt;dt&gt;Root&lt;/dt&gt;
    &lt;dd&gt;In a hierarchy of control, the root users has access to everything. It&amp;#8217;s like using `sudo` in a shell program. We&amp;#8217;ll cover this soon, but it&amp;#8217;s strongly discouraged to use this login on a daily basis due to the power it holds. For example, under this user you can control the accounts billing information and payment&amp;nbsp;methods.&lt;/dd&gt;
    &lt;dt&gt;User&lt;/dt&gt;
    &lt;dd&gt;A type of individual with less power than the root user. These can be granted unique login credentials. Some common users would be Administrators and Machine Learning Engineers – obviously the MLEs should have less power than the full admins, and by assigning people to user accounts, that can be&amp;nbsp;controlled.&lt;/dd&gt;
    &lt;dt&gt;Group&lt;/dt&gt;
    &lt;dd&gt;A collection of users with a pre-specified set of permissions. These are useful because it&amp;#8217;s easier to manage a collection of users rather than manually going through a list of users to change their individual permissions. Using groups is simply a way to attach permissions to multiple users at one time. A common example is an Administrators group, which can have multiple admins all with the same&amp;nbsp;permissions.&lt;/dd&gt;
    &lt;dt&gt;Role&lt;/dt&gt;
    &lt;dd&gt;A collection of policies/permissions assigned to one or more users when needed. The key here is that, separately from groups, roles provide temporary security. These are useful if you want to, for example, provide credentials to an external group for auditing purposes, or to assign a set of permissions to an &lt;span class="caps"&gt;AWS&lt;/span&gt; service that allow it access another &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;service.&lt;/dd&gt;
    &lt;dt&gt;Policy&lt;/dt&gt;
    &lt;dd&gt;A policy is a marker that defines permissions. These can get complicated, so &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html" target="_blank"&gt;here&amp;#8217;s a link to the in-depth explanation&lt;/a&gt;. For example though, one might create a group called `MainTableAccess` and assign some users to it, and the policy attached to this group only &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_dynamodb_specific-table.html" target="_blank"&gt;allows those in the group to access a specific table&lt;/a&gt; in a DynamoDB&amp;nbsp;database.&lt;/dd&gt;
    &lt;dt&gt;Service&lt;/dt&gt;
    &lt;dd&gt;One of the many subplatforms on &lt;span class="caps"&gt;AWS&lt;/span&gt; that can cause functionality, such as Lambda or &lt;span class="caps"&gt;EC2&lt;/span&gt;.&lt;/dd&gt;
&lt;/dl&gt;

&lt;h2&gt;Quick&amp;nbsp;Setup&lt;/h2&gt;
&lt;h3&gt;Tip&amp;nbsp;#1&lt;/h3&gt;
&lt;p&gt;The first key to securing your &lt;span class="caps"&gt;AWS&lt;/span&gt; account and ensuring your permissions won&amp;#8217;t allow you or others to intentionally, or otherwise, compromise your account, is to follow the &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege" target="_blank"&gt;least privileges model&lt;/a&gt;. Under this mindset, we only assign permissions as they&amp;#8217;re needed. This ensures no user is too privileged, to the point where they may accidentally harm the&amp;nbsp;account.&lt;/p&gt;
&lt;p&gt;Most importantly, make sure that you set up a non-root user. You&amp;#8217;ll almost never want to use the root user. Instead, here I&amp;#8217;ll guide you to setting up an Administrator user. Administrator accounts don&amp;#8217;t get to access things like billing information and cost management, although they can do things like manage users and groups which less powerful users&amp;nbsp;cannot.&lt;/p&gt;
&lt;p&gt;To add an administrator user to your personal &lt;span class="caps"&gt;AWS&lt;/span&gt; account, navigate to your &lt;span class="caps"&gt;AWS&lt;/span&gt; home, where you&amp;#8217;ll see an option to add a user. Name your new user &lt;code&gt;Administrator&lt;/code&gt; or something like it. I assume you&amp;#8217;re working through the console, but may later want to set up the &lt;span class="caps"&gt;AWS&lt;/span&gt; command line tools, so check off programmatic and &lt;span class="caps"&gt;AWS&lt;/span&gt; Management Console access. Choose to set a password later (if you set one now you&amp;#8217;ll still have to reset it later). We&amp;#8217;ll create a new group of users called &lt;code&gt;Administrators&lt;/code&gt; and select the &lt;code&gt;AdministratorAccess&lt;/code&gt; policy. Skip the Tags section and review what you&amp;#8217;ve done. There will be a link in the success box which, upon clicking, will log out the root user and prompt you to log in under a new user. Your username is &lt;code&gt;Administrator&lt;/code&gt; (or whatever you chose) and the password was that which was&amp;nbsp;generated.&lt;/p&gt;
&lt;h3&gt;Tip&amp;nbsp;#2&lt;/h3&gt;
&lt;p&gt;My second tip is to &lt;a href="https://aws.amazon.com/iam/features/mfa" target="_blank"&gt;set up Multi-Factor Authentication (&lt;span class="caps"&gt;MFA&lt;/span&gt;)&lt;/a&gt;. This is an added layer of protection from anyone unwanted accessing your account, which becomes more important your projects and work scale up. For students at &lt;span class="caps"&gt;UC&lt;/span&gt; San Diego, we&amp;#8217;ve become accustomed to using &lt;a href="https://duo.com" target="_blank"&gt;Duo Security&lt;/a&gt; as a two-factor authentication system. With Duo, when you log in with your username and password, you&amp;#8217;ll also be prompted for an authentication response within the&amp;nbsp;app.&lt;/p&gt;
&lt;p&gt;&lt;img class="uk-align-center" data-src="/images/aws_iam_mfa.png" height="" width="80%" alt="" uk-img&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
Preview of setting up Multi-Factor Authentication in &lt;span class="caps"&gt;AWS&lt;/span&gt;. Using Duo is an easy solution and requires scanning a &lt;span class="caps"&gt;QR&lt;/span&gt; code and entering the corresponding authentication codes.
&lt;/div&gt;

&lt;p&gt;To set up &lt;span class="caps"&gt;MFA&lt;/span&gt;, navigate to your &lt;span class="caps"&gt;AWS&lt;/span&gt; &lt;span class="caps"&gt;IAM&lt;/span&gt; home, where there will be an accordion of security credential options. Select to activate &lt;span class="caps"&gt;MFA&lt;/span&gt;, and choose &lt;code&gt;Virtual MFA Device&lt;/code&gt;. Open Duo, scan the &lt;span class="caps"&gt;QR&lt;/span&gt; code, and enter in the authentication keys.&amp;nbsp;Done!&lt;/p&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;That&amp;#8217;s it for this post, but I encourage you go on and explore the &lt;span class="caps"&gt;IAM&lt;/span&gt; aspect of &lt;span class="caps"&gt;AWS&lt;/span&gt; further, especially in regards to the policies and roles that may be set. Once we begin setting up services like Lambda and DynamoDB, it will be important to only allow the bare minimum of what they need to&amp;nbsp;access.&lt;/p&gt;</content><category term="meta"></category><category term="cloud computing"></category></entry><entry><title>Music Collection</title><link href="/posts/2020/May/music-collection/" rel="alternate"></link><published>2020-05-13T00:00:00-07:00</published><updated>2020-05-13T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-05-13:/posts/2020/May/music-collection/</id><summary type="html">&lt;p&gt;How I developed an open-source music collection&amp;nbsp;application&lt;/p&gt;</summary><content type="html">&lt;!-- readtime: 15.1 --&gt;

&lt;p&gt;There is a serious problem with how people attempt to explain why they enjoy certain music. Listeners don’t have the tools, or capacity, to accurately respond to questions like “What kind of music do you listen to?” or “Who are your favorite&amp;nbsp;bands?”.&lt;/p&gt;
&lt;p&gt;Most people are isolated within small social and geographic circles and the scale at which we miss out on good music is astronomical. There’s endless opportunity to discover new music that we might love, and endless opportunity to share what we find and bring joy to others. Almost every music streaming or purchasing platform these days has a recommendation engine, but none has ways to keep track of our thoughts about the music so we can figure out what we like and what we don&amp;#8217;t like. In fact, it seems most people don’t have any systematic way to form relationships between musical entities. Over the last couple months, I&amp;#8217;ve endeavored to create a solution, and this article presents a web-based application I built to enable deeper reasoning about the music I&amp;nbsp;enjoy.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/comparison.png" alt="A screenshot of the music collection app while comparing two albums"&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    Upon loading the application, you&amp;#8217;re are given the option to search for albums within your collection, add new albums to your collection, or continue to score albums.
&lt;/div&gt;

&lt;p&gt;When I first began thinking of this problem, I wanted a way to methodically record my emotional and perceptual experiences with music so that I could have a better idea of what I like, what I don’t like, and how to respond to a question like “What’s your favorite album of all time?” This matters to me because I love music and believe that the music I listen to plays an integral part in building my personality and defining who I am. Enjoying a wide-variety of music allows me to always have a fallback conversation point (although, it doesn’t work when people don’t have a strong connection to music), and I’ve found that people love talking about their tastes in music. You can learn a lot about a person by the musical qualities they&amp;nbsp;enjoy.&lt;/p&gt;
&lt;p&gt;The problem is: how can you quantify the way you think and feel toward music? Ultimately, I’d like to be able to authentically and accurately answer: What are your top 3 albums? and perhaps, Who are your favorite musicians? Knowing my favorite genres would also be exciting. How, then, do we quantify, or at least document, our reactions to&amp;nbsp;records?&lt;/p&gt;
&lt;p&gt;These questions are based upon the assumption that there’s a linear rank that albums could be lined up on. Humans are obsessed with ranking: sports teams ranked on &lt;span class="caps"&gt;ESPN&lt;/span&gt;, product reviews ranked on Amazon, universities rankings on &lt;span class="caps"&gt;US&lt;/span&gt; News. Rankings are intuitive, simple, and natural, therefore they show up prominently in this project. The question then becomes, How do we rank something subjective and aesthetic, like&amp;nbsp;music?&lt;/p&gt;
&lt;p&gt;The study of aesthetics has a long history, and volumes of philosophical arguments and perspectives. Immanuel Kant was one of the most invested spokespeople of aesthetics, arguing that aesthetic judgement is rooted in neither scientific knowledge nor is it bound by rules of understanding. It is the thoughts surrounding individual objects, within and around themselves alone, and in the light of the sensory experiences they generate. He argues that aesthetic judgement cannot be supported by objective or universal principles, for a judgment of taste is always&amp;nbsp;individual.&lt;/p&gt;
&lt;p&gt;With that in mind, it makes sense then to forget about making a multi-user platform: everyone has a different idea of what’s best, and the music charts already exist as an attempt to aggregate reviews over many people. Instead, we need a per-individual&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;A way to organize the collection of music I’ve invested time into is important, both for record keeping (to refresh my limited memory when needed) and for using to rank music. Thus, I developed a system to log my music collection with all the features I need to informatively rank albums. Based upon lots of comparisons between albums, we can construct a ranking, and thus begin to answer the questions we care&amp;nbsp;about.&lt;/p&gt;
&lt;p&gt;I sought to build my own platform to handle my specific needs: the needs of the individual. I began by throwing together a prototype in Python, using the command line as an interface. I tested out the idea of having an input/output pipeline for making comparisons between albums on a variety of characteristics. This helped me identify viable algorithms and create a feedback loop with my study of aesthetics to refine how I could compare albums, ultimately converging upon the idea of pairwise comparisons amongst a variety of incisive questions. The results are two-fold: I have a distributed, cognitive tool which guides my memories and thoughts on records, and I also have a way to quantitatively assess aesthetic pieces to definitively answer the questions I was first motivated&amp;nbsp;by.&lt;/p&gt;
&lt;h2&gt;Music&amp;nbsp;Collection&lt;/h2&gt;
&lt;p&gt;I love talking about music. But when you begin to span dozens of genres, decades, styles, and more, you start to lose track of what’s what and who’s who. To help support my memory, and make it easy to jot notes (which is proven to help you remember things), my application has multiple fields for writing. Each album can receive a review, as can each track. Ideally, after listening to each track and giving them reviews, you’d have a good idea for the global structure and feel of the&amp;nbsp;album.&lt;/p&gt;
&lt;p&gt;To ensure I could draw upon a vast database of world music, I integrate with Spotify, my primary platform for listening to music. This works well, because any record I find or listen to on Spotify can be loaded into the application. The search bar at the top provides a portal to access Spotify’s&amp;nbsp;collections:&lt;/p&gt;
&lt;video height="600" uk-video="autoplay: inview" loop muted&gt;
    &lt;source src="/images/preview.mp4" type="video/mp4"/&gt;
    Your browser does not support the video tag.
&lt;/video&gt;
&lt;div class="caption"&gt;
    Preview of interaction with the application.
&lt;/div&gt;

&lt;p&gt;Below the search, there’s an area which allows two albums to be compared. Which albums get chosen for comparison is optimal (see below), so I can be sure that each comparison is doing the most to generate an accurate ranking. The comparison happens according to a series of questions which I created, although even these are subjective and individualistic: what I think makes a great album isn’t necessarily what you think does (although I tried to be a&amp;nbsp;generalist).&lt;/p&gt;
&lt;h2&gt;Development&lt;/h2&gt;
&lt;p&gt;I underwent the task of teaching myself the React-Redux ecosystem from scratch to make this happen. I would consider myself a JavaScript bystander – occasionally using it with decent proficiency – but learning React and Redux required me to (re)learn a lot. I would argue there’s a decently steep learning curve to the frameworks, given the way the application data are held quite separately in an immutable state. Nonetheless, I made it happen and experienced only a few bouts of hair&amp;nbsp;ripping.&lt;/p&gt;
&lt;p&gt;It was all a learning experience, but from the start I had a rough idea of the size and scope of my application. I intended to apply some React-Redux best practices, which occasionally required some major refactoring, but it was probably worth it. The application is modularized, and I’ve tried to ensure the hierarchy of components keeps logic and data at the appropriate scope. One downside of my current configuration is that the application store holds a lot of data, especially the album collection data. This has started to become a little cumbersome on reloads, especially as I begin to notice small performance hits. I’ve searched for articles outlining best practices for scaling applications with React but haven’t come across anything suitable&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;For storage, I created a MongoDB instance served locally. To interface with this, my backend &lt;span class="caps"&gt;API&lt;/span&gt; is built with Flask, which also routes the main page. This Flask &lt;span class="caps"&gt;API&lt;/span&gt; is responsible for all album data manipulation, including ranking albums and serving category scores, caching and serving album art, and storing changes to reviews and listening history. I also utilize the Spotify Developer’s &lt;span class="caps"&gt;API&lt;/span&gt; to fetch information about albums, including tracklists and album art. Upon adding a new album to my collection, the album art is cached locally on my computer to prevent me from making an unnecessarily large number of requests to Spotify’s image &lt;span class="caps"&gt;CDN&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In summary, the application architecture is as&amp;nbsp;follows:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/architecture.png" alt="The application's architecture relies on Python, Flask, React/Redux, mongo DB, and the Spotify API"&gt;&lt;/p&gt;
&lt;p&gt;Some details are left out here, but the gist is conveyed. I toyed with the idea of using a relational database instead of NoSQL MongoDB, but figured the rest of my code would be most interpretable with a NoSQL framework. Since I’m not pushing the edges of storage capabilities, I didn’t anticipate this to create any noticeable performance issues&amp;nbsp;either.&lt;/p&gt;
&lt;p&gt;At the top of the application, there are methods for filtering and sorting. As my collection grows larger, it’s become increasingly important for me to be able to quickly find albums. I’ve noticed this as I talk about music and want to pull up an album quickly, and when I’m rating albums, and need a refresher. I have five ways to sort: 1) by the date I added the record to my collection, 2) by the date I last listened to the record, 3) by the record’s runtime, 4) by the record’s rank, and 5) by the record’s recommendation score. I can also search according to artist or album name, or by&amp;nbsp;genre:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/filter.png" alt="A screenshot of the application when filtering albums"&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    Example of the filtering methods: a search for &amp;#8220;bepop&amp;#8221; aptly returned John Coltrane&amp;#8217;s A Love Supreme
&lt;/div&gt;

&lt;p&gt;Below I discuss more about the album ranks and recommendation scores. The genres are a somewhat quasi-genres: they’re actually genres of the artist. Spotify doesn’t yet allow developers to access album genres, so I make due with broader genres. Usually, artists have genres; however, some music I’ve discovered is highly esoteric and therefore without classification. This was an edge case I didn’t anticipate but luckily doesn’t affect the &lt;span class="caps"&gt;UX&lt;/span&gt; too&amp;nbsp;much.&lt;/p&gt;
&lt;h2&gt;Design&lt;/h2&gt;
&lt;p&gt;At heart, I’m a sucker for elegant and compelling design. This includes color schemes, negative space, typography, the whole thing. As a result, a constant voice inside me begged for better and better user interface design. I&amp;nbsp;acquiesced.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/album.png" alt="A screenshot of the album view, with Nevermind by Nirvana in focus"&gt;&lt;/p&gt;
&lt;div class="caption"&gt;
    Design was at the forefront of this project, going through many iterations. Clean, elegant, colorful, open was the goal.
&lt;/div&gt;

&lt;p&gt;The design stemmed from some ideas I had and styles I liked, as well as a combination of inspirations from Apple Music, Spotify, various projects I discovered on Behance, and input from friends. It amounted to a clean, straightforward design, with ample incorporation of the uniqueness and beauty inherent in many album artworks. I wanted plenty of negative space to let the application breathe, even if that meant having a long, long list of albums. Simplicity was in mind from the graphs to the&amp;nbsp;fonts.&lt;/p&gt;
&lt;p&gt;With some &lt;span class="caps"&gt;CSS&lt;/span&gt; blur, rotate, and saturation filters, I took the artwork for each record and placed it in the top right corner of each card, creating album themes unique to each record and gently bringing in a little more color and&amp;nbsp;pop.&lt;/p&gt;
&lt;p&gt;The icons come from &lt;a href="http://fontawesome.io/" target="_blank"&gt;FontAwesome.com&lt;/a&gt;, which conveniently can be tied together with specialized React components to ensure proper updates and loading. More can be &lt;a href="https://fontawesome.com/how-to-use/on-the-web/using-with/react" target="_blank"&gt;read&lt;/a&gt; here on&amp;nbsp;that.&lt;/p&gt;
&lt;h2&gt;Scoring and&amp;nbsp;Ranking&lt;/h2&gt;
&lt;p&gt;What really piqued my interest in the beginning was the idea of scoring or ranking albums, on some “best” to “worst” subjective scale. I started out by researching what experts considered characteristics of the “best” music. I found quite a few academic papers. I read hours of album reviews from strangers on internet forums. I took notes while watching music reviewers on YouTube. And I considered my own personal taste. &lt;a href="https://pdfs.semanticscholar.org/d3dd/702011708b38c8bbb58a364a23d452753c52.pdf" target="_blank"&gt;Some researchers&lt;/a&gt; have attempted the idea of quantitatively judging aesthetics, but nothing&amp;#8217;s seemed to have gained recognition or suit my needs. All my research led to the conclusion that there probably wasn’t a good way to rank music (or art in general), let alone quantify its relative superiority to other&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;But it wouldn’t be fun if we just ended the project here. So, I abstracted out 12 categories which I think help explain what makes a good record. Each category became associated with a question, or prompt, for which someone could say one album or the other answered the question better. For example, I think the album art contributes a non-negligible amount to how good an album is. Some of the best albums ever have intriguing, provocative, relevant, and/or memorable artwork (see Dark Side of the Moon, Nevermind, etc.). Here is the list of questions which albums may be compared&amp;nbsp;under:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which album art contributes to the album&amp;nbsp;more?&lt;/li&gt;
&lt;li&gt;Which album would you buy for a music&amp;nbsp;critic?&lt;/li&gt;
&lt;li&gt;Which has songs that build an album greater than its&amp;nbsp;parts?&lt;/li&gt;
&lt;li&gt;Which album makes you think&amp;nbsp;more?&lt;/li&gt;
&lt;li&gt;Which album better balances soft and&amp;nbsp;loud?&lt;/li&gt;
&lt;li&gt;More songs on which album didn&amp;#8217;t flow well with the&amp;nbsp;rest?&lt;/li&gt;
&lt;li&gt;Which album would you buy for your best&amp;nbsp;friend?&lt;/li&gt;
&lt;li&gt;Which are you more likely to get distracted during while&amp;nbsp;listening?&lt;/li&gt;
&lt;li&gt;Which would you choose if forced to listen to one once every&amp;nbsp;day?&lt;/li&gt;
&lt;li&gt;Taking only the lyrics from these albums, which would make a better story in book&amp;nbsp;form?&lt;/li&gt;
&lt;li&gt;Which album has more filler&amp;nbsp;tracks?&lt;/li&gt;
&lt;li&gt;Which album has better&amp;nbsp;vocals?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these questions results in a pairwise comparison, and luckily, there is a long history of ranking according to pairwise comparison. Much of the interest in this field relates to ranking sports teams, chess players, or other types of competitive activities. One popular algorithm the &lt;a href="https://en.wikipedia.org/wiki/Elo_rating_system" target="_blank"&gt;&lt;span class="caps"&gt;ELO&lt;/span&gt; rating method&lt;/a&gt;. However, we can also picture albums as competitors and apply the same&amp;nbsp;principles.&lt;/p&gt;
&lt;p&gt;Previous work by &lt;a href="https://arxiv.org/pdf/1801.01253.pdf" target="_blank"&gt;Heckel et al (2018)&lt;/a&gt; proposed a pairwise ranking algorithm with theoretically optimal guarantees for active learning. Their work was particularly relevant to my system because they designed their algorithm specifically for an active learning setting. This means that there are ways to figure out what the model doesn’t know, or isn’t confident in, and leverage this uncertainty to pick the next, most informative comparison. The algorithm by Heckel et al wasn’t quite what I was looking for, but &lt;a href="https://dl.acm.org/doi/pdf/10.5555/3305890.3305923" target="_blank"&gt;Maystre &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Grossglauser’s (2017)&lt;/a&gt; work proved valuable. They suggested optimal competitive uncertainty sampling with the popular Bradley-Terry ranking model simply by choosing to compare the pair whose relative ordering in most uncertain (has the smallest gap between&amp;nbsp;scores).&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model" target="_blank"&gt;Bradley-Terry model framework&lt;/a&gt; is by far one of the most common approaches to ranking entities given pairwise comparisons. Using the &lt;code&gt;choix&lt;/code&gt; Python package, I compute a Bradley-Terry model for each rating category over all albums. On output, each album is associated with a score from 0 to 1. I take all 12 scores, average them, and rank the albums using this average score. So far, this has worked quite&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;However, I have requirements for when an album can be ranked. Namely, each album is assigned default values for each category which fall between about 0.4 and 0.6, subject to some quirks in the Bradley-Terry models. Only after I’ve listened to the album three full times through may I begin to compare it to other albums. I do this a safeguard and baseline. I don’t want to misjudge an album after having only listened to it once. It may take time to understand it, and often does. Once an album reaches three listens, it will be ready to be queued up in the comparison&amp;nbsp;framework.&lt;/p&gt;
&lt;h2&gt;Recommendation&amp;nbsp;Algorithm&lt;/h2&gt;
&lt;p&gt;With a desire to get the most out of the music I know, I sought out a recommendation engine to suggest which album I should listen to&amp;nbsp;next.&lt;/p&gt;
&lt;p&gt;Most engineers default to complex algorithms when they think of recommendation algorithms. However, my data are fairly slim, and I had some ideas in mind to build a heuristic algorithm instead. This just means that instead of a black-box recommendation algorithm, relying on the albums content or perhaps other data about my listening behavior, I have a deterministic set of rules to create a “recommended&amp;nbsp;score”.&lt;/p&gt;
&lt;p&gt;This recommended score is based on five things: when was the last time I listened to the album, when did I add the album to my collection, how many minutes long is the album, how many times have I listened to the album (and how close is it to having 3 listens), and how common are the genres the artist is listed under. Using these attributes, scores for each are given to each album, and then a weighted average is taken to create an overall recommended score. Sort the recommended score from highest (1) to lowest (0) and there’s the recommendation. It appears on each album card to the right of a small compass&amp;nbsp;icon.&lt;/p&gt;
&lt;p&gt;Unfortunately, this doesn’t discover new music I’ve never heard before; only records I’ve put in my collection already. This isn’t the worst case scenario though. In fact, one of the things I enjoy most is crate-digging. During the &lt;span class="caps"&gt;COVID&lt;/span&gt;-19 lockdown, this now is usually digital crate digging, but I still love to put in the effort to find new artists myself. One great label I recommend for finding eclectic and esoteric music is the &lt;a href="http://www.numerogroup.com/" target="_blank"&gt;Numero Group&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Last&amp;nbsp;Words&lt;/h2&gt;
&lt;p&gt;Overall, I use my application almost every day now as both a repository and an information source. It’s used to record my thoughts and feelings about albums and tracks, and it’s used to recommend what I should listen to next. I filter and sort and discover new patterns in what I like and don’t like. I see gaps in genres of music which I should listen to, forcing me out of my comfort zone and into artists and albums I wouldn’t normally think to&amp;nbsp;explore.&lt;/p&gt;
&lt;p&gt;I won’t be sharing my top albums or genres yet, I have lots of albums to add and listen to before that can&amp;nbsp;happen.&lt;/p&gt;
&lt;p&gt;I maintain &lt;a href="https://github.com/liebscher/MusicCollection" target="_blank"&gt;this project on GitHub&lt;/a&gt;, so feel free to fork it if you think you’d also benefit from it. If you have questions, you may email me or post an issue. I’ll respond either way. One potential use for this is to go beyond music – the framework would work just as great to determine your favorite books, beers, or birds (birds? why not, I needed the&amp;nbsp;alliteration).&lt;/p&gt;</content><category term="meta"></category><category term="music"></category><category term="programming"></category><category term="design"></category></entry><entry><title>Paper accepted at CogSci 2020</title><link href="/posts/2020/Apr/cogsci-acceptance/" rel="alternate"></link><published>2020-04-30T00:00:00-07:00</published><updated>2020-04-30T00:00:00-07:00</updated><author><name>Alex Liebscher</name></author><id>tag:None,2020-04-30:/posts/2020/Apr/cogsci-acceptance/</id><summary type="html">&lt;p&gt;Our paper was accepted at this year&amp;#8217;s Cognitive Science&amp;nbsp;Conference.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A first-half of my undergraduate thesis was accepted to &lt;a href="https://cognitivesciencesociety.org/cogsci-2020/"&gt;CogSci 2020&lt;/a&gt;. I am in the process of submitting this together with the second (confirmatory) half to&amp;nbsp;journals.&lt;/p&gt;
&lt;p&gt;If you wish, you may read &lt;a href="https://liebscher.github.io/assets/pdf/liebscher_cogsci20_proceedings.pdf"&gt;our CogSci paper here&lt;/a&gt;.&lt;/p&gt;</content><category term="meta"></category><category term="news"></category></entry></feed>